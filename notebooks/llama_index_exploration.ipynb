{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set your API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env OPENAI_API_KEY=<Fetch at: https://platform.openai.com/account/api-keys>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-ins\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# custom lib\n",
    "from rag_tools.repo.ops import ensure_repo_exists_locally, DocumentationExtractor\n",
    "\n",
    "# third party libs\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, Document, download_loader\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.llms import OpenAI\n",
    "from metaflow import Flow\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    def __init__(self, response: str, source_node_ids: List[str]):\n",
    "        self.response = response\n",
    "        self.source_node_ids = source_node_ids\n",
    "\n",
    "    def get_link_df(self, meta_df, link_col = 'doc_id'):\n",
    "        return meta_df[meta_df[link_col].isin(self.source_node_ids)]\n",
    "\n",
    "def qa_iter(\n",
    "    question: str, \n",
    "    index: VectorStoreIndex, \n",
    "    k:int = 2, \n",
    "    response_mode:str = 'tree_summarize'\n",
    ") -> Context:\n",
    "    \"Match a question against an index and returns the response.\"\n",
    "    retriever = VectorIndexRetriever(index=index, similarity_top_k=k)\n",
    "    response_synthesizer = get_response_synthesizer(response_mode=response_mode)\n",
    "    query_engine = index.as_query_engine(response_synthesizer=response_synthesizer, retriever=retriever)\n",
    "    query_res = query_engine.query(question)\n",
    "    return Context(\n",
    "        response=query_res.response, source_node_ids=list(query_res.metadata.keys())\n",
    "    )\n",
    "\n",
    "dm = lambda x: display(Markdown(x))\n",
    "def dmqa(q, a): \n",
    "    dm(f\"\"\"\n",
    "**Question:** {q}\n",
    "\n",
    "**Answer:** {a}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def nb_output_format(question, response, similar_chunk_df):\n",
    "    dm(f\"#### {question}\")\n",
    "    dm(f\"**Retrieved Response**\")\n",
    "    dm(response)\n",
    "    dm(f\"#### Sources\")\n",
    "    for _, chunk in similar_chunk_df.iterrows():\n",
    "        dm(f\"##### [{chunk.header}]({chunk.page_url})\")\n",
    "        dm(f\"{chunk.contents[:100]}...\")\n",
    "\n",
    "def get_documents_from_content_section_df(df):\n",
    "    ids = []; documents = []\n",
    "    for i, text in enumerate(df.contents):\n",
    "        doc = Document(text=text, id_=i)\n",
    "        documents.append(doc)\n",
    "        ids.append(doc.id_)\n",
    "    return documents, ids\n",
    "\n",
    "def generative_search_engine_iter(question, index, meta_df, meta_df_id_col='doc_id'):\n",
    "    \"Assumes index and df are defined in the global scope\"\n",
    "    context = qa_iter(question, index)\n",
    "    similar_chunk_df = meta_df[meta_df[meta_df_id_col].isin(context.source_node_ids)]\n",
    "    nb_output_format(question, context.response, similar_chunk_df)\n",
    "\n",
    "def get_documents_from_md_file_paths(fps):\n",
    "    MarkdownReader = download_loader(\"MarkdownReader\")\n",
    "    loader = MarkdownReader()\n",
    "    documents = []\n",
    "    for fp in fps:\n",
    "        documents += loader.load_data(file=Path(fp))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›‘ Set variables based on your machine's setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are part of this repo, so you don't need to change\n",
    "DATA_DIR='../data'\n",
    "LLAMA_INDEX_TUTORIAL_DATA = os.path.join(DATA_DIR, 'llama-index-tutorial')\n",
    "\n",
    "# this is unique to your machine. where did you clone https://github.com/Netflix/metaflow-docs to?\n",
    "YOUR_LOCAL_METAFLOW_DOCS_REPO_PATH = os.path.expanduser(\"~/Dev/metaflow-docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GitHub repos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PARAMS = [\n",
    "    {\n",
    "        \"deployment_url\": \"docs.metaflow.org\",\n",
    "        \"repository_path\": \"https://github.com/Netflix/metaflow-docs\",\n",
    "        \"repository_ref\": \"master\",\n",
    "        \"base_search_path\": \"docs\",\n",
    "        \"exclude_paths\": [\"docs/v\"],\n",
    "        \"exclude_files\": [\"README.md\", \"README\"],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Llama Index Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will trigger llama_index to look for OPENAI_API_KEY in environment variables,\n",
    "# then default to downloading a llama 2 model binary locally.\n",
    "\n",
    "# this thing is looking for a .txt file in the data dir.\n",
    "documents = SimpleDirectoryReader(LLAMA_INDEX_TUTORIAL_DATA).load_data()\n",
    "\n",
    "# Indexing is the first, and most crucial, stage in a RAG workflow.\n",
    "# It is the process of converting a set of documents into a vector representation.\n",
    "# This vector representation is later used to retrieve relevant documents for a given query.\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 computer. They also built a microcomputer kit and started programming on it, writing simple games and a word processor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query engine \"takes in a natural language query, and returns a response, along with reference context retrieved and passed to the LLM.\"\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "dm(response.response)\n",
    "\n",
    "# Taking too many minutes to run with Llama 2 on my macbook :( \n",
    "# Conservatively estimate OpenAI API is ~$1 per dozen end-to-end runs of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a [Llama Hub tool for parsing `.md` files](https://llamahub.ai/l/file-markdown)\n",
    "\n",
    "This could be used in conjunction or in place of the custom markdown parser used in `./markdown_chunker.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index import download_loader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarkdownReader = download_loader(\"MarkdownReader\")\n",
    "loader = MarkdownReader()\n",
    "\n",
    "# start with a single document\n",
    "test_path = os.path.abspath(\"%s/test-data/ob/blog/metaflow-fast-data.md\" % DATA_DIR)\n",
    "documents = loader.load_data(file=Path(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask some questions over the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** What is the fastest way to load data onto AWS Batch instances using Metaflow?\n",
       "\n",
       "**Answer:** The fastest way to load data onto AWS Batch instances using Metaflow would be to utilize the data loading capabilities provided by Metaflow itself. Metaflow offers built-in functionality for handling data loading and processing, allowing you to efficiently transfer and process data on AWS Batch instances. By leveraging Metaflow's data loading features, you can optimize the loading process and ensure efficient utilization of AWS Batch resources.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = (\n",
    "    \"What is the fastest way to load data onto AWS Batch instances using Metaflow?\"\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(question).response\n",
    "\n",
    "dmqa(question, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How does Metaflow use `tmpfs`?\n",
       "\n",
       "**Answer:** Metaflow uses `tmpfs` to store temporary data during the execution of workflows. `tmpfs` is a temporary file system that resides in memory, which means that the data stored in `tmpfs` is not persisted across system reboots. This makes it ideal for storing temporary data that is only needed during the execution of a workflow and can be discarded afterwards. By using `tmpfs`, Metaflow can achieve faster read and write operations compared to using disk-based storage.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"How does Metaflow use `tmpfs`?\"\n",
    "response = query_engine.query(question).response\n",
    "dmqa(question, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Controlling hallucinations by curating an index\n",
    "Here are a few questions we will explore in this section:\n",
    "\n",
    "**What is the problem with the above workflow?**\n",
    "\n",
    "In the previous section's index, we created all the vectors from chunks of a [post](https://outerbounds.com/blog/metaflow-fast-data/) specifically about the `tmpfs` feature. [Metaflow docs](https://docs.metaflow.org/) don't contain that much content about `tmpfs` yet.\n",
    "\n",
    "If we use the Metaflow docs as the source objects to populate the index, and a question is asked to the model about `tmpfs`, how can we know if it is hallucinating it, or referencing an actual piece of content that Metaflow maintainers endorse?\n",
    "> Bing Chat AI:\n",
    "Give a bunch of links to the content that LLM response was conditioned on.\n",
    "\n",
    "We will build a simple system like this in the next section. First, let's see the power of understanding the domain of our index, and then move to using it as a way to reference source material in the generated response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Metaflow docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = DocumentationExtractor().filter_files(\n",
    "    YOUR_LOCAL_METAFLOW_DOCS_REPO_PATH,\n",
    "    base_search_path = \"docs\",\n",
    "    exclude_paths = [\"docs/v\"],\n",
    "    exclude_files = [\"README.md\", \"README\"],\n",
    "    considered_extensions = [\".md\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [abs_path for abs_path, _ in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents_from_md_file_paths(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing sample of 1 out of 500 <class 'llama_index.schema.Document'> objects\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id_='b185a5f6-76a2-4095-9523-adb59d3518c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='168707b49cebf5424ed48615defbba683a0d7932f8451d263d491040c37aa87f', text='\\n\\nWelcome to Metaflow\\n\\nMetaflow makes it easy to build and manage real-life data science and machine learning projects.\\n\\n\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1\n",
    "print(\n",
    "    \"Showing sample of {m} out of {n} {t} objects\".format(\n",
    "        m=N, n=len(documents), t=type(documents[0])\n",
    "    )\n",
    ")\n",
    "documents[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 582 ms, sys: 187 ms, total: 770 ms\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "# TODO: Measure times as this thing scales with N documents and larger sized documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A iterations over the Metaflow docs index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** What is Metaflow?\n",
       "\n",
       "**Answer:** Metaflow is a Python library that simplifies the development, deployment, and operation of data-intensive applications, specifically those related to data science and machine learning. It was initially created at Netflix to enhance the efficiency of data scientists working on a range of projects, from traditional statistics to cutting-edge deep learning. Metaflow is an open-source tool released under the Apache License, Version 2.0.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What is Metaflow?\"\n",
    "context = qa_iter(question, index)\n",
    "dmqa(question, context.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How do I specify conda dependencies in my flow?\n",
       "\n",
       "**Answer:** You can specify conda dependencies in your flow using the `@conda_base` and `@conda` decorators. The `@conda_base` decorator is used at the flow level to specify explicit library dependencies, python version, and whether to exclude all steps from executing within a conda environment. The `@conda` decorator is used at the step level to update the explicit library dependencies, python version, and conda environment exclusion as specified by the `@conda_base` decorator. By using these decorators, you can define the conda environment for each step in your flow. Additionally, you can add an explicit dependency on a specific module by using the `@conda` decorator in the corresponding step.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"How do I specify conda dependencies in my flow?\"\n",
    "context = qa_iter(question, index)\n",
    "dmqa(question, context.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Metaflow docs know about `tmpfs` though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How does Metaflow use `tmpfs`?\n",
       "\n",
       "**Answer:** Metaflow does not use `tmpfs` based on the given information.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"How does Metaflow use `tmpfs`?\"\n",
    "dmqa(question, qa_iter(question, index).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding specific knowledge to the index\n",
    "\n",
    "As of August, 2023, the Metaflow documentation do not have much writing about `tmpfs`, so this makes sense.\n",
    "\n",
    "How can we add [Outerbounds blog post](https://outerbounds.com/blog/metaflow-fast-data/) that announced the `tmpfs` and Metaflow integration to the index, to give the model the context it needs to answer this question?\n",
    "\n",
    "Let's create an index that combines the one we saw earlier for the `tmpfs` blog post with the one we just created for Metaflow docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_data_file_path = os.path.abspath('%s/test-data/ob/blog/metaflow-fast-data.md' % DATA_DIR)\n",
    "\n",
    "# combining the document set\n",
    "fast_data_doc = get_documents_from_md_file_paths([fast_data_file_path])\n",
    "index_fast_data_post = VectorStoreIndex.from_documents(fast_data_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How does Metaflow use `tmpfs`?\n",
       "\n",
       "**Answer:** Metaflow recently implemented support for memory-based `tmpfs` filesystem on AWS Batch and Kubernetes. This feature allows users to create an ephemeral filesystem backed by memory on the fly, without making any changes to the infrastructure. By enabling this feature using the `@batch(use_tmpfs=True)` decorator for AWS Batch workloads or `@kubernetes(use_tmpfs=True)` decorator for Kubernetes, the `metaflow.S3` client is automatically aware of the `tmpfs` volume and will use it to speed up downloads. This helps improve the performance of data downloads from S3 in Metaflow workflows.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same question as above. now we can answer it with the new index.\n",
    "question = \"How does Metaflow use `tmpfs`?\"\n",
    "dmqa(question, qa_iter(question, index_fast_data_post).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes are updateable/composable! \n",
    "for doc_chunk in fast_data_doc:\n",
    "    index.insert(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How does Metaflow use `tmpfs`?\n",
       "\n",
       "**Answer:** Metaflow uses `tmpfs` by implementing support for memory-based `tmpfs` filesystem on Batch and Kubernetes. This allows users to create an ephemeral filesystem backed by memory on the fly, without having to make any changes on the infrastructure side. When the `tmpfs` feature is enabled, the `metaflow.S3` client automatically uses it to speed up downloads. To enable this feature, users can add `@batch(use_tmpfs=True)` for AWS Batch workloads or `@kubernetes(use_tmpfs=True)` for Kubernetes in their Metaflow code.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Question:** How do I specify conda dependencies in my flow?\n",
       "\n",
       "**Answer:** You can specify conda dependencies in your flow using the `@conda_base` and `@conda` decorators. The `@conda_base` decorator is used at the flow level to specify explicit library dependencies, python version, and whether to exclude all steps from executing within a conda environment. The `@conda` decorator is used at the step level to update the explicit library dependencies, python version, and conda environment exclusion as specified by the `@conda_base` decorator. By using these decorators, you can define the conda environment for each step in your flow. Additionally, you can add an explicit dependency on a specific module by using the `@conda` decorator in the desired step.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same questions as above. now we can answer it with the new index.\n",
    "question = \"How does Metaflow use `tmpfs`?\"\n",
    "dmqa(question, qa_iter(question, index).response)\n",
    "\n",
    "# and this one too.\n",
    "question = \"How do I specify conda dependencies in my flow?\"\n",
    "dmqa(question, qa_iter(question, index).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constructing an index based on sections of endorsed content we can link to\n",
    "[Parse the Documents into Nodes](https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/usage_pattern.html#parse-the-documents-into-nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch all file paths of .md files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for remote repository at https://github.com/Netflix/metaflow-docs\n",
      "Looking for remote repository at https://github.com/huggingface/accelerate\n"
     ]
    }
   ],
   "source": [
    "from rag_tools.filetypes.markdown import Mixin as mm\n",
    "# this cell is like a condensed version of `/flows/markdown_chunker.py`\n",
    "_mm = mm()\n",
    "_mm.repo_params = REPO_PARAMS\n",
    "\n",
    "# this is an unprocessed df, so you may want to clean it as /flows/data_table_processor.py does.\n",
    "df = _mm.load_df_from_repo_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, ids = get_documents_from_content_section_df(df)\n",
    "df['doc_ids'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The above instructions work even if you use [`@conda`\n",
       " decorators](/scaling/dependencies#managing-dependencies-with-conda-decorator) in your\n",
       " code; you need, however, to ensure that the `conda` binary is available in your `PATH`.\n",
       " The easiest way to do this is to set the `PATH` environment variable to properly include\n",
       " the path to the `conda` binary if it is in a non-standard location. In VSCode, you can\n",
       " simply add this value in the env section of launch.json and in PyCharm, the UI allows\n",
       " you to set environment variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "dm(random.choice(documents).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataframe of text chunks and metadata from your latest workflow runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692847583518101\n"
     ]
    }
   ],
   "source": [
    "# find latest Metaflow run that saved processed df\n",
    "run = None\n",
    "for _run in Flow('DataTableProcessor'):\n",
    "    if _run.data.save_processed_df:\n",
    "        run = _run\n",
    "        break\n",
    "\n",
    "print(run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run.data.processed_df\n",
    "documents, ids = get_documents_from_content_section_df(df)\n",
    "df['doc_id'] = ids\n",
    "index = VectorStoreIndex(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1209']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### What is Metaflow?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Retrieved Response**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Metaflow is a Python library that simplifies the development, deployment, and operation of data-intensive applications, particularly those related to data science and machine learning. It was initially created at Netflix to enhance the productivity of data scientists working on various projects. Metaflow is available as an open-source framework under the Apache License, Version 2.0. It allows data scientists to focus on important aspects like feature engineering and model development while abstracting away tasks such as job organization, orchestration, scheduling, and interaction with data warehouses. Additionally, Metaflow enables the building of production-ready machine learning workflows using a simple Python API and facilitates seamless transitions between local prototyping environments and cloud-based deployments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Sources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [What is Metaflow](https://docs.metaflow.org/introduction/what-is-metaflow#what-is-metaflow)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Metaflow is a human-friendly Python library that makes it straightforward to develop, deploy, and op..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [Reproducible ML pipelines with Metaflow](https://outerbounds.com/blog/machine-learning-pipelines-from-prototype-to-production#reproducible-ml-pipelines-with-metaflow)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To help data scientists focus on the parts of the stack they really care about, such as feature engi..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What is Metaflow?\"\n",
    "generative_search_engine_iter(question, index, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### How does Metaflow work with Kubernetes?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Retrieved Response**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Metaflow now has the capability to run on top of any Kubernetes cluster. Users can run all or parts of any Metaflow flow on Kubernetes from their workstation by using the command \"run --with kubernetes\". Additionally, users can deploy their flow to Argo Workflows, a Kubernetes-native workflow scheduler, with a single command \"argo-workflows create\" to execute the flow asynchronously. For more information on setting up and operating Kubernetes for Metaflow, users can refer to the engineering resources provided by Metaflow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Sources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [Add capability to launch Metaflow tasks on Kubernetes and schedule Metaflow flows with Argo Workflows.](https://docs.metaflow.org/internals/release-notes#add-capability-to-launch-metaflow-tasks-on-kubernetes-and-schedule-metaflow-flows-with-argo-workflows)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "This release enables brand new capabilities for [Metaflow on top of\n",
       " Kubernetes](https://outerbounds..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [Using Kubernetes](https://docs.metaflow.org/scaling/remote-tasks/kubernetes#using-kubernetes)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are some useful tips and tricks related to running Metaflow on Kubernetes. See our\n",
       " engineering..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"How does Metaflow work with Kubernetes?\"\n",
    "generative_search_engine_iter(question, index, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### What is a DAG?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Retrieved Response**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "A DAG, or directed acyclic graph, is a graph that consists of nodes connected by directed edges, where the edges have a specific direction and there are no cycles in the graph. In the context of Metaflow, a DAG is inferred based on the transitions between step functions. The nodes in the DAG are the steps, which represent operations, and the edges represent the transitions between steps. The DAG structure is important for defining the flow of execution and dependencies between steps in Metaflow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Sources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [Graph](https://docs.metaflow.org/internals/technical-overview#graph)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Metaflow infers a directed (typically acyclic) graph based on the transitions between\n",
       " step function..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### [The Structure of Metaflow Code](https://docs.metaflow.org/metaflow/basics#the-structure-of-metaflow-code)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Metaflow follows [the dataflow\n",
       " paradigm](https://en.wikipedia.org/wiki/Dataflow_programming) which ..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What is a DAG?\"\n",
    "generative_search_engine_iter(question, index, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG for a generic sales pitch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A custom prompt template in pure Python\n",
    "Many tools exist to make prompts easy to manage. [Langchain](https://www.langchain.com/) is an emerging leader in this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Write an introduction email to a potential technical user who works as a {role} at {company}.\n",
    "\n",
    "Do not directly address the user's role or company anywhere in the email.\n",
    "\n",
    "Write the email for a technical audience who doesn't want to read marketing copy.\n",
    "\n",
    "Highlight Metaflow features related to their interests including {interests}.\n",
    "\n",
    "Include a summary motivating the benefits of these features by summarizing this context about Metaflow:\n",
    "{context_about_interests}\n",
    "\n",
    "Make a subtle reference that Outerbounds platform can help them with {enterprise_platform_interest_hook}.\n",
    "\n",
    "Include a summary motivating the benefits of Outerbounds platform by summarizing this context about Outerbounds platform:\n",
    "{context_about_enterprise_platform_interest_hook}\n",
    "\n",
    "Make the CTA to schedule a meeting to discuss how Outerbounds platform can help them.\n",
    "\n",
    "Make the email as short as possible. \n",
    "\n",
    "Do not reference your own profession or any experiences. Do not talk about yourself.\n",
    "\n",
    "Do not explicitly reference the company that the receiver works for. Only implicitly use this knowledge to demonstrate knowledge of the problems their organization may face.\n",
    "\n",
    "Avoid speaking from the first person.\n",
    "\n",
    "Avoid directly saying that you know about anyone's past experience or background. \n",
    "\n",
    "Avoid saying anything with similar sentiment to these statements:\n",
    "    <br/> &ensp;- Author Metaflow flows using notebooks\n",
    "    <br/> &ensp;- Refer to an interest listed above as something Metaflow works with\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering 101\n",
    "Inject some relevant context into our prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_we_learned_about_a_prospect = dict(\n",
    "    role=\"data scientist\",\n",
    "    company=\"Big Industries Co.\",\n",
    "\n",
    "    # comma-separated lists\n",
    "    interests=\"mlops, deep learning, kubernetes\",\n",
    "    enterprise_platform_interest_hook=\"CI/CD, security\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGify! \n",
    "Here we use the Q&A iteration you saw in previous sections, but instead of printing the results we are using them to \"augment\" the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:27<00:00,  9.04s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00, 10.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# RAG step - fetch some context\n",
    "from tqdm import tqdm\n",
    "\n",
    "interest_list = things_we_learned_about_a_prospect[\"interests\"].split(\", \")\n",
    "context_about_interests = []\n",
    "for interest in tqdm(interest_list):\n",
    "    context_about_interest = qa_iter(\n",
    "        f\"Describe how Metaflow and {interest} can be used together in ML workflows. Focus on Metaflow being used as a complimentary tool.\",\n",
    "        index,\n",
    "    )\n",
    "    context_about_interests.append(context_about_interest)\n",
    "\n",
    "enterprise_platform_interest_hook = things_we_learned_about_a_prospect[\n",
    "    \"enterprise_platform_interest_hook\"\n",
    "].split(\", \")\n",
    "context_about_enterprise_platform_interest_hook = []\n",
    "for interest in tqdm(enterprise_platform_interest_hook):\n",
    "    context_about_interest = qa_iter(\n",
    "        f\"Describe how Metaflow and {interest} can be used together in ML workflows. Focus on Metaflow being used as a complimentary tool.\",\n",
    "        index,\n",
    "    )\n",
    "    context_about_enterprise_platform_interest_hook.append(context_about_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack context injection data to encourage the generative LLM to embed the links in its Markdown response.\n",
    "\n",
    "def prepare_with_links(context_list: List[Context]):\n",
    "    def strip_numbers_and_punctuation(header):\n",
    "        import string\n",
    "        import re\n",
    "\n",
    "        return re.sub(\n",
    "            r\"\\d\", \"\", header.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        )\n",
    "\n",
    "    context_to_inject = \"\"\"\n",
    "The results will be given to you in a format like\n",
    "<br/> &ensp;- \"Text\": [Comma-separated list of [Link Label](Link URL)]\n",
    "Use the [Link Label](Link URL) syntax in the summary, and use the links in context of the paragraph.\n",
    "\n",
    "These are the results to summarize:\n",
    "\"\"\"\n",
    "    for _context in context_list:\n",
    "        similar_chunk_df = _context.get_link_df(df)\n",
    "        links = []\n",
    "        for header, url in list(\n",
    "            zip(similar_chunk_df.header.values, similar_chunk_df.page_url.values)\n",
    "        ):\n",
    "            links.append(f\"[{strip_numbers_and_punctuation(header)}]({url})\")\n",
    "        context_to_inject += (\n",
    "            \"<br/>\" + \" &ensp;-\" + ' \"' + _context.response + '\": ' + \", \".join(links)\n",
    "        )\n",
    "    return context_to_inject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(\n",
    "    **things_we_learned_about_a_prospect,\n",
    "    context_about_interests=prepare_with_links(context_about_interests),\n",
    "    context_about_enterprise_platform_interest_hook=prepare_with_links(\n",
    "        context_about_enterprise_platform_interest_hook\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a negative sentiment to avoid by append to the prompt with an 'avoid' instruction, or press enter to continue, or type r then enter to restart:  \n"
     ]
    }
   ],
   "source": [
    "# append negative sentiment escapes to prompt.\n",
    "# treat these like UX escape hatches, where you can always just stuff extra things in, until you reach the model's context width.\n",
    "user_interaction = True\n",
    "negative_sentiment_context_lines = []\n",
    "while user_interaction:\n",
    "\n",
    "    if len(negative_sentiment_context_lines) == 0:\n",
    "        user_input = input(\n",
    "            \"Enter a negative sentiment to avoid by append to the prompt with an 'avoid' instruction, or press enter to continue, or type r then enter to restart: \"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Current list of negative sentiment statements:\")\n",
    "        for line in negative_sentiment_context_lines:\n",
    "            print(line)\n",
    "        user_input = input(\n",
    "            \"Single enter to continue, double enter to complete list of results of negative sentiment statements.\"\n",
    "        )\n",
    "    # process user input\n",
    "    if user_input == \"\":\n",
    "        user_interaction = False\n",
    "    elif user_input == \"r\":\n",
    "        negative_sentiment_context_lines = []\n",
    "    else:\n",
    "        negative_sentiment_context_lines.append(user_input)\n",
    "\n",
    "for line in negative_sentiment_context_lines:\n",
    "    prompt += \"<br/>\" + \" &ensp;-\" + \" \" + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the final prompt the model will see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### The first five hundred chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Write an introduction email to a potential technical user who works as a data scientist at Big Industries Co..\n",
       "\n",
       "Do not directly address the user's role or company anywhere in the email.\n",
       "\n",
       "Write the email for a technical audience who doesn't want to read marketing copy.\n",
       "\n",
       "Highlight Metaflow features related to their interests including mlops, deep learning, kubernetes.\n",
       "\n",
       "Include a summary motivating the benefits of these features by summarizing this context about Metaflow:\n",
       "\n",
       "The results will be give..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm(\"##### The first five hundred chars\") \n",
    "dm(prompt[:500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See your RAG app in action! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Generated email"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Subject: Enhancing ML Workflows with Metaflow and Outerbounds Platform\n",
       "\n",
       "Dear [Recipient],\n",
       "\n",
       "I hope this email finds you well. I wanted to reach out to introduce you to Metaflow, a powerful tool that can enhance your data science workflows and help you achieve scalability, reproducibility, and production-readiness.\n",
       "\n",
       "Metaflow can be used as a complimentary tool in ML workflows, particularly when combined with MLOps practices. By integrating Metaflow into your pipeline, you can leverage its capabilities to build and deploy ML models more efficiently. It takes care of low-level infrastructure such as data, compute, orchestration, and versioning, allowing you to focus on the fun parts of building applications and models. [Metaflow takes care of the plumbing so you can focus on the fun parts](https://docs.metaflow.org/introduction/why-metaflow#10-metaflow-takes-care-of-the-plumbing-so-you-can-focus-on-the-fun-parts).\n",
       "\n",
       "For deep learning projects, Metaflow provides a robust and user-friendly foundation. It covers the full stack of DS/ML infrastructure, allowing you to focus on iterating on ideas quickly and deploying them confidently. [Metaflow covers the full stack of DS/ML infrastructure](https://docs.metaflow.org/introduction/why-metaflow#9-metaflow-covers-the-full-stack-of-ds-ml-infrastructure).\n",
       "\n",
       "If you're working with Kubernetes, Metaflow seamlessly integrates with it to leverage scalable infrastructure for running ML/DS applications. This makes it suitable for both small and large organizations. [Metaflow relies on systems that engineers know and trust](https://docs.metaflow.org/introduction/why-metaflow#11-metaflow-relies-on-systems-that-engineers-know-and-trust).\n",
       "\n",
       "In addition to Metaflow, I wanted to mention Outerbounds Platform, which can further enhance your ML workflows. It offers CI/CD capabilities, ensuring that changes to ML models and data pipelines are thoroughly tested and deployed in a reliable and efficient manner. Outerbounds Platform also prioritizes security, respecting your company's security policies and providing a secure environment for executing data science projects.\n",
       "\n",
       "I would love to schedule a meeting to discuss how Metaflow and Outerbounds Platform can specifically benefit your organization and address any challenges you may be facing. Please let me know a time that works for you, and I will be happy to set up a call.\n",
       "\n",
       "Looking forward to hearing from you.\n",
       "\n",
       "Best regards,\n",
       "[Your Name]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_res = query_engine.query(prompt)\n",
    "response = query_res.response\n",
    "dm(\"##### Generated email\")\n",
    "dm(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [\n",
    "    {\n",
    "        \"deployment_url\": \"docs.metaflow.org\",\n",
    "        \"repository_path\": os.path.expanduser(\"~/Dev/metaflow-docs\"),\n",
    "        \"repository_ref\": \"master\",\n",
    "        \"base_search_path\": \"docs\",\n",
    "        \"exclude_paths\": [\"docs/v\"],\n",
    "        \"exclude_files\": [\"README.md\", \"README\"],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_repos_to_docs(repos):\n",
    "    documents = []\n",
    "    for params in repos:\n",
    "        md_files = DocumentationExtractor().filter_files(\n",
    "            params[\"repository_path\"],\n",
    "            base_search_path=params[\"base_search_path\"],\n",
    "            exclude_paths=params[\"exclude_paths\"],\n",
    "            exclude_files=params[\"exclude_files\"],\n",
    "            considered_extensions=[\".md\"]\n",
    "        )\n",
    "        md_files = [abs_path for abs_path, _ in md_files]\n",
    "        documents += get_documents_from_md_file_paths(md_files)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='818c7d59-7d59-4c9a-8e26-be8fa66929f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='168707b49cebf5424ed48615defbba683a0d7932f8451d263d491040c37aa87f', text='\\n\\nWelcome to Metaflow\\n\\nMetaflow makes it easy to build and manage real-life data science and machine learning projects.\\n\\n\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='baebefe9-9cf4-4c6b-8831-3fec827af036', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0c733db8a7e3a129b3c47977e53aa8d0ee5e0942e768f40d822a65e1da4f9aea', text='\\n\\nMotivation\\n\\n- Why Metaflow\\n- What is Metaflow\\n- Metaflow Resources\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = local_repos_to_docs(repos)\n",
    "documents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.0\n",
    "model = \"gpt-3.5-turbo\"\n",
    "chat_mode = \"react\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=OpenAI(model=model, temperature=temp))\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(service_context=service_context, chat_mode=chat_mode, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'How does Metaflow help AI developers?'}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mObservation: Metaflow helps AI developers by providing a robust and user-friendly foundation for data-intensive applications. It takes care of the low-level infrastructure such as data, compute, orchestration, and versioning, allowing developers to focus on building their own applications, models, and policies on top of it. This means that AI developers who have a basic understanding of Python can leverage Metaflow to streamline their development process and focus on the more enjoyable aspects of their work.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"How does Metaflow help AI developers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Metaflow helps AI developers by providing a robust and user-friendly foundation for data-intensive applications. It takes care of the low-level infrastructure such as data, compute, orchestration, and versioning, allowing developers to focus on building their own applications, models, and policies on top of it. This means that AI developers who have a basic understanding of Python can leverage Metaflow to streamline their development process and focus on the more enjoyable aspects of their work."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mThought: I have already answered this question. I can provide a summary of my previous response to help answer the question again.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': \"The enjoyable aspects of AI developers' work\"}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mObservation: The enjoyable aspects of AI developers' work include the ability to create value with machine learning, similar to traditional software engineering. The development and deployment of ML systems are expected to mature and improve over time, just as software development has done in the past 20 years. Efforts from various entities, such as governments, open source communities, and for-profit companies, are being made to articulate risks, develop best practices, and provide tooling to support ML development. This indicates a positive prognosis for the future of AI development.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mResponse: The enjoyable aspects of AI developers' work include the ability to create value with machine learning, the opportunity for continuous learning and staying updated with the latest advancements, the potential for impactful applications, collaboration with interdisciplinary teams, the freedom to experiment and innovate, and the automation of repetitive tasks. Additionally, efforts from various entities are being made to support and improve the development and deployment of ML systems, indicating a positive prognosis for the future of AI development.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The enjoyable aspects of AI developers' work include the ability to create value with machine learning, the opportunity for continuous learning and staying updated with the latest advancements, the potential for impactful applications, collaboration with interdisciplinary teams, the freedom to experiment and innovate, and the automation of repetitive tasks. Additionally, efforts from various entities are being made to support and improve the development and deployment of ML systems, indicating a positive prognosis for the future of AI development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What are the enjoyable aspects of their work?\")\n",
    "dm(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_engine.chat_repl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG demo",
   "language": "python",
   "name": "rag-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

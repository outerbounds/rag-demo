index,header,contents,type,page_url,is_howto,char_count,word_count,tld
0,Welcome to Metaflow,"Metaflow makes it easy to build and manage real-life data science and machine learning
 projects.
 
 <div className=""tocList"">",H1,https://docs.metaflow.org/#welcome-to-metaflow,False,126,18,https://docs.metaflow.org
10,What is Metaflow,"Metaflow is a human-friendly Python library that makes it straightforward to develop,
 deploy, and operate various kinds of data-intensive applications, in particular those
 involving data science and ML. Metaflow was originally developed at Netflix to boost the
 productivity of data scientists who work on a wide variety of projects, from classical
 statistics to state-of-the-art deep learning.
 
 Metaflow is available as open-source under the [Apache License, Version
 2.0](https://github.com/Netflix/metaflow/blob/master/LICENSE).",H1,https://docs.metaflow.org/introduction/what-is-metaflow#what-is-metaflow,False,536,68,https://docs.metaflow.org
11,What does Metaflow do exactly?,"Metaflow provides a unified API to the whole [infrastructure
 stack](/introduction/why-metaflow) that is required to execute data science projects
 from prototype to production. Take a look at this simple Metaflow flow that illustrates
 the concepts:
 
 ![image](/assets/what-is-metaflow.svg)
 
  - **Modeling**: You can use any Python libraries with Metaflow. Metaflow helps [make
    them available in all environments reliably](/scaling/dependencies).
  - **Deployment**: Metaflow supports highly available, production-grade [workflow
    orchestration and other deployment
    patterns](/production/scheduling-metaflow-flows/introduction/).
  - **Versioning**: Metaflow [keeps track of all flows, experiments, and artifacts
    automatically](/metaflow/basics#artifacts).
  - **Orchestration**: Metaflow makes it easy to [construct workflows and test them
    locally](/metaflow/basics).
  - **Compute**: Metaflow leverages your [cloud account and Kubernetes clusters for
    scalability](/scaling/introduction).
  - **Data**: Besides managing the data flow inside the workflow, Metaflow provides
    patterns for [accessing data from data warehouses and lakes](/scaling/data).
 
 You could use a separate tool for each of these layers but many data scientists prefer
 using a unified, thoughtfully designed library. This also minimizes the operational
 burden for engineers who manage the infrastructure.",H2,https://docs.metaflow.org/introduction/what-is-metaflow#what-does-metaflow-do-exactly,False,1409,189,https://docs.metaflow.org
12,How does Metaflow support prototyping and production use cases?,"Based on our experiences with hundreds of data science and ML projects, we believe that
 projects should grow gradually from quick experiments on the laptop, conducted by a
 single data scientist, to business-critical production deployments developed by a team
 of experts.
 
 In contrast to traditional software engineering, it is hard to assess the value of a
 DS/ML project without running realistic experiments, like backtesting models at scale,
 exposing a prototype to business stakeholders, or running a live A/B test. This should
 be doable without a high upfront cost. When the value of the project has been proven, it
 shouldn't be too hard to take the project all the way to large-scale production.
 
 Here is how Metaflow supports projects throughout this journey (click links in the image
 for more information about specific topics):
 
 <object type=""image/svg+xml"" data=""/assets/metaflow-lifecycle.svg""></object>
 
 A typical project advances through these three stages:
 
  1. [**Prototyping**](/metaflow/introduction): You can [develop and test Metaflow
  workflows locally](/getting-started/install) without having to deploy any
  infrastructure. Making the local development experience fast and smooth is a key to
  productivity.
  2. [**Scaling**](/scaling/introduction): There is only so much data and compute you can
  manage on a laptop. It is very convenient to be able to [test workflows at
  scale](/scaling/introduction) as early as possible. This gives you a good idea of how
  the system is going to behave in production, at no risk.
  3. [**Production**](/production/introduction): A defining feature of any production
  deployment is *high availability*. No matter how the project is deployed to production,
  it shouldn't require any human attention. Metaflow supports this through
  [production-grade workflow
  orchestrators](/production/scheduling-metaflow-flows/introduction), deploying to which
  require no changes in the code. Also, the team needs to be able to continue development
  of [new versions of the project alongside any production
  deployments](/production/coordinating-larger-metaflow-projects) and be able to A/B test
  them easily. And, as you needs grow, you may want to start building larger, [reactive
  systems using individual flows as building blocks](/production/event-triggering).
 
 You can assess the value of the project at every stage before deciding to invest more. A
 core tenet of Metaflow is to make simple things simple and demanding
 production-deployments possible. Read more about the journey from prototype to
 production in [Introduction to Developing with Metaflow](/metaflow/introduction).
 
 Also - don't consider only the happy path! Any real-world project should [account for
 failures](/scaling/failures), consider how the system is
 [monitored](https://github.com/Netflix/metaflow-ui), and provide clear playbooks for
 [debugging issues](/metaflow/debugging) occurring at any point in the project's
 lifecycle, production issues in particular.",H2,https://docs.metaflow.org/introduction/what-is-metaflow#how-does-metaflow-support-prototyping-and-production-use-cases,False,3026,425,https://docs.metaflow.org
13,Is Metaflow easy to deploy and operate?,"You can get started with local development [by `pip` installing
 Metaflow](/getting-started/install) like any other Python library. To benefit from
 scaling and production features of Metaflow, you need to [deploy Metaflow to your cloud
 account or Kubernetes cluster](/getting-started/infrastructure) which can be done using
 [our Terraform or Cloudformation
 templates](https://outerbounds.com/docs/engineering-welcome/) which shouldn't take more
 than 15-30 minutes, unless you want to customize the setup. Take a look at [an overview
 of Metaflow infrastructure](/getting-started/infrastructure) for more information.
 
 In general, engineering teams like Metaflow as it integrates well with the company's
 existing infrastructure instead of introducing major new components. Metaflow works with
 all the major cloud providers: AWS, Azure, and GCP. It provides native,
 thoroughly-tested integrations to popular systems like [AWS
 Batch](https://aws.amazon.com/batch/), [AWS Step
 Functions](https://aws.amazon.com/step-functions/),
 [Kubernetes](https://kubernetes.io/), [Argo
 Workflows](https://argoproj.github.io/argo-workflows/), and [Apache
 Airflow](https://airflow.apache.org/).
 
 Many teams find it comforting to know that Metaflow has been used for serious,
 large-scale production use cases involving tens of thousands of flows and millions of
 runs for more than four years, so the codebase is extremely well tested and
 battle-hardened. Also, we provide [a strong guarantee of backwards compatibility for the
 user-facing API](/api), so you get to stand on a solid foundation.",H2,https://docs.metaflow.org/introduction/what-is-metaflow#is-metaflow-easy-to-deploy-and-operate,False,1594,192,https://docs.metaflow.org
14,Should I Use Metaflow?,"If you are working on an existing project dealing with data and compute, or you are
 planning to start a new one, consider the following questions:
 
 1. **Scalability**: Do you need more than one laptop-size computer in the project?
 2. **Criticality**: Is it important that results are produced correctly and in a timely
    manner?
 3. **Complexity**: Does the project have many moving pieces or many people working
    together?
 
 If you answered ""yes"" to any of the above, keep on reading - Metaflow can help you! If
 the answer is ""no"" to all of the above, Metaflow doesn't provide much benefit. This is a
 valid scenario, for instance, when you are hacking small-scale experiments in a
 notebook. You should come back when the project is ready to move to the next stage.
 
 When the time is right, moving from notebooks-only to
 [notebooks-with-Metaflow](/metaflow/client) should be a smooth sailing. Metaflow is
 designed to be user-friendly and welcoming to all data scientists, novice and experts
 alike, who want to start building end-to-end applications more independently.",H2,https://docs.metaflow.org/introduction/what-is-metaflow#should-i-use-metaflow,False,1086,180,https://docs.metaflow.org
15,Metaflow Resources,"Here's an incomplete overview of Metaflow resources outside this documentation. [Let us
 know on Slack](http://slack.outerbounds.co) or [open a pull
 request](https://github.com/netflix/metaflow-docs) if you find or, even better, create a
 resource that should be listed here 🤗",H1,https://docs.metaflow.org/introduction/metaflow-resources#metaflow-resources,False,277,35,https://docs.metaflow.org
16,Community,"- Join [the Metaflow Slack](http://slack.outerbounds.co) to meet the developers and
    users of Metaflow across hundreds of companies.
  - Report [issues on GitHub](https://github.com/netflix/metaflow/issues).
  - You can also email us at [help@metaflow.org](mailto://help@metaflow.org).",H2,https://docs.metaflow.org/introduction/metaflow-resources#community,False,288,35,https://docs.metaflow.org
17,Deployment & Operations,"- A comprehensive guide to [deploying and operating the infrastructure for
    Metaflow](https://outerbounds.com/docs/engineering-welcome/).",H2,https://docs.metaflow.org/introduction/metaflow-resources#deployment-operations,False,140,15,https://docs.metaflow.org
18,Tutorials,"- [Getting started with Metaflow tutorial](/getting-started/tutorials), a part of this
    documentation.
  - [Additional tutorials](https://outerbounds.com/docs/intro-tutorial-overview/),
    provided by Outerbounds.
  - [Metaflow how-to guides](https://outerbounds.com/docs/data-science-welcome/) for tips
    & tricks.",H2,https://docs.metaflow.org/introduction/metaflow-resources#tutorials,False,321,36,https://docs.metaflow.org
19,Books,"- [Effective Data Science
    Infrastructure](https://www.manning.com/books/effective-data-science-infrastructure):
    Learn to design and develop the full infrastructure stack for data science using
    Metaflow.",H2,https://docs.metaflow.org/introduction/metaflow-resources#books,False,214,28,https://docs.metaflow.org
20,Videos,"- [Metaflow on YouTube](https://www.youtube.com/results?search_query=metaflow+ml).
  - You can start with [this recent
    overview](https://www.youtube.com/watch?v=gZnhSHvhuFQ).",H2,https://docs.metaflow.org/introduction/metaflow-resources#videos,False,178,16,https://docs.metaflow.org
21,Blogs,"- 23andMe: [Developing safe and reliable ML products at
    23andMe](https://medium.com/23andme-engineering/machine-learning-eeee69d40736)
  - AWS: [Getting started with the open source data science tool Metaflow on
    AWS](https://aws.amazon.com/blogs/opensource/getting-started-with-the-open-source-data-science-tool-metaflow-on-aws/)
  - CNN: [Accelerating ML within
    CNN](https://medium.com/cnn-digital/accelerating-ml-within-cnn-983f6b7bd2eb)
  - Latana: [Brand Tracking with Bayesian Statistics and AWS
    Batch](https://aws.amazon.com/blogs/startups/brand-tracking-with-bayesian-statistics-and-aws-batch/)
  - Netflix: [Open-Sourcing Metaflow, a Human-Centric Framework for Data
    Science](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9)
  - Netflix: [Unbundling Data Science Workflows with Metaflow and AWS Step
    Functions](https://netflixtechblog.com/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280)
  - Netflix: [Open-Sourcing a Monitoring GUI for Metaflow, Netflix’s ML
    Platform](https://netflixtechblog.com/open-sourcing-a-monitoring-gui-for-metaflow-75ff465f0d60)
  - Netflix: [Supporting content decision makers with machine
    learning](https://netflixtechblog.com/supporting-content-decision-makers-with-machine-learning-995b7b76006f)
  - Netflix: [Scaling Media Machine Learning at
    Netflix](https://netflixtechblog.com/scaling-media-machine-learning-at-netflix-f19b400243)
  - Outerbounds: [Various articles about Metaflow](https://outerbounds.com/blog/)
  - REA: [Accelerating experimentation with
    MLOps](https://www.rea-group.com/about-us/news-and-insights/blog/accelerating-experimentation-with-mlops/)
  - Realtor.com: [Improving Data Science Processes to Speed Innovation at
    Realtor.com](https://medium.com/realtor-com-innovation-blog/improving-data-science-processes-to-speed-innovation-at-realtor-com-b6b90fa530dc)
  - SAP: [Train your model in SAP AI Core using the Metaflow-Argo
    plugin](https://blogs.sap.com/2022/04/20/train-your-model-in-sap-ai-core-using-the-metaflow-argo-plugin/)
  - Softlandia: [Distributed data science with Metaflow and Dask in Azure Kubernetes
    Service](https://softlandia.fi/en/blog/distributed-data-science-with-metaflow-and-dask)",H2,https://docs.metaflow.org/introduction/metaflow-resources#blogs,False,2313,191,https://docs.metaflow.org
23,1. Modern businesses are eager to utilize data science and ML,"In the past, data scientists and ML engineers had to rely on a medley of point solutions
 and custom systems to build ML and data science applications.
 
 ![Many data science opportunities](/assets/mf-intro-01.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#1-modern-businesses-are-eager-to-utilize-data-science-and-ml,False,214,32,https://docs.metaflow.org
24,2. What is common in DS/ML applications?,"Applications can be built quicker and more robustly if they stand on a common,
 human-friendly foundation. But what should the foundation cover?
 
 ![A solid foundation for all use cases](/assets/mf-intro-02.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#2-what-is-common-in-ds-ml-applications,False,212,30,https://docs.metaflow.org
25,3. All DS/ML applications use data,"**Data** may come in different shapes and sizes and may be loaded from various data
 stores. However, no matter what data is used, accessing and processing it shouldn't be
 too cumbersome.
 
 ![Data](/assets/mf-intro-03.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#3-all-ds-ml-applications-use-data,False,224,33,https://docs.metaflow.org
26,4. DS/ML applications need to perform computation,"Some applications require a tremendous amount of compute power - think computer vision -
 while some do with less. Regardless of the scale, all applications need to perform
 **computation** reliably. Thanks to cloud computing, data scientists and ML engineers
 should be able to utilize elastic compute resources without friction.
 
 ![Compute](/assets/mf-intro-04.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#4-ds-ml-applications-need-to-perform-computation,False,369,51,https://docs.metaflow.org
27,5. DS/ML applications consists of multiple interconnected parts,"Consider an application that loads data, transforms it, trains a bunch of models,
 chooses the best performing one, runs inference, and writes the results to a database.
 Multi-steps workflows like this are a norm in ML. **A workflow orchestrator** is needed
 to make sure all steps get executed in order, on time.
 
 ![Orchestration](/assets/mf-intro-05.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#5-ds-ml-applications-consists-of-multiple-interconnected-parts,False,359,54,https://docs.metaflow.org
28,6. DS/ML applications evolve over time incrementally,"Rarely a real-world application is built and deployed only once. Instead, a typical
 application is built gradually, through contributions by many people. The project needs
 to be tracked, organized, and **versioned**, which enables systematic and continuous
 improvement over time.
 
 ![Versioning](/assets/mf-intro-06.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#6-ds-ml-applications-evolve-over-time-incrementally,False,324,41,https://docs.metaflow.org
29,7. DS/ML applications produce business value in various ways,"To produce real business value, DS/ML applications can't live in a walled garden. They
 must be integrated with the surrounding systems seamlessly: Some applications enhance
 data in a database, some power internal dashboards or microservices, whereas some power
 user-facing products. There are many such ways to **deploy** ML in production. The more
 valuable the application, the more carefully it needs to be operated and monitored as
 well.
 
 ![Deployment](/assets/mf-intro-07.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#7-ds-ml-applications-produce-business-value-in-various-ways,False,487,69,https://docs.metaflow.org
30,8. DS/ML applications should leverage the best tools available,"For many data scientists and ML engineers, the most rewarding part of the project is
 **modeling**. Using their domain knowledge and expertise, the modeler should be able to
 choose the best tool for the job amongst off-the-shelf libraries, such as PyTorch,
 XGBoost, Scikit Learn, and many others. Or, if necessary, they should be able to use a
 wholly custom approach.
 
 ![Modeling](/assets/mf-intro-08.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#8-ds-ml-applications-should-leverage-the-best-tools-available,False,410,62,https://docs.metaflow.org
31,9. Metaflow covers the full stack of DS/ML infrastructure,"Metaflow was originally created at Netflix, motivated by the realization that data
 scientists and ML engineers need help with all these concerns: Any gaps or friction in
 the stack can slow down the project drastically. Thanks to a common foundation provided
 by Metaflow, data scientists can iterate on ideas quickly and deploy them confidently by
 relying on a well-defined architecture and best practices, shared by everyone in the
 team.
 
 ![Full-stack Metaflow](/assets/mf-intro-09.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#9-metaflow-covers-the-full-stack-of-ds-ml-infrastructure,False,493,72,https://docs.metaflow.org
32,"10. Metaflow takes care of the plumbing, so you can focus on the fun parts","Metaflow provides a robust and user-friendly foundation for a wide spectrum of
 data-intensive applications, including most data science and ML use cases. Data
 scientists and ML engineers who know the basics of Python can build their own
 applications, models, and policies on top of it, while Metaflow takes care of the
 low-level infrastructure: data, compute, orchestration, and versioning.
 
 ![Full stack triangles](/assets/mf-intro-10.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#10-metaflow-takes-care-of-the-plumbing-so-you-can-focus-on-the-fun-parts,False,446,62,https://docs.metaflow.org
33,11. Metaflow relies on systems that engineers know and trust,"Metaflow was designed at Netflix to serve the needs of business-critical ML/DS
 applications. It relies on proven and scalable infrastructure which works for small and
 large organizations alike. Metaflow integrates with all the top clouds as well as with
 Kubernetes and systems around them in a responsible manner. It respects the security and
 other policies of your company, making engineering teams happy too.
 
 ![Existing infrastructure](/assets/mf-intro-11.png)",H3,https://docs.metaflow.org/introduction/why-metaflow#11-metaflow-relies-on-systems-that-engineers-know-and-trust,False,469,66,https://docs.metaflow.org
34,12. Metaflow is used by hundreds of innovative companies,"Today, Metaflow powers thousands of ML/DS applications at innovative companies such as
 [Netflix](https://netflixtechblog.com/supporting-content-decision-makers-with-machine-learning-995b7b76006f),
 [CNN](https://medium.com/cnn-digital/accelerating-ml-within-cnn-983f6b7bd2eb),
 [SAP](https://blogs.sap.com/2022/04/20/train-your-model-in-sap-ai-core-using-the-metaflow-argo-plugin/),
 [23andMe](https://medium.com/23andme-engineering/machine-learning-eeee69d40736),
 [Realtor.com](https://medium.com/realtor-com-innovation-blog/improving-data-science-processes-to-speed-innovation-at-realtor-com-b6b90fa530dc),
 [REA](https://www.rea-group.com/about-us/news-and-insights/blog/accelerating-experimentation-with-mlops/),
 [Coveo](https://outerbounds.com/blog/dataops-mlops-reasonable-organizations/),
 [Latana](https://aws.amazon.com/blogs/startups/brand-tracking-with-bayesian-statistics-and-aws-batch/),
 and hundreds of others across industries. Commercial support for Metaflow is provided by
 [Outerbounds](https://outerbounds.com). To hear first-hand experiences from these
 companies and many others, [join the Metaflow Slack](http://slack.outerbounds.co).",H3,https://docs.metaflow.org/introduction/why-metaflow#12-metaflow-is-used-by-hundreds-of-innovative-companies,False,1160,48,https://docs.metaflow.org
35,Release Notes,"Read below how Metaflow has improved over time.
 
 We take backwards compatibility very seriously. In the vast majority of cases, you can
 upgrade Metaflow without expecting changes in your existing code. In the rare cases when
 breaking changes are absolutely necessary, usually, due to bug fixes, you can take a
 look at minor breaking changes below before you upgrade.
 
 :::info
 
 For the most recent release notes, see [release notes on
 Github](https://github.com/Netflix/metaflow/releases)
 
 :::",H1,https://docs.metaflow.org/internals/release-notes#release-notes,False,504,76,https://docs.metaflow.org
37,"[2.6.0 (Apr 25, 2022)](https://github.com/Netflix/metaflow/releases/tag/2.6.0)","The Metaflow 2.6.0 release is a minor release and introduces Metaflow's integration with
 [Kubernetes](https://docs.metaflow.org/scaling/introduction/effortless-scaling-with-kubernetes)
 and [Argo",H2,https://docs.metaflow.org/internals/release-notes#260-apr-25-2022,False,196,16,https://docs.metaflow.org
38,Add capability to launch Metaflow tasks on Kubernetes and schedule Metaflow flows with Argo Workflows.,"This release enables brand new capabilities for [Metaflow on top of
 Kubernetes](https://outerbounds.com/blog/human-centric-data-science-on-kubernetes-with-metaflow/).
 You can now [`run --with
 kubernetes`](https://docs.metaflow.org/scaling/introduction/effortless-scaling-with-kubernetes)
 all or parts of any Metaflow flow on top of _any_ Kubernetes cluster from your
 workstation. To execute your flow asynchronously, you can deploy the flow to Argo
 Workflows (a Kubernetes-native workflow scheduler) with a single command -
 [`argo-workflows
 create`](https://docs.metaflow.org/production/scheduling-metaflow-flows/introduction/scheduling-with-argo-workflows).
 
 To get started, take a look at the [deployment guide for
 Kubernetes](https://outerbounds.com/docs/engineering-welcome/). Your feedback and
 feature requests are highly appreciated! - please reach out to us at
 slack.outerbounds.co
 
 PR #992 addressed issue #50.",H4,https://docs.metaflow.org/internals/release-notes#add-capability-to-launch-metaflow-tasks-on-kubernetes-and-schedule-metaflow-flows-with-argo-workflows,False,933,93,https://docs.metaflow.org
39,Expose `tags` in `current` object.,"Metaflow tags are now available as part of the `current` singleton object.
 
 ```
 @step
 def my_step(self):
     from metaflow import current
     tags = current.tags
     ...
 ```
 
 PR #1019 fixed issue #1007.",H4,https://docs.metaflow.org/internals/release-notes#expose-tags-in-current-object,False,212,44,https://docs.metaflow.org
45,"[2.4.9 (Jan 18, 2022)](https://github.com/Netflix/metaflow/releases/tag/2.4.9)","The Metaflow 2.4.9 release is a patch release.
 
 * Improvements
   * Store information about the DAG being executed in an artifact. This will allow to
     render execution DAG in a `@card` (
     [#822](https://github.com/Netflix/metaflow/pull/822) )
 * Bug Fixes
   * Fixed cli command when task_id provided (
     [#890](https://github.com/Netflix/metaflow/pull/890) )
   * Fix with metadata syncing on AWS Batch when running without remote metadata service
     ( [#902](https://github.com/Netflix/metaflow/pull/902) )
   * Fix default resource math. Previously we sometimes computed vCPU and memory settings
     incorrectly, in cases when they were set to something less than the default value (
     [#810](https://github.com/Netflix/metaflow/pull/810) , fixes
     [#467](https://github.com/Netflix/metaflow/issues/467) )",H2,https://docs.metaflow.org/internals/release-notes#249-jan-18-2022,False,830,134,https://docs.metaflow.org
52,Add default image config option as described in [489](https://github.com/Netflix/metaflow/issues/489) ([813](https://github.com/Netflix/metaflow/pull/813)),"We're moving to a more consistent scheme for naming options related to docker images.
 You can read the details in [#489](https://github.com/Netflix/metaflow/issues/489), but
 this release introduces new config options `DEFAULT_CONTAINER_IMAGE` and
 `DEFAULT_CONTAINER_REGISTRY` that can be used to specify docker image in addition to
 plugin-specific options like `KUBERNETES_CONTAINER_IMAGE`",H4,https://docs.metaflow.org/internals/release-notes#add-default-image-config-option-as-described-in-489,False,393,46,https://docs.metaflow.org
53,Read default k8s namespace from config ([823](https://github.com/Netflix/metaflow/pull/823)),"This adds a new configuration option to set the default namespace for the Kubernetes
 plugin",H4,https://docs.metaflow.org/internals/release-notes#read-default-k8s-namespace-from-config-823,False,92,15,https://docs.metaflow.org
56,"Fix a race condition when accessing artifacts of a running task ([789](https://github.com/Netflix/metaflow/pull/789)) <a href=""user-content-789"" id=""user-content-789""></a>","When accessing artifacts of a running task using `Task(...).artifacts`, a race condition
 existed and the call could return a difficult to understand error message. This release
 fixes this issue and making this call will either return the artifacts present or no
 artifacts at all if none are present yet.",H4,https://docs.metaflow.org/internals/release-notes#fix-a-race-condition-when-accessing-artifacts-of-a-running-task-789,False,306,49,https://docs.metaflow.org
57,"Fix an issue when using a combination of `@catch` and `@retry` decorators ([776](https://github.com/Netflix/metaflow/pull/776)) <a href=""user-content-776"" id=""user-content-776""></a>","A step as below:
 
 ```python
 @retry(times=2)
 @catch(var='exception')
 @step
 def my_step(self):
     raise ValueError()
 ```
 
 would not retry 2 times as expected but instead the exception would be caught the first
 time around. This release fixes this issue and the step will now execute a total of 3
 times and the exception will be caught on the third time.",H4,https://docs.metaflow.org/internals/release-notes#fix-an-issue-when-using-a-combination-of-catch-and-retry-decorators-776,False,364,63,https://docs.metaflow.org
58,"Upgrade Pandas in tutorials ([707](https://github.com/Netflix/metaflow/pull/707)) <a href=""user-content-707"" id=""user-content-707""></a>","On macOS Big Sur, certain tutorials were broken due to using an older version of Pandas.
 This updates the tutorials to use 1.3.3 to solve this issue",H4,https://docs.metaflow.org/internals/release-notes#upgrade-pandas-in-tutorials-707,False,149,27,https://docs.metaflow.org
61,Fix a bug with accessing legacy logs through `metaflow.client` ([779](https://github.com/Netflix/metaflow/pull/779)),"Metaflow `v2.4.1` introduced a bug (due to a typo) in accessing legacy task logs through
 `metaflow.client`
 
 ```
 Task(""pathspec/to/task"").stdout
 ```
 
 This release fixes this issue.",H4,https://docs.metaflow.org/internals/release-notes#fix-a-bug-with-accessing-legacy-logs-through-metaflowclient-779,False,186,26,https://docs.metaflow.org
62,Fix a bug with task datastore access when no task attempt has been recorded ([780](https://github.com/Netflix/metaflow/pull/780)),"A subtle bug was introduced in Metaflow `2.4.0` where the task datastore access fails
 when no task attempt was recorded. This release fixes this issue.",H4,https://docs.metaflow.org/internals/release-notes#fix-a-bug-with-task-datastore-access-when-no-task-attempt-has-been-recorded-780,False,152,25,https://docs.metaflow.org
65,Expose non-pythonic dependencies inside the conda environment on AWS Batch ([735](https://github.com/Netflix/metaflow/pull/735)),"Prior to this release, non-pythonic dependencies in a conda environment were not
 automatically visible to a Metaflow task executing on AWS Batch (see
 [#734](https://github.com/Netflix/metaflow/issues/734)) (they were available for tasks
 that were executed locally). For example
 
 ```python
 import os
 from metaflow import FlowSpec, step, conda, conda_base, batch
 
 class TestFlow(FlowSpec):
 
     @step
     def start(self):
         self.next(self.use_node)
 
     @batch
     @conda(libraries={""nodejs"": "">=16.0.0""})
     @step
     def use_node(self):
         print(os.system(""node --version""))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 
 if __name__ == ""__main__"":
     TestFlow()
 ```
 
 would print an error. This release fixes the issue with the incorrect `PATH`
 configuration.",H4,https://docs.metaflow.org/internals/release-notes#expose-non-pythonic-dependencies-inside-the-conda-environment-on-aws-batch-735,False,830,161,https://docs.metaflow.org
67,Introduce size properties for artifacts and logs in metaflow.client ([752](https://github.com/Netflix/metaflow/pull/752)),"This release exposes size properties for artifacts and logs (stderr and stdout) in
 metaflow.client. These properties are relied upon by the Metaflow UI ([open-sourcing
 soon!](https://www.eventbrite.fi/e/netflix-data-science-metaflow-gui-pre-release-meetup-tickets-185523605097)).",H4,https://docs.metaflow.org/internals/release-notes#introduce-size-properties-for-artifacts-and-logs-in-metaflowclient-752,False,281,25,https://docs.metaflow.org
68,Expose attempt level task properties ([725](https://github.com/Netflix/metaflow/pull/725)),"In addition to the above mentioned properties, now users of Metaflow can access attempt
 specific Task metadata using the client
 
 ```
 Task('42/start/452', attempt=1)
 ```",H4,https://docs.metaflow.org/internals/release-notes#expose-attempt-level-task-properties-725,False,173,25,https://docs.metaflow.org
69,Introduce @kubernetes decorator for launching Metaflow tasks on Kubernetes ([644](https://github.com/Netflix/metaflow/pull/644)),"This release marks the alpha launch of `@kubernetes` decorator that allows farming off
 Metaflow tasks onto Kubernetes. The functionality works in exactly the same manner as
 [`@batch`](/scaling/remote-tasks/introduction) -
 
 ```python
 from metaflow import FlowSpec, step, resources
 
 class BigSum(FlowSpec):
 
     @resources(memory=60000, cpu=1)
     @step
     def start(self):
         import numpy
         import time
         big_matrix = numpy.random.ranf((80000, 80000))
         t = time.time()
         self.sum = numpy.sum(big_matrix)
         self.took = time.time() - t
         self.next(self.end)
 
     @step
     def end(self):
         print(""The sum is %f."" % self.sum)
         print(""Computing it took %dms."" % (self.took * 1000))
 
 if __name__ == '__main__':
     BigSum()
 ```
 
 ```
 python big_sum.py run --with kubernetes
 ```
 
 will run all steps of this workflow on your existing EKS cluster (which can be
 configured with `metaflow configure eks`) and provides all the goodness of Metaflow!
 
 To get started follow [this
 guide](https://docs.google.com/document/d/1L_4Fws1KoGg_dtSTaRlAcREX1F8FPS4ZaYk7eJyu_jA/edit)!
 We would appreciate your early feedback at
 [http://slack.outerbounds.co](htps://slack.outerbounds.co).",H4,https://docs.metaflow.org/internals/release-notes#introduce-kubernetes-decorator-for-launching-metaflow-tasks-on-kubernetes-644,False,1256,237,https://docs.metaflow.org
70,"[2.4.0 (Oct 4th, 2021)](https://github.com/Netflix/metaflow/releases/tag/2.4.0)",The Metaflow 2.4.0 release is a minor release and includes a _breaking change_,H2,https://docs.metaflow.org/internals/release-notes#240-oct-4th-2021,False,78,13,https://docs.metaflow.org
72,Change return type of created_at/finished_at in the client ([692](https://github.com/Netflix/metaflow/pull/692)),"Prior to this release, the return type for `created_at` and `finished_at` properties in
 the Client API was a timestamp string. This release changes this to a `datetime` object,
 as the old behavior is considered an unintentional mis-feature (see below for details).
 
 _How to retain the old behavior_
 
 To keep the old behavior, append an explicit string conversion,
 `.strftime('%Y-%m-%dT%H:%M:%SZ')`, to the `created_at` and `finished_at` calls, e.g.
 
 ```
 run.created_at.strftime('%Y-%m-%dT%H:%M:%SZ')
 ```
 
 _Background_
 
 The first versions of Metaflow (internal to Netflix) returned a `datetime` object in all
 calls dealing with timestamps in the Client API to make it easier to perform operations
 between timestamps. Unintentionally, the return type was changed to string in the
 initial open-source release. This release introduces a number of internal changes,
 removing all remaining discrepancies between the legacy version of Metaflow that was
 used inside Netflix and the open-source version.
 
 The timestamp change is the only change affecting the user-facing API. While Metaflow
 continues to make a strong promise of backwards compatibility of user-facing features
 and APIs, the benefits of one-time unification outweigh the cost of this relatively
 minor breaking change.",H4,https://docs.metaflow.org/internals/release-notes#change-return-type-of-created-at-finished-at-in-the-client-692,False,1299,187,https://docs.metaflow.org
74,Better error messages in case of a Conda issue ([706](https://github.com/Netflix/metaflow/pull/706)),"Conda errors printed to `stderr` were not surfaced to the user; this release addresses
 this issue.",H4,https://docs.metaflow.org/internals/release-notes#better-error-messages-in-case-of-a-conda-issue-706,False,99,16,https://docs.metaflow.org
75,Fix error message in Metadata service ([712](https://github.com/Netflix/metaflow/pull/712)),"The code responsible for printing error messages from the metadata service had a problem
 that could cause it to be unable to print the correct error message and would instead
 raise another error that obfuscated the initial error. This release addresses this issue
 and errors from the metadata service are now properly printed.",H4,https://docs.metaflow.org/internals/release-notes#fix-error-message-in-metadata-service-712,False,329,53,https://docs.metaflow.org
77,S3 retry counts are now configurable ([700](https://github.com/Netflix/metaflow/pull/700)),"This release allows you to set the number of times S3 access are retried (the default is
 7). The relevant environment variable is: `METAFLOW_S3_RETRY_COUNT`.",H4,https://docs.metaflow.org/internals/release-notes#s3-retry-counts-are-now-configurable-700,False,158,24,https://docs.metaflow.org
78,New datastore implementation resulting in improved performance ([580](https://github.com/Netflix/metaflow/pull/580)),"The datastore implementation was reworked to make it easier to extend in the future. It
 also now uploads artifacts in parallel to S3 (as opposed to sequentially) which can lead
 to better performance. The changes also contribute to a notable improvement in the speed
 of `resume` which can now start resuming a flow twice as fast as before. Documentation
 can be found [here](https://github.com/Netflix/metaflow/blob/master/docs/datastore.md).",H4,https://docs.metaflow.org/internals/release-notes#new-datastore-implementation-resulting-in-improved-performance-580,False,444,63,https://docs.metaflow.org
79,S3 datatools performance improvements ([697](https://github.com/Netflix/metaflow/pull/697)),"The S3 datatools better handles small versus large files by using the `download_file`
 command for larger files and using `get_object` for smaller files to minimize the number
 of calls made to S3.",H4,https://docs.metaflow.org/internals/release-notes#s3-datatools-performance-improvements-697,False,197,32,https://docs.metaflow.org
82,[Fix recursion error when `METAFLOW_DEFAULT_ENVIRONMENT` is set to `conda`](https://github.com/Netflix/metaflow/releases673),"Prior to this release, setting default execution environment to `conda` through
 `METAFLOW_DEFAULT_ENVIRONMENT` would result in a recursion error.
 
 ```
 METAFLOW_DEFAULT_ENVIRONMENT=conda python flow.py run
 ```
 
 ```
   File ""/Users/savin/Code/metaflow/metaflow/cli.py"", line 868, in start
     if e.TYPE == environment][0](ctx.obj.flow)
   File ""/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py"", line 27, in __init__
     if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)
   File ""/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py"", line 27, in __init__
     if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)
   File ""/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py"", line 27, in __init__
     if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)
   [Previous line repeated 488 more times]
   File ""/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py"", line 24, in __init__
     from ...plugins import ENVIRONMENTS
 RecursionError: maximum recursion depth exceeded
 ```
 
 This release fixes this bug.",H4,https://docs.metaflow.org/internals/release-notes#fix-recursion-error-when-metaflow-default-environment-is-set-to-conda,False,1083,127,https://docs.metaflow.org
83,[Allow dots in `host_volumes` attribute for `@batch` decorator](https://github.com/Netflix/metaflow/releases676),"Dots in volume names - `@batch(host_volumes='/path/with/.dot')` weren't being sanitized
 properly resulting in errors when a Metaflow task launched on AWS Batch. This release
 fixes this bug.",H4,https://docs.metaflow.org/internals/release-notes#allow-dots-in-host-volumes-attribute-for-batch-decorator,False,191,26,https://docs.metaflow.org
86,[Enable mounting host volumes in AWS Batch](https://github.com/Netflix/metaflow/issues/441),"With this release, you can now [mount and access instance host
 volumes](https://aws.amazon.com/premiumsupport/knowledge-center/batch-mount-efs/) within
 a Metaflow task running on AWS Batch. To access a host volume, you can add
 `host-volumes` argument to your `@batch` decorator -
 
 ```
 @batch(host_volumes=['/home', '/var/log'])
 ```",H4,https://docs.metaflow.org/internals/release-notes#enable-mounting-host-volumes-in-aws-batch,False,338,40,https://docs.metaflow.org
88,[Fix input values for Parameters of type `list` within a Metaflow Foreach task](https://github.com/Netflix/metaflow/issues/651),"The following flow had a bug where the value for `self.input` was being imputed to
 `None` rather than the dictionary element. This release fixes this issue -
 
 ```python
 from metaflow import FlowSpec, Parameter, step, JSONType
 
 class ForeachFlow(FlowSpec):
     numbers_param = Parameter(
         ""numbers_param"",
         type=JSONType,
         default='[1,2,3]'
     )
 
     @step
     def start(self):
         # This works, and passes each number to the run_number step:
         #
         # self.numbers = self.numbers_param
         # self.next(self.run_number, foreach='numbers')
 
         # But this doesn't:
         self.next(self.run_number, foreach='numbers_param')
 
     @step
     def run_number(self):
         print(f""number is {self.input}"")
         self.next(self.join)
 
     @step
     def join(self, inputs):
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     ForeachFlow()
 ```",H4,https://docs.metaflow.org/internals/release-notes#fix-input-values-for-parameters-of-type-list-within-a-metaflow-foreach-task,False,971,250,https://docs.metaflow.org
91,[Fix execution of `step-functions create` when using an `IncludeFile` parameter](https://github.com/Netflix/metaflow/releases637),"PR [#607](https://github.com/Netflix/metaflow/pull/607) in `Metaflow 2.3.3` introduced a
 bug with `step-functions create` command for `IncludeFile` parameters. This release
 rolls back that PR. A subsequent release will reintroduce a modified version of PR
 [#607](https://github.com/Netflix/metaflow/pull/607).",H4,https://docs.metaflow.org/internals/release-notes#fix-execution-of-step-functions-create-when-using-an-includefile-parameter,False,312,32,https://docs.metaflow.org
94,[Support resource tags for Metaflow's integration with AWS Batch](https://github.com/Netflix/metaflow/releases632),"Metaflow now supports setting [resource tags for AWS Batch
 jobs](https://docs.aws.amazon.com/batch/latest/userguide/using-tags.html) and
 propagating them to the underlying ECS tasks. The following tags are attached to the AWS
 Batch jobs now -",H4,https://docs.metaflow.org/internals/release-notes#support-resource-tags-for-metaflow-s-integration-with-aws-batch,False,245,30,https://docs.metaflow.org
96,[Properly handle `None` as defaults for parameters for AWS Step Functions execution](https://github.com/Netflix/metaflow/releases630),"Prior to this release, a parameter specification like -
 
 ```
 Parameter(name=""test_param"", type=int, default=None)
 ```
 
 will result in an error even though the default has been specified
 
 ```
 Flow failed:
     The value of parameter test_param is ambiguous. It does not have a default and it is not required.
 ```
 
 This release fixes this behavior by allowing the flow to execute as it would locally.",H4,https://docs.metaflow.org/internals/release-notes#properly-handle-none-as-defaults-for-parameters-for-aws-step-functions-execution,False,410,71,https://docs.metaflow.org
97,[Fix return value of `IncludeFile` artifacts](https://github.com/Netflix/metaflow/releases607),"The `IncludeFile` parameter would return JSONified metadata about the file rather than
 the file contents when accessed through the `Metaflow Client`. This release fixes that
 behavior by returning instead the file contents, just like any other Metaflow data
 artifact.",H4,https://docs.metaflow.org/internals/release-notes#fix-return-value-of-includefile-artifacts,False,269,39,https://docs.metaflow.org
99,Features,"**`step-functions trigger` command now supports `--run-id-file` option**
 
 Similar to `run` , you can now pass `--run-id-file` option to `step-function trigger`.
 Metaflow then will write the triggered run id to the specified file. This is useful if
 you have additional scripts that require the run id to examine the run or wait until it
 finishes.",H3,https://docs.metaflow.org/internals/release-notes#features,False,350,55,https://docs.metaflow.org
101,Features,"[**Performance optimizations for
 `merge_artifacts`**](https://github.com/Netflix/metaflow/releases/tag/2.3.1#556)
 
 Prior to this release, `FlowSpec.merge_artifacts` was loading all of the merged
 artifacts into memory after doing all of the consistency checks with hashes. This
 release now avoids the memory and compute costs of decompressing, de-pickling,
 re-pickling, and recompressing each merged artifact - resulting in improved performance
 of `merge_artifacts`.",H3,https://docs.metaflow.org/internals/release-notes#features,False,472,53,https://docs.metaflow.org
104,[Coordinate larger Metaflow projects with `@project`](../production/coordinating-larger-metaflow-projects),"It's not uncommon for multiple people to work on the same workflow simultaneously.
 Metaflow makes it possible by keeping executions [isolated through independently stored
 artifacts and namespaces](../scaling/tagging). However, by default, [all AWS Step
 Functions deployments](../production/scheduling-metaflow-flows/introduction) are bound
 to the name of the workflow. If multiple people call `step-functions create`
 independently, each deployment will overwrite the previous one. In the early stages of a
 project, this simple model is convenient but as the project grows, it is desirable that
 multiple people can test their own AWS Step Functions deployments without interference.
 Or, as a single developer, you may want to experiment with multiple independent AWS Step
 Functions deployments of their workflow. This release introduces a `@project` decorator
 to address this need. The `@project` decorator is used at the `FlowSpec`-level to bind a
 Flow to a specific project. All flows with the same project name belong to the same
 project.
 
 ```python
 from metaflow import FlowSpec, step, project, current
 
 @project(name='example_project')
 class ProjectFlow(FlowSpec):
 
     @step
     def start(self):
         print('project name:', current.project_name)
         print('project branch:', current.branch_name)
         print('is this a production run?', current.is_production)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     ProjectFlow()
 ```
 
 ```
 python flow.py run
 ```
 
 The flow works exactly as before when executed outside AWS Step Functions and introduces
 `project_name`, `branch_name` & `is_production` in the
 [`current`](../scaling/tagging#accessing-current-ids-in-a-flow) object.
 
 On AWS Step Functions, however, `step-functions create` will create a new workflow
 `example_project.user.username.ProjectFlow` (where `username` is your username) with a
 user-specific [isolated namespace](../scaling/tagging) and a [separate production
 token](../scaling/tagging#production-tokens).
 
 For deploying experimental (test) versions that can run in parallel with production, you
 can deploy custom branches with `--branch`
 
 ```
 python flow.py --branch foo step-functions create
 ```
 
 To deploy a production version, you can deploy with `--production` flag (or pair it up
 with `--branch` if you want to run multiple variants in production)
 
 ```
 python project_flow.py --production step-functions create
 ```
 
 Note that the isolated namespaces offered by `@project` work best when your code is
 designed to respect these boundaries. For instance, when writing results to a table, you
 can use current.branch_name to choose the table to write to or you can disable writes
 outside production by checking current.is_production.",H4,https://docs.metaflow.org/internals/release-notes#coordinate-larger-metaflow-projects-with-project-production-coordinating-larger-metaflow-projects,False,2832,421,https://docs.metaflow.org
105,Hyphenated-parameters support in AWS Step Functions,"Prior to this release, hyphenated parameters in AWS Step Functions weren't supported
 through CLI.
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 
 class ParameterFlow(FlowSpec):
     foo_bar = Parameter('foo-bar',
                       help='Learning rate',
                       default=0.01)
 
     @step
     def start(self):
         print('foo_bar is %f' % self.foo_bar)
         self.next(self.end)
 
     @step
     def end(self):
         print('foo_bar is still %f' % self.foo_bar)
 
 if __name__ == '__main__':
     ParameterFlow()
 ```
 
 Now, users can create their flows as usual on AWS Step Functions (with `step-functions
 create`) and trigger the deployed flows through CLI with hyphenated parameters -
 
 ```
 python flow.py step-functions trigger --foo-bar 42
 ```",H4,https://docs.metaflow.org/internals/release-notes#hyphenated-parameters-support-in-aws-step-functions,False,800,186,https://docs.metaflow.org
106,State Machine execution history logging for AWS Step Functions,"Metaflow now logs [State Machine execution history in AWS CloudWatch
 Logs](https://docs.aws.amazon.com/step-functions/latest/dg/cw-logs.html) for deployed
 Metaflow flows. You can enable it by specifying `--log-execution-history` flag while
 creating the state machine
 
 ```
 python flow.py step-functions create --log-execution-history
 ```
 
 Note that you would need to set the environment variable (or alternatively in your
 Metaflow config) `METAFLOW_SFN_EXECUTION_LOG_GROUP_ARN` to your AWS CloudWatch Logs Log
 Group ARN to pipe the execution history logs to AWS CloudWatch Logs",H4,https://docs.metaflow.org/internals/release-notes#state-machine-execution-history-logging-for-aws-step-functions,False,587,72,https://docs.metaflow.org
109,[Handle regression with `@batch` execution on certain docker images](https://github.com/Netflix/metaflow/releases/tag/2.2.13534),"Certain [docker
 images](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html)
 override the entrypoint by executing `eval` on the user-supplied command. The `2.2.10`
 release impacted these docker images where we modified the entrypoint to support
 datastore based logging. This release fixes that regression.",H4,https://docs.metaflow.org/internals/release-notes#handle-regression-with-batch-execution-on-certain-docker-images,False,356,35,https://docs.metaflow.org
112,[Add capability to override AWS Step Functions state machine name while deploying flows to AWS Step Functions](https://github.com/Netflix/metaflow/releases/tag/2.2.12532),"Prior to this release, the State Machines created by Metaflow while deploying flows to
 AWS Step Functions had the same name as that of the flow. With this release, Metaflow
 users can now override the name of the State Machine created by passing in a `--name`
 argument : `python flow.py step-functions --name foo create` or `python flow.py
 step-functions --name foo trigger`.",H4,https://docs.metaflow.org/internals/release-notes#add-capability-to-override-aws-step-functions-state-machine-name-while-deploying-flows-to-aws-step-functions,False,378,61,https://docs.metaflow.org
113,[Introduce heartbeats for Metaflow flows](https://github.com/Netflix/metaflow/releases/tag/2.2.12333),"Metaflow now registers heartbeats at the run level and the task level for all flow
 executions (with the exception of flows running on AWS Step Functions where only
 task-level heartbeats are captured). This provides the necessary metadata to ascertain
 if a run/task has been lost. Subsequent releases of Metaflow will expose this
 information through the client.",H4,https://docs.metaflow.org/internals/release-notes#introduce-heartbeats-for-metaflow-flows,False,364,56,https://docs.metaflow.org
115,[Handle regression with `Click >=8.0.x`](https://github.com/Netflix/metaflow/releases/tag/2.2.12526),"The latest release of Click (8.0.0) broke certain idempotency assumptions in Metaflow
 which PR [#526](https://github.com/Netflix/metaflow/pull/526) addresses.",H4,https://docs.metaflow.org/internals/release-notes#handle-regression-with-click-80x,False,159,16,https://docs.metaflow.org
118,Fix regression that broke compatibility with Python 2.7,"`shlex.quote`, introduced in #493, is not compatible with Python 2.7. `pipes.quote` is
 now used for Python 2.7.",H4,https://docs.metaflow.org/internals/release-notes#fix-regression-that-broke-compatibility-with-python-27,False,112,17,https://docs.metaflow.org
121,"AWS Logs Group, Region and Stream are now available in metadata for tasks executed on AWS Batch","For tasks that execute on AWS Batch, Metaflow now records the location where the AWS
 Batch instance writes the container logs in AWS Logs. This can be handy in locating the
 logs through the client API -
 
 ```
 Step('Flow/42/a').task.metadata_dict['aws-batch-awslogs-group']
 Step('Flow/42/a').task.metadata_dict['aws-batch-awslogs-region']
 Step('Flow/42/a').task.metadata_dict['aws-batch-awslogs-stream']
 ```",H4,https://docs.metaflow.org/internals/release-notes#aws-logs-group-region-and-stream-are-now-available-in-metadata-for-tasks-executed-on-aws-batch,False,413,43,https://docs.metaflow.org
122,Execution logs are now available for all tasks in Metaflow universe,"All Metaflow runtime/task logs are now published via a sidecar process to the datastore.
 The user-visible logs on the console are streamed directly from the datastore. For
 Metaflow's integrations with the cloud (AWS at the moment), the compute tasks logs (AWS
 Batch) are directly written by Metaflow into the datastore (Amazon S3) independent of
 where the flow is launched from (User's laptop or AWS Step Functions). This has multiple
 benefits",H4,https://docs.metaflow.org/internals/release-notes#execution-logs-are-now-available-for-all-tasks-in-metaflow-universe,False,448,70,https://docs.metaflow.org
124,Fix regression with `ping/` endpoint for Metadata service,"Fix a regression introduced in `v2.2.9` where the endpoint responsible for ascertaining
 the version of the deployed Metadata service was erroneously moved to `ping/` from
 `ping`",H4,https://docs.metaflow.org/internals/release-notes#fix-regression-with-ping-endpoint-for-metadata-service,False,179,26,https://docs.metaflow.org
125,[Fix the behaviour of `--namespace=` CLI args when executing a flow](https://gitter.im/metaflow_org/community?at=605decca68921b62f48a4190),"`python flow.py run --namespace=` now correctly makes the global namespace visible
 within the flow execution.",H4,https://docs.metaflow.org/internals/release-notes#fix-the-behaviour-of-namespace-cli-args-when-executing-a-flow-https-gitterim-metaflow-org-community-at605decca68921b62f48a4190,False,110,15,https://docs.metaflow.org
129,[Improve handling of `/` in image parameter for batch](https://gitter.im/metaflow_org/community?at=5f80e21d02e81701b0106c6d),"You are now able to specify docker images of the form `foo/bar/baz:tag` in the batch
 decorator. See PR [#466](https://github.com/Netflix/metaflow/pull/466).",H4,https://docs.metaflow.org/internals/release-notes#improve-handling-of-in-image-parameter-for-batch-https-gitterim-metaflow-org-community-at5f80e21d02e81701b0106c6d,False,157,19,https://docs.metaflow.org
130,List custom FlowSpec parameters in the intended order,"The order in which parameters are specified by the user in the FlowSpec is now preserved
 when displaying them with `--help`. See PR
 [#456](https://github.com/Netflix/metaflow/pull/456).",H4,https://docs.metaflow.org/internals/release-notes#list-custom-flowspec-parameters-in-the-intended-order,False,187,24,https://docs.metaflow.org
133,[Fix `@environment` behavior for conflicting attribute values](https://gitter.im/metaflow_org/community?at=604a2bfb44f5a454a46cc7f8),"Metaflow was incorrectly handling environment variables passed through the
 `@environment` decorator in some specific instances. When `@environment` decorator is
 specified over multiple steps, the actual environment that's available to any step is
 the union of attributes of all the `@environment` decorators; which is incorrect
 behavior. For example, in the following workflow -
 
 ```python
 from metaflow import FlowSpec, step, batch, environment
 import os
 class LinearFlow(FlowSpec):
     @environment(vars={'var':os.getenv('var_1')})
     @step
     def start(self):
         print(os.getenv('var'))
         self.next(self.a)
     @environment(vars={'var':os.getenv('var_2')})
     @step
     def a(self):
         print(os.getenv('var'))
         self.next(self.end)
     @step
     def end(self):
         pass
 if __name__ == '__main__':
     LinearFlow()
 ```
 
 ```
 var_1=foo var_2=bar python flow.py run
 ```
 
 will result in
 
 ```
 Metaflow 2.2.7.post10+gitb7d4c48 executing LinearFlow for user:savin
 Validating your flow...
     The graph looks good!
 Running pylint...
     Pylint is happy!
 2021-03-12 20:46:04.161 Workflow starting (run-id 6810):
 2021-03-12 20:46:04.614 [6810/start/86638 (pid 10997)] Task is starting.
 2021-03-12 20:46:06.783 [6810/start/86638 (pid 10997)] foo
 2021-03-12 20:46:07.815 [6810/start/86638 (pid 10997)] Task finished successfully.
 2021-03-12 20:46:08.390 [6810/a/86639 (pid 11003)] Task is starting.
 2021-03-12 20:46:10.649 [6810/a/86639 (pid 11003)] foo
 2021-03-12 20:46:11.550 [6810/a/86639 (pid 11003)] Task finished successfully.
 2021-03-12 20:46:12.145 [6810/end/86640 (pid 11009)] Task is starting.
 2021-03-12 20:46:15.382 [6810/end/86640 (pid 11009)] Task finished successfully.
 2021-03-12 20:46:15.563 Done!
 ```
 
 Note the output for the step `a` which should have been `bar`. PR
 [#452](https://github.com/Netflix/metaflow/pull/452) fixes the issue.",H4,https://docs.metaflow.org/internals/release-notes#fix-environment-behavior-for-conflicting-attribute-values-https-gitterim-metaflow-org-community-at604a2bfb44f5a454a46cc7f8,False,1926,291,https://docs.metaflow.org
134,[Fix `environment is not callable` error when using `@environment`](https://gitter.im/metaflow_org/community?at=6048a07d823b6654d296d62d),"Using `@environment` would often result in an error from `pylint` - `E1102: environment
 is not callable (not-callable)`. Users were getting around this issue by launching their
 flows with `--no-pylint`. PR [#451](https://github.com/Netflix/metaflow/pull/451) fixes
 this issue.",H4,https://docs.metaflow.org/internals/release-notes#fix-environment-is-not-callable-error-when-using-environment-https-gitterim-metaflow-org-community-at6048a07d823b6654d296d62d,False,279,34,https://docs.metaflow.org
137,[Handle for-eaches properly for AWS Step Functions workflows running on AWS Fargate](https://gitter.im/metaflow_org/community?at=601f56d955359c58bf28ef1a),"Workflows orchestrated by AWS Step Functions were failing to properly execute `for-each`
 steps on AWS Fargate. The culprit was lack of access to instance metadata for ECS.
 Metaflow instantiates a connection to Amazon DynamoDB to keep track of `for-each`
 cardinality. This connection requires knowledge of the region that the job executes in
 and is made available via [instance
 metadata](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html)
 on EC2; which unfortunately is not available on ECS (for AWS Fargate). This fix
 introduces the necessary checks for inferring the region correctly for tasks executing
 on AWS Fargate. Note that after the recent changes to [Amazon S3's consistency
 model](https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/),
 the Amazon DynamoDB dependency is no longer needed and will be done away in a subsequent
 release. PR: [#436](https://github.com/Netflix/metaflow/pull/436)",H4,https://docs.metaflow.org/internals/release-notes#handle-for-eaches-properly-for-aws-step-functions-workflows-running-on-aws-fargate-https-gitterim-metaflow-org-community-at601f56d955359c58bf28ef1a,False,974,118,https://docs.metaflow.org
140,Support AWS Fargate as compute backend for Metaflow tasks launched on AWS Batch,"At [AWS re:invent 2020, AWS announced support for AWS
 Fargate](https://aws.amazon.com/blogs/aws/new-fully-serverless-batch-computing-with-aws-batch-support-for-aws-fargate/)
 as a compute backend (in addition to EC2) for AWS Batch. With this feature, Metaflow
 users can now submit their Metaflow jobs to AWS Batch Job Queues which are connected to
 AWS Fargate Compute Environments as well. By setting the environment variable -
 `METAFLOW_ECS_FARGATE_EXECUTION_ROLE`, users can configure the ecsTaskExecutionRole for
 the AWS Batch container and AWS Fargate agent.",H4,https://docs.metaflow.org/internals/release-notes#support-aws-fargate-as-compute-backend-for-metaflow-tasks-launched-on-aws-batch,False,567,68,https://docs.metaflow.org
141,"Support `shared_memory`, `max_swap`, `swappiness` attributes for Metaflow tasks launched on AWS Batch","The `@batch` decorator now supports `shared_memory`, `max_swap`, `swappiness` attributes
 for Metaflow tasks launched on AWS Batch to provide a greater degree of control for
 memory management.",H4,https://docs.metaflow.org/internals/release-notes#support-shared-memory-max-swap-swappiness-attributes-for-metaflow-tasks-launched-on-aws-batch,False,193,26,https://docs.metaflow.org
142,Support wider very-wide workflows on top of AWS Step Functions,"The tag `metaflow_version:` and `runtime:` is now available for all packaged executions
 and remote executions as well. This ensures that every run logged by Metaflow will have
 `metaflow_version` and `runtime` system tags available.",H4,https://docs.metaflow.org/internals/release-notes#support-wider-very-wide-workflows-on-top-of-aws-step-functions,False,233,33,https://docs.metaflow.org
144,Assign tags to `Run` objects generated through AWS Step Functions executions,"`Run` objects generated by flows executed on top of AWS Step Functions were missing the
 tags assigned to the flow; even though the tags were correctly persisted to tasks. This
 release fixes and brings inline the tagging behavior as observed with local flow
 executions.",H4,https://docs.metaflow.org/internals/release-notes#assign-tags-to-run-objects-generated-through-aws-step-functions-executions,False,271,44,https://docs.metaflow.org
145,Pipe all workflow set-up logs to `stderr`,Execution set-up logs for `@conda` and `IncludeFile` were being piped to `stdout` which,H4,https://docs.metaflow.org/internals/release-notes#pipe-all-workflow-set-up-logs-to-stderr,False,87,13,https://docs.metaflow.org
147,Handle null assignment to `IncludeFile` properly,"A workflow executed without a required `IncludeFile` parameter would fail when the
 parameter was referenced inside the flow. This release fixes the issue by assigning a
 null value to the parameter in such cases.",H4,https://docs.metaflow.org/internals/release-notes#handle-null-assignment-to-includefile-properly,False,213,34,https://docs.metaflow.org
150,Log `metaflow_version:` and `runtime:` tag for all executions,"The tag `metaflow_version:` and `runtime:` is now available for all packaged executions
 and remote executions as well. This ensures that every run logged by Metaflow will have
 `metaflow_version` and `runtime` system tags available.",H4,https://docs.metaflow.org/internals/release-notes#log-metaflow-version-and-runtime-tag-for-all-executions,False,233,33,https://docs.metaflow.org
152,Handle inconsistently cased file system issue when creating @conda environments on macOS for linux-64,"Conda fails to correctly set up environments for linux-64 packages on macOS at times due
 to inconsistently cased filesystems. Environment creation is needed to collect the
 necessary metadata for correctly setting up the conda environment on AWS Batch. This fix
 simply ignores the error-checks that conda throws while setting up the environments on
 macOS when the intended destination is AWS Batch.",H4,https://docs.metaflow.org/internals/release-notes#handle-inconsistently-cased-file-system-issue-when-creating-conda-environments-on-macos-for-linux-64,False,401,61,https://docs.metaflow.org
155,Metaflow is now compliant with AWS GovCloud & AWS CN regions,"AWS GovCloud & AWS CN users can now enjoy all the features of Metaflow within their
 region partition with no change on their end. PR: #364",H4,https://docs.metaflow.org/internals/release-notes#metaflow-is-now-compliant-with-aws-govcloud-aws-cn-regions,False,139,26,https://docs.metaflow.org
157,Address a bug with overriding the default value for [IncludeFile](../scaling/datadata-in-local-files),"Metaflow v2.1.0 introduced a bug in [IncludeFile
 functionality](../scaling/data#data-in-local-files) which prevented users from
 overriding the default value specified.",H4,https://docs.metaflow.org/internals/release-notes#address-a-bug-with-overriding-the-default-value-for-includefile-scaling-datadata-in-local-files,False,169,17,https://docs.metaflow.org
158,Port AWS region check for AWS DynamoDb from `curl` to `requests`,"Metaflow's AWS Step Functions' integration relies on AWS DynamoDb to manage
 [foreach](../metaflow/basics#foreach) constructs. Metaflow was leveraging `curl` at
 runtime to detect the region for AWS DynamoDb. Some docker images don't have `curl`
 installed by default; moving to `requests` (a metaflow dependency) fixes the issue.",H4,https://docs.metaflow.org/internals/release-notes#port-aws-region-check-for-aws-dynamodb-from-curl-to-requests,False,330,44,https://docs.metaflow.org
161,Fix issue [305](https://github.com/Netflix/metaflow/issues/305) : Default 'help' for parameters was not handled properly,"Fix the issue where default `help` for parameters was not handled properly. Issue
 [#305](https://github.com/Netflix/metaflow/issues/305): flow fails because
 `IncludeFile`'s default value for the `help` argument is None. PR:
 [#318](https://github.com/Netflix/metaflow/pull/318)",H4,https://docs.metaflow.org/internals/release-notes#fix-issue-305,False,279,28,https://docs.metaflow.org
162,Pin the conda library versions for Metaflow default dependencies based on the Python version,"The previously pinned library version does not work with python 3.8. Now we have two
 sets of different version combinations which should work for python 2.7, 3.5, 3.6, 3.7,
 and 3.8. PR: [#308](https://github.com/Netflix/metaflow/pull/308)",H4,https://docs.metaflow.org/internals/release-notes#pin-the-conda-library-versions-for-metaflow-default-dependencies-based-on-the-python-version,False,240,33,https://docs.metaflow.org
163,Add conda bin path to the PATH environment variable during Metaflow step execution,"Previously the executable installed in conda environment was not visible inside Metaflow
 steps. Fixing this issue by appending conda bin path to the PATH environment variable.
 PR: [#307](https://github.com/Netflix/metaflow/pull/307)
 
 PRs: [#307](https://github.com/Netflix/metaflow/pull/307),
 [#308](https://github.com/Netflix/metaflow/pull/308),
 [#310](https://github.com/Netflix/metaflow/pull/310),
 [#314](https://github.com/Netflix/metaflow/pull/314),
 [#317](https://github.com/Netflix/metaflow/pull/317),
 [#318](https://github.com/Netflix/metaflow/pull/318)",H4,https://docs.metaflow.org/internals/release-notes#add-conda-bin-path-to-the-path-environment-variable-during-metaflow-step-execution,False,570,36,https://docs.metaflow.org
166,Fix a regression with Conda,"Metaflow 2.2.1 included a commit which was merged too early and broke the use of Conda.
 This release reverses this patch.",H4,https://docs.metaflow.org/internals/release-notes#fix-a-regression-with-conda,False,122,21,https://docs.metaflow.org
167,Clarify Pandas version needed for Episode 04,"Recent versions of Pandas are not backward compatible with the one used in the tutorial;
 a small comment was added to warn of this fact.",H4,https://docs.metaflow.org/internals/release-notes#clarify-pandas-version-needed-for-episode-04,False,137,25,https://docs.metaflow.org
168,Fix an issue with the metadata service,"In some cases, the metadata service would not properly create runs or tasks.
 
 PRs [#296](https://github.com/Netflix/metaflow/pull/296),
 [#297](https://github.com/Netflix/metaflow/pull/297),
 [#298](https://github.com/Netflix/metaflow/pull/298)",H4,https://docs.metaflow.org/internals/release-notes#fix-an-issue-with-the-metadata-service,False,246,18,https://docs.metaflow.org
171,Add `include` parameter for `merge_artifacts`,"You can now specify the artifacts to be merged explicitly by the `merge_artifacts`
 method as opposed to just specifying the ones that should _not_ be merged.",H4,https://docs.metaflow.org/internals/release-notes#add-include-parameter-for-merge-artifacts,False,158,26,https://docs.metaflow.org
174,Fix an issue with Conda in certain environments,"In some cases, Conda is installed system wide and the user cannot write to its
 installation directory. This was causing issues when trying to use the Conda
 environment. Fixes [#179](https://github.com/Netflix/metaflow/issues/179).",H4,https://docs.metaflow.org/internals/release-notes#fix-an-issue-with-conda-in-certain-environments,False,232,30,https://docs.metaflow.org
175,Fix an issue with the S3 datastore in case of retries,"Retries were not properly handled when uploading artifacts to the S3 datastore. This fix
 addresses this issue.
 
 PRs [#282](https://github.com/Netflix/metaflow/pull/282),
 [#286](https://github.com/Netflix/metaflow/pull/286),
 [#287](https://github.com/Netflix/metaflow/pull/287),
 [#288](https://github.com/Netflix/metaflow/pull/288),
 [#289](https://github.com/Netflix/metaflow/pull/289),
 [#290](https://github.com/Netflix/metaflow/pull/290),
 [#291](https://github.com/Netflix/metaflow/pull/291)",H4,https://docs.metaflow.org/internals/release-notes#fix-an-issue-with-the-s3-datastore-in-case-of-retries,False,501,26,https://docs.metaflow.org
176,"2.2.0 (Aug 4th, 2020)","The Metaflow 2.2.0 release is a minor release and introduces [Metaflow's support for R
 lang](../../v/r/).",H2,https://docs.metaflow.org/internals/release-notes#220-aug-4th-2020,False,106,15,https://docs.metaflow.org
178,Support for R lang.,"This release provides an [idiomatic API to access Metaflow in R lang](../../v/r/). It
 piggybacks on the Pythonic implementation as the backend providing most of the
 functionality previously accessible to the Python community. With this release, R users
 can structure their code as a metaflow flow. Metaflow will [snapshot the code, data, and
 dependencies](../../v/r/metaflow/basics#the-structure-of-metaflow-code) automatically in
 a content-addressed datastore allowing for [resuming of
 workflows](../../v/r/metaflow/debugging#how-to-debug-failed-flows), [reproducing past
 results, and inspecting anything about the workflow](../../v/r/metaflow/client) e.g. in
 a notebook or RStudio IDE. Additionally, without any changes to their workflows, users
 can now [execute code on AWS Batch and interact with Amazon S3
 seamlessly](../../v/r/metaflow/scaling).
 
 PR [#263](https://github.com/Netflix/metaflow/pull/263) and PR
 [#214](https://github.com/Netflix/metaflow/pull/214)",H4,https://docs.metaflow.org/internals/release-notes#support-for-r-lang,False,981,106,https://docs.metaflow.org
181,Handle race condition for `/step` endpoint of metadata service.,"The `foreach` step in AWS Step Functions launches multiple AWS Batch tasks, each of
 which tries to register the step metadata if it already doesn't exist. This can result
 in a race condition and cause the task to fail. This patch properly handles the 409
 response from the service.
 
 PR [#258](https://github.com/Netflix/metaflow/pull/258) & PR
 [#260](https://github.com/Netflix/metaflow/pull/260)",H4,https://docs.metaflow.org/internals/release-notes#handle-race-condition-for-step-endpoint-of-metadata-service,False,402,55,https://docs.metaflow.org
182,"2.1.0 (Jul 29th, 2020)","The Metaflow 2.1.0 release is a minor release and introduces [Metaflow's integration
 with AWS Step Functions](../production/scheduling-metaflow-flows/introduction).",H2,https://docs.metaflow.org/internals/release-notes#210-jul-29th-2020,False,165,16,https://docs.metaflow.org
184,Add capability to schedule Metaflow flows with AWS Step Functions.,"Netflix uses an [internal DAG
 scheduler](https://medium.com/@NetflixTechBlog/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280)
 to orchestrate most machine learning and ETL pipelines in production. Metaflow users at
 Netflix can seamlessly deploy and schedule their flows to this scheduler. Now, with this
 release, we are introducing a similar integration with [AWS Step
 Functions](https://aws.amazon.com/step-functions/) where Metaflow users can [easily
 deploy & schedule their flows](../production/scheduling-metaflow-flows/introduction) by
 simply executing
 
 ```
 python myflow.py step-functions create
 ```
 
 which will create an AWS Step Functions state machine for them. With this feature,
 Metaflow users can now enjoy all the features of Metaflow along with a highly available,
 scalable, maintenance-free production scheduler without any changes in their existing
 code.
 
 We are also introducing a new decorator -
 [`@schedule`](../production/scheduling-metaflow-flows/introduction#scheduling-a-flow),
 which allows Metaflow users to instrument time-based triggers via [Amazon
 EventBridge](https://aws.amazon.com/eventbridge/) for their flows deployed on AWS Step
 Functions.
 
 With this integration, Metaflow users can [inspect](../metaflow/client) their flows
 deployed on AWS Step Functions as before and [debug and
 reproduce](../metaflow/debugging#reproducing-production-issues-locally) results from AWS
 Step Functions on their local laptop or within a notebook.
 
 [Documentation](../production/scheduling-metaflow-flows/introduction)\
 [Launch Blog
 Post](https://medium.com/@NetflixTechBlog/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280)
 
 PR [#211](https://github.com/Netflix/metaflow/pull/211) addresses Issue
 [#2](https://github.com/Netflix/metaflow/issues/2).",H4,https://docs.metaflow.org/internals/release-notes#add-capability-to-schedule-metaflow-flows-with-aws-step-functions,False,1867,179,https://docs.metaflow.org
186,Fix log indenting in Metaflow.,"Metaflow was inadvertently removing leading whitespace from user-visible logs on the
 console. Now Metaflow presents user-visible logs with the correct formatting.
 
 PR [#244](https://github.com/Netflix/metaflow/pull/244) fixed issue
 [#223](https://github.com/Netflix/metaflow/issues/223).",H4,https://docs.metaflow.org/internals/release-notes#fix-log-indenting-in-metaflow,False,291,27,https://docs.metaflow.org
187,Throw exception properly if fetching code package from Amazon S3 on AWS Batch fails.,"Due to malformed permissions, AWS Batch might not be able to fetch the code package from
 Amazon S3 for user code execution. In such scenarios, it wasn't apparent to the user,
 where the code package was being pulled from, making triaging any permission issue a bit
 difficult. Now, the Amazon S3 file location is part of the exception stack trace.
 
 PR [#243](https://github.com/Netflix/metaflow/pull/243) fixed issue
 [#232](https://github.com/Netflix/metaflow/issues/232).",H4,https://docs.metaflow.org/internals/release-notes#throw-exception-properly-if-fetching-code-package-from-amazon-s3-on-aws-batch-fails,False,476,66,https://docs.metaflow.org
188,Remove millisecond information from timestamps returned by Metaflow client.,"Metaflow uses `time` to store the `created_at` and `finished_at` information for the
 `Run` object returned by Metaflow client. `time` unfortunately does not support the
 [`%f` directive](https://docs.python.org/3/library/time.html#time.strftime), making it
 difficult to parse these fields by `datetime` or `time`. Since Metaflow doesn't expose
 timings at millisecond grain, this PR drops the `%f` directive.
 
 PR [#227](https://github.com/Netflix/metaflow/pull/227) fixed issue
 [#224](https://github.com/Netflix/metaflow/issues/224).",H4,https://docs.metaflow.org/internals/release-notes#remove-millisecond-information-from-timestamps-returned-by-metaflow-client,False,538,57,https://docs.metaflow.org
189,Handle CloudWatchLogs resource creation delay gracefully.,"When launching jobs on AWS Batch, the CloudWatchLogStream might not be immediately
 created (and may never be created if say we fail to pull the docker image for any reason
 whatsoever). Metaflow will now simply retry again next time.
 
 PR [#209](https://github.com/Netflix/metaflow/pull/209).",H4,https://docs.metaflow.org/internals/release-notes#handle-cloudwatchlogs-resource-creation-delay-gracefully,False,294,42,https://docs.metaflow.org
192,Fix logging of prefixes in datatools.S3.\_read_many_files,"Avoid a cryptic error message when `datatools.S3._read_many_files` is unsuccessful by
 converting `prefixes` from a generator to a list.",H4,https://docs.metaflow.org/internals/release-notes#fix-logging-of-prefixes-in-datatoolss3-read-many-files,False,136,18,https://docs.metaflow.org
193,Increase retry count for AWS Batch logs streaming.,"Modify the retry behavior for log fetching on AWS Batch by adding jitters to exponential
 backoffs as well as reset the retry counter for every successful request.
 
 Additionally, fail the Metaflow task when we fail to stream the task logs back to the
 user's terminal even if AWS Batch task succeeds.",H4,https://docs.metaflow.org/internals/release-notes#increase-retry-count-for-aws-batch-logs-streaming,False,302,52,https://docs.metaflow.org
194,Upper-bound pylint version to < 2.5.0.,"`pylint` version `2.5.0` would mark Metaflow's `self.next()` syntax as an error. As a
 result, `python helloworld.py run` would fail at the pylint check step unless we run
 with `--no-pylint`. This version upper-bound is supposed to automatically downgrade
 `pylint` during `metaflow` installation if `pylint==2.5.0` has been installed.",H4,https://docs.metaflow.org/internals/release-notes#upper-bound-pylint-version-to-250,False,336,46,https://docs.metaflow.org
197,Expose `retry_count` in `Current`,"You can now use the [`current`](../scaling/tagging#accessing-current-ids-in-a-flow)
 singleton to access the `retry_count` of your task. The first attempt of the task will
 have `retry_count` as 0 and subsequent retries will increment the `retry_count`. As an
 example:
 
 ```python
 @retry
 @step
 def my_step(self):
     from metaflow import current
     print(""retry_count: %s"" % current.retry_count)
     self.next(self.a)
 ```",H4,https://docs.metaflow.org/internals/release-notes#expose-retry-count-in-current,False,431,63,https://docs.metaflow.org
198,Mute superfluous `ThrottleExceptions` in AWS Batch job logs,"The AWS Logs API for `get_log_events` has a global hard limit on 10 requests per sec.
 While we have retry logic in place to respect this limit, some of the
 `ThrottleExceptions` usually end up in the job logs causing confusion to the end-user.
 This release addresses this issue (also documented in #184).",H4,https://docs.metaflow.org/internals/release-notes#mute-superfluous-throttleexceptions-in-aws-batch-job-logs,False,306,52,https://docs.metaflow.org
200,Set proper thresholds for retrying `DescribeJobs` API for AWS Batch,"The AWS Batch API for `describe_jobs` throws `ThrottleExceptions` when managing a flow
 with a very wide `for-each` step. This release adds retry behavior with backoffs to add
 proper resiliency (addresses #138).",H4,https://docs.metaflow.org/internals/release-notes#set-proper-thresholds-for-retrying-describejobs-api-for-aws-batch,False,212,31,https://docs.metaflow.org
201,Explicitly override `PYTHONNOUSERSITE` for `conda` environments,"In certain user environments, to properly isolate `conda` environments, we have to
 explicitly override `PYTHONNOUSERSITE` rather than simply relying on `python -s`
 (addresses #178).",H4,https://docs.metaflow.org/internals/release-notes#explicitly-override-pythonnousersite-for-conda-environments,False,183,24,https://docs.metaflow.org
202,Preempt AWS Batch job log collection when the job fails to get into a `RUNNING` state,"Fixes a bug where if the AWS Batch job crashes before entering the `RUNNING` state
 (often due to incorrect IAM perms), the previous log collection behavior would fail to
 print the correct error message making it harder to debug the issue (addresses #185).",H4,https://docs.metaflow.org/internals/release-notes#preempt-aws-batch-job-log-collection-when-the-job-fails-to-get-into-a-running-state,False,257,43,https://docs.metaflow.org
205,Parameter listing,"You can now use the `current` singleton (documented
 [here](../scaling/tagging#accessing-current-ids-in-a-flow)) to access the names of the
 parameters passed into your flow. As an example:
 
 ```python
 for var in current.parameter_names:
     print(""Parameter %s has value %s"" % (var, getattr(self, var))
 ```
 
 This addresses [#137](https://github.com/Netflix/metaflow/issues/137).",H4,https://docs.metaflow.org/internals/release-notes#parameter-listing,False,385,47,https://docs.metaflow.org
206,Usability improvements,"A few issues were addressed to improve the usability of Metaflow. In particular, `show`
 now properly respects indentation making the description of steps and flows more
 readable. This addresses [#92](https://github.com/Netflix/metaflow/issues/92).
 Superfluous print messages were also suppressed when executing on AWS batch with the
 local metadata provider ([#152](https://github.com/Netflix/metaflow/pull/152)).",H4,https://docs.metaflow.org/internals/release-notes#usability-improvements,False,416,47,https://docs.metaflow.org
208,Conda,"A smaller, newer and standalone Conda installer is now used resulting in faster and more
 reliable Conda bootstrapping ([#123](https://github.com/Netflix/metaflow/pull/123)).",H4,https://docs.metaflow.org/internals/release-notes#conda,False,174,19,https://docs.metaflow.org
210,Executing on AWS Batch,"We now check for the command line `--datastore-root` prior to using the environment
 variable `METAFLOW_DATASTORE_SYSROOT_S3` when determining the S3 root
 ([#134](https://github.com/Netflix/metaflow/pull/134)). This release also fixes an issue
 where using the local Metadata provider with AWS batch resulted in incorrect directory
 structure in the `.metaflow` directory
 ([#141](https://github.com/Netflix/metaflow/pull/141)).",H4,https://docs.metaflow.org/internals/release-notes#executing-on-aws-batch,False,429,46,https://docs.metaflow.org
216,Technical Overview,"Make sure you have read [Basics of Metaflow](../metaflow/basics) before diving into
 technical details below. You can find more technical details at the infrastructure level
 in [Administrator's Guide to Metaflow](https://outerbounds.com/docs/admin). This
 document focuses on the Metaflow codebase.
 
 We wanted to build a data science platform that can make data science code usable,
 scalable, reproducible, and production-ready, as described in the [Why
 Metaflow](../introduction/why-metaflow) section. There are many ways to achieve these
 high-level goals. We took an approach designed around the following four core functions:
 
 1. Provide a highly usable API for structuring the code as a workflow, i.e. as a
    directed graph of steps (**usability**).
 2. Persist an immutable snapshot of data, code, and external dependencies required to
    execute each step (**reproducibility**).
 3. Facilitate execution of the steps in various environments, from development to
    production (**scalability**, **production-readiness**).
 4. Record metadata about previous executions and make them easily accessible
    (**usability**, **reproducibility**).
 
 This document gives an overview of how the core functionality is implemented.",H1,https://docs.metaflow.org/internals/technical-overview#technical-overview,False,1239,175,https://docs.metaflow.org
217,Architecture,"Here is a high-level architecture diagram of Metaflow:
 
 ![](/assets/Untitled_presentation.png)
 
 Below, we will describe the components in detail. To highlight the time-dimension which
 is missing from the diagram, we group the descriptions by the following phases in the
 development lifecycle:
 
 1. Development-time, i.e. when the code gets written.
 2. Runtime, i.e. when the code gets run.
 3. Result-time, i.e. when the results of the run get used.
 
 Every component includes links to source files where the functionality is implemented.",H2,https://docs.metaflow.org/internals/technical-overview#architecture,False,547,82,https://docs.metaflow.org
218,Development-Time Components,"The core development-time concept in Metaflow is a _flow_. It represents the business
 logic of what needs to be computed.
 
 How to intertwine the business logic with the framework in the most **usable** manner is
 a central design concern of Metaflow. We want to encourage the user to structure the
 code in a way that enables **reproducibility** and **scalability**.
 
 In contrast, we would like to minimize concerns related to production-readiness during
 development time. Optimally, the user can write idiomatic Python code focusing on the
 logic itself and the guard rails of the framework will automatically make the code
 production-ready.",H2,https://docs.metaflow.org/internals/technical-overview#development-time-components,False,649,101,https://docs.metaflow.org
219,**Flow**,"A flow is the smallest unit of computation that can be scheduled for execution.
 Typically, a flow defines a workflow that pulls data from an external source as input,
 processes it in several steps, and produces output data.
 
 User implements a flow by subclassing `FlowSpec` and implementing steps as methods.
 Besides steps, a flow can define other attributes relevant for scheduling, such as
 parameters and data triggers.",H3,https://docs.metaflow.org/internals/technical-overview#flow,False,427,68,https://docs.metaflow.org
220,Graph,"Metaflow infers a directed (typically acyclic) graph based on the transitions between
 step functions.
 
 Metaflow requires the transitions to be defined so that the graph can be parsed from the
 source code of the flow statically. This makes it possible to translate the graph for
 execution by runtimes that support only statically defined graphs, such as Meson.",H3,https://docs.metaflow.org/internals/technical-overview#graph,False,364,58,https://docs.metaflow.org
221,Step,"A step is the smallest resumable unit of computation. It is implemented by the user as a
 method that is decorated with the `@step` decorator in a flow class.
 
 A step is [a checkpoint](https://en.wikipedia.org/wiki/Application_checkpointing).
 Metaflow takes a snapshot of the data produced by a step which in turn is used as input
 to the subsequent steps. Hence, if a step fails, it can be resumed without rerunning the
 preceding steps.
 
 Being able to resume execution is a powerful feature. It would be convenient to be able
 to resume execution at any arbitrary line of code. The main reason why checkpointing is
 done at the step level instead of line level is the overhead of saving state. The user
 is encouraged to keep the steps small but not so small that the overhead becomes
 noticeable.",H3,https://docs.metaflow.org/internals/technical-overview#step,False,804,136,https://docs.metaflow.org
222,Decorators,"The behavior of a step can be modified with decorators. Tags are the main mechanism for
 extending Metaflow. For instance, a decorator can catch exceptions, implement a timeout,
 or define resource requirements for a step.
 
 A step may have arbitrary many decorators, implemented as Python decorators.",H3,https://docs.metaflow.org/internals/technical-overview#decorators,False,302,47,https://docs.metaflow.org
223,Step Code,"Step code is the body of a step. It implements the actual business logic of flow.
 
 It is possible to implement various language bindings, e.g. R, for Metaflow so that only
 the language of the step code is changed while all the core functionality, implemented
 in Python, stays intact.
 
 All instance variables, e.g. `self.x`, used in the step code become _data artifacts_
 that are persisted automatically. Stack variables, e.g. `x`, are not persisted. This
 dichotomy allows the user to control the overhead of checkpointing by explicitly
 choosing between persistent vs. non-persistent variables in the step code.",H3,https://docs.metaflow.org/internals/technical-overview#step-code,False,619,98,https://docs.metaflow.org
224,Runtime Components,"The core runtime concept in Metaflow is a _run_, that is, an execution of a user-defined
 flow. A run happens when the user executes `python myflow.py run` on the command line.
 
 A key design decision of Metaflow is to make the framework runtime-agnostic. The same
 code should be runnable in various environments, such as on a laptop during development
 or on a **production-ready** workflow orchestrator during production.
 
 Similarly, we want to provide seamless **scalability** by allowing the same code run on
 a laptop in parallel over multiple processes or in the cloud over multiple batch jobs.",H2,https://docs.metaflow.org/internals/technical-overview#runtime-components,False,604,98,https://docs.metaflow.org
225,**Task**,"The runtime counterpart of a step is a _task_. In runtime, a normal step spawns one task
 for execution. A foreach split step may spawn multiple tasks which are identified by a
 unique _foreach stack_.",H3,https://docs.metaflow.org/internals/technical-overview#task,False,201,35,https://docs.metaflow.org
226,Code Package,"In order to be able to **reproduce** the results of a run, we need to snapshot the code
 that was run.
 
 Code package is an immutable snapshot of the relevant code in the working directory,
 stored in the datastore, at the time when the run was started. A convenient side effect
 of the snapshot is that it also works as a code distribution mechanism for runs that
 happen in the cloud.",H3,https://docs.metaflow.org/internals/technical-overview#code-package,False,387,72,https://docs.metaflow.org
227,**Environment**,"Unfortunately, just snapshotting the working directory of the flow code is not
 sufficient for reproducibility. The code often depends on external libraries which also
 need to be included in the snapshot.
 
 The concept of an _environment_ is closely related to code packages. The environment
 encapsulates both the flow code and its external dependencies, so that the exact
 execution environment can be reproduced on a remote system accurately.",H3,https://docs.metaflow.org/internals/technical-overview#environment,False,447,68,https://docs.metaflow.org
228,Runtime,"A run of a flow is executed by executing tasks defined by steps in a topological order.
 It is the job of a runtime to orchestrate this execution. A better name for ""runtime""
 might be a scheduler.
 
 For quick local iterations, Metaflow comes with a built-in runtime which executes tasks
 as separate processes. However, this is not intended as a production-grade scheduler.
 
 For production runs, one should use a runtime that supports retries, error reporting,
 logging, is highly available, scalable, and preferably comes with a user-friendly UI. At
 Netflix,
 [Meson](https://medium.com/netflix-techblog/meson-workflow-orchestration-for-netflix-recommendations-fc932625c1d9)
 is such a runtime. It is well-supported by Metaflow.
 
 A key feature of Metaflow is that it is agnostic of the runtime. The same code can be
 executed both with the local runtime and with production runtime, which enables a rapid
 development-deploy-debug cycle.",H3,https://docs.metaflow.org/internals/technical-overview#runtime,False,945,136,https://docs.metaflow.org
229,Datastore,"Metaflow requires an object store where both code snapshots and data artifacts can be
 persisted. This data store should be accessible by all environments where Metaflow code
 is executed. The AWS S3 is a perfect solution for this need. Secondarily, Metaflow
 supports using a local disk as a data store, which is mainly useful during the
 development of Metaflow itself.
 
 An important feature of Metaflow is that the data store is used as a content-addressed
 storage. Both code and data are identified by a hash of their contents, similar to Git,
 so equal copies of data are deduplicated automatically. Note that this deduplication is
 limited in scope however; data across different flows will not be deduplicated.",H3,https://docs.metaflow.org/internals/technical-overview#datastore,False,720,117,https://docs.metaflow.org
230,Metadata Provider,"A centralized Metadata Provider keeps track of runs. Strictly speaking, this
 functionality is not required by Metaflow, but it makes the system much more **usable.**
 The service also helps to make data artifacts and other metadata about runs more
 discoverable during result-time, as explained below.",H3,https://docs.metaflow.org/internals/technical-overview#metadata-provider,False,302,45,https://docs.metaflow.org
231,Result-time Components,"Flows are defined and run for their results. Metaflow supports a number of different
 ways to consume outputs of runs: Results can be written to Hive tables for consumption
 by downstream systems and dashboards, they can be accessed in a notebook for further
 analysis, or in a hosted web service (this last functionality is not yet available in
 Open Source).",H2,https://docs.metaflow.org/internals/technical-overview#result-time-components,False,360,60,https://docs.metaflow.org
232,Metaflow Client,"Metaflow provides a highly **usable** Python API to access results of previous runs,
 called `metaflow.client`. A typical way to use `metaflow.client` is to access data
 artifacts of past runs in a Jupyter notebook. It is extremely convenient to be able to
 examine the internal state of production runs or perform further ad-hoc analysis of the
 results in a notebook.",H3,https://docs.metaflow.org/internals/technical-overview#metaflow-client,False,369,59,https://docs.metaflow.org
233,Testing Philosophy,"Watch this talk for motivation: [Autonomous Testing and the Future of Software
 Development by Will Wilson](https://www.youtube.com/watch?v=fFSPwJFXVlw).",H1,https://docs.metaflow.org/internals/testing-philosophy#testing-philosophy,False,153,16,https://docs.metaflow.org
234,Metaflow Test Suite,"The integration test harness for the core Metaflow at `test/core`, generates and
 executes synthetic Metaflow flows, exercising all aspects of Metaflow. The test suite is
 executed using [tox](http://tox.readthedocs.io) as configured in `tox.ini`. You can run
 the tests by hand using `pytest` or `run_tests.py` as described below.
 
 What happens when you execute `python helloworld.py run`? The execution involves
 multiple layers of the Metaflow stack. The stack looks like following, starting from the
 most fundamental layer all the way to the user interface:
 
 1. Python interpreter \(`python2`, `python3`\)
 2. Metaflow core \(`task.py`, `runtime.py`, `datastore`, etc.\)
 3. Metaflow plugins \(`@timeout`, `@catch`, `metadata.py` etc.\)
 4. User-defined graph
 5. User-defined step functions
 6. User interface \(`cli.py`, `metaflow.client`\)
 
 We could write unit tests for functions in the layers 2, 3, and 6, which would capture
 some bugs. However, a much larger superset of bugs is caused by unintended interactions
 across the layers. For instance, exceptions caught by the `@catch` tag \(3\) inside a
 deeply nested foreach graph \(4\) might not be returned correctly in the client API
 \(6\) when using Python 3 \(1\).
 
 The integration test harness included in the `core` directory tries to surface bugs like
 this by generating test cases automatically using _specifications_ provided by the
 developer.",H2,https://docs.metaflow.org/internals/testing-philosophy#metaflow-test-suite,False,1424,207,https://docs.metaflow.org
235,Specifications,"The test harness allows you to customize behavior in four ways that correspond to the
 layers above:
 
 1. You define the execution environment, including environment variables, the version of
    the Python interpreter, and the type of datastore used as _contexts_ in
    `contexts.json` \(layers 1 and 2\).
 2. You define the step functions, the decorators used, and the expected results as
    `MetaflowTest` templates, stored in the `tests` directory \(layers 3 and 5\).
 3. You define various graphs that match the step functions as simple JSON descriptions
    of the graph structure, stored in the `graphs` directory \(layer 4\).
 4. You define various ways to check the results that correspond to the different user
    interfaces of Metaflow as `MetaflowCheck` classes, stored in the `metaflow_test`
    directory \(layer 6\). You can customize which checkers get used in which contexts in
    `context.json`.
 
 The test harness takes all `contexts`, `graphs`, `tests`, and `checkers` and generates a
 test flow for every combination of them, unless you explicitly set constraints on what
 combinations are allowed. The test flows are then executed, optionally in parallel, and
 results are collected and summarized.",H2,https://docs.metaflow.org/internals/testing-philosophy#specifications,False,1226,204,https://docs.metaflow.org
236,**Contexts**,"Contexts are defined in `contexts.json`. The file should be pretty self-explanatory.
 Most likely you do not need to edit the file unless you are adding tests for a new
 command-line argument.
 
 Note that some contexts have `disabled: true`. These contexts are not executed by
 default when tests are run by a CI system. You can enable them on the command line for
 local testing, as shown below.",H3,https://docs.metaflow.org/internals/testing-philosophy#contexts,False,397,68,https://docs.metaflow.org
237,**Tests**,"Take a look at `tests/basic_artifact.py`. This test verifies that artifacts defined in
 the first step are available in all steps downstream. You can use this simple test as a
 template for new tests.
 
 Your test class should derive from `MetaflowTest`. The class variable `PRIORITY` denotes
 how fundamental the exercised functionality is to Metaflow. The tests are executed in
 the ascending order of priority, to make sure that foundations are solid before
 proceeding to more sophisticated cases.
 
 The step functions are decorated with the `@steps` decorator. Note that in contrast to
 normal Metaflow flows, these functions can be applied to multiple steps in a graph. A
 core idea behind this test harness is to decouple graphs from step functions, so various
 combinations can be tested automatically. Hence, you need to provide step functions that
 can be applied to various step types.
 
 The `@steps` decorator takes two arguments. The first argument is an integer that
 defines the order of precedence between multiple `steps` functions, in case multiple
 step function templates match. A typical pattern is to provide a specific function for a
 specific step type, such as joins and give it a precedence of `0`. Then another
 catch-all can be defined with `@steps(2, ['all'])`. As the result, the special function
 is applied to joins and the catch-all function for all other steps.
 
 The second argument gives a list of _qualifiers_ specifying which types of steps this
 function can be applied to. There is a set of built-in qualifiers: `all`, `start`,
 `end`, `join`, `linear` which match to the corresponding step types. In addition to
 these built-in qualifiers, graphs can specify any custom qualifiers.
 
 By specifying `required=True` as a keyword argument to `@steps`, you can require that a
 certain step function needs to be used in combination with a graph to produce a valid
 test case. By creating a custom qualifier and setting `required=True` you can control
 how tests get matched to graphs.
 
 In general, it is beneficial to write test cases that do not specify overly restrictive
 qualifiers and `required=True`. This way you cast a wide net to catch bugs with many
 generated test cases. However, if the test is slow to execute and/or does not benefit
 from a large number of matching graphs, it is a good idea to make it more specific.",H3,https://docs.metaflow.org/internals/testing-philosophy#tests,False,2373,387,https://docs.metaflow.org
238,**Assertions**,"The test case is not very useful unless it verifies its results. There are two ways to
 assert that the test behaves as expected.
 
 You can use a function `assert_equals(expected, got)` inside step functions to confirm
 that data inside the step functions is valid. Secondly, you can define a method
 `check_results(self, flow, checker)` in your test class, which verifies the stored
 results after the flow has been executed successfully.
 
 Use
 
 ```text
 checker.assert_artifact(step_name, artifact_name, expected_value)
 ```
 
 to assert that steps contain the expected data artifacts.
 
 Take a look at existing test cases in the `tests` directory to get an idea how this
 works in practice.",H4,https://docs.metaflow.org/internals/testing-philosophy#assertions,False,698,109,https://docs.metaflow.org
239,**Graphs**,"Graphs are simple JSON representations of directed graphs. They list every step in a
 graph and transitions between them. Every step can have an optional list of custom
 qualifiers, as described above.
 
 You can take a look at the existing graphs in the `graphs` directory to get an idea of
 the syntax.",H3,https://docs.metaflow.org/internals/testing-philosophy#graphs,False,304,53,https://docs.metaflow.org
240,**Checkers**,"Currently, the test harness exercises two types of user interfaces: The command-line
 interface, defined in `cli_check.py`, and the Python API, defined in `mli_check.py`.
 
 Currently, you can use these checkers to assert values of data artifacts or log output.
 If you want to add tests for new types of functionality in the CLI and/or the Python
 API, you should add a new method in the `MetaflowCheck` base class and corresponding
 implementations in `mli_check.py` and `cli_check.py`. If certain functionality is only
 available in one of the interfaces, you can provide a stub implementation returning
 `True` in the other checker class.",H3,https://docs.metaflow.org/internals/testing-philosophy#checkers,False,642,99,https://docs.metaflow.org
241,Usage,"The test harness is executed by running `run_tests.py`. By default, it executes all
 valid combinations of contexts, tests, graphs, and checkers. This mode is suitable for
 automated tests run by a CI system.
 
 When testing locally, it is recommended to run the test suite as follows:
 
 ```text
 cd metaflow/test/core
 PYTHONPATH=`pwd`/../../ python run_tests.py --debug --contexts dev-local
 ```
 
 This uses only the `dev_local` context, which does not depend on any over-the-network
 communication like `--metadata=service` or `--datastore=s3`. The `--debug` flag makes
 the harness fail fast when the first test case fails. The default mode is to run all
 test cases and summarize all failures in the end.
 
 You can run a single test case as follows:
 
 ```text
 cd metaflow/test/core
 PYTHONPATH=`pwd`/../../ python run_tests.py --debug --contexts dev-local --graphs single-linear-step --tests BasicArtifactTest
 ```
 
 This chooses a single context, a single graph, and a single test. If you are developing
 a new test, this is the fastest way to test the test.",H2,https://docs.metaflow.org/internals/testing-philosophy#usage,False,1070,161,https://docs.metaflow.org
242,Coverage report,"The test harness uses the `coverage` package in Python to produce a test coverage
 report. By default, you can find a comprehensive test coverage report in the `coverage`
 directory after the test harness has finished.
 
 After you have developed a new feature in Metaflow, use the line-by-line coverage report
 to confirm that all lines related the new feature are touched by the tests.",H3,https://docs.metaflow.org/internals/testing-philosophy#coverage-report,False,387,64,https://docs.metaflow.org
243,Contributing to Metaflow,"First off, thanks for taking the time!
 
 If you are interested in contributing to Metaflow, we'd love to hear from you! Drop us a
 line in our [chatroom](http://chat.metaflow.org/).",H1,https://docs.metaflow.org/internals/contributing#contributing-to-metaflow,False,182,29,https://docs.metaflow.org
244,Contributing Code and Issues,"We are proud of our philosophy and human-centric development style, which means that we
 value thoughtfulness and a polished user experience more than the number of features or
 lines of code.
 
 When Metaflow was developed internally at Netflix, we spent a considerable amount of
 time, often months, to hone the design for features before we implemented them. We are
 not sure what’s the best way to facilitate the design process in the open yet - your
 ideas are welcome. We have outlined our current suggested way below -
 
 Please make sure there is an open issue discussing your contribution. Before opening a
 new issue, please check for [existing
 issues](https://github.com/Netflix/metaflow/issues?q=is%3Aissue). If you find an
 existing issue that matches closely with yours, please thumbs-up or comment on it, so we
 know that the issue is relevant to many people.
 
 If you hit a bug that is not covered by an existing issue, please open a new issue. If
 you are able to fix the bug by yourself with a few lines of code, we welcome your PR.
 However, if fixing the bug requires more effort, please wait for our response on the
 issue. We try to respond as quickly as possible.
 
 If you have a proposal for an enhancement or a new feature, please open an issue and
 engage with us on the issue before devoting significant time and resources to it. We
 care deeply about the ergonomics of Metaflow, and as such, for any new user-visible
 enhancement, please expect multiple design iterations.
 
 We will do our best to respond to and review your PR, and we hope you will stay engaged
 with us throughout the process.
 
 We'd appreciate [issue reports](https://github.com/Netflix/metaflow/issues) if you run
 into trouble using Metaflow.",H3,https://docs.metaflow.org/internals/contributing#contributing-code-and-issues,False,1747,292,https://docs.metaflow.org
245,Community,"Everyone is welcome to join us in our [chatroom](http://chat.metaflow.org/)!
 
 Please maintain appropriate, professional conduct while participating in our community.
 This includes all channels of communication. We take reports of harassment or
 unwelcoming behavior very seriously. To report such behavior, please contact us via
 [email](mailto:help@metaflow.org).",H3,https://docs.metaflow.org/internals/contributing#community,False,367,45,https://docs.metaflow.org
246,Accessing Secrets,"If your flow needs to access an external service (e.g. a database) that requires
 authentication, you need to supply credentials to the flow. If security wasn't
 a concern, you could easily achieve this using
 [Metaflow parameters](/metaflow/basics#how-to-define-parameters-for-flows). However,
 when it comes to credentials and other sensitive information, security is a top concern.
 
 The industry-standard best practice is to store credentials in a secrets
 manager, such as [AWS Secrets Manager](https://aws.amazon.com/secrets-manager/).
 Once secrets are managed by such a system, Metaflow provides a decorator, `@secrets`,
 which makes it easy to access them securely in a flow.
 
 For more background, see [the `@secrets` launch blog post](https://outerbounds.com/blog/metaflow-secrets/).
 Also, take a look at [the API docs for `@secrets`](/api/step-decorators/secrets).
 
 :::info
 
 Currently, `@secrets` supports only AWS Secrets Manager. Contact us on
 [Metaflow support Slack](http://chat.metaflow.org) if you are interested in
 using another secrets manager.
 
 :::",H1,https://docs.metaflow.org/scaling/secrets#accessing-secrets,False,1080,140,https://docs.metaflow.org
247,Basic usage,"This video gives a one-minute overview of how to store a secret and access it in
 Metaflow (no sound):
 
 import ReactPlayer from 'react-player'
 
 <ReactPlayer controls url=""https://www.youtube.com/watch?v=tGRc8tWTzoQ"" />
 <br/>
 
 The secrets manager stores secrets as a set of key-value pairs that are
 identified by a name. Given a name, the `@secrets` decorator fetches the
 key-value pairs - assuming your IAM user is allowed to read the secret - and
 exposes them through environment variables.
 
 Here is the simple example featured in the video:
 
 ```python
 from metaflow import FlowSpec, step, secrets
 import os
 
 class SecretFlow(FlowSpec):
 
     @secrets(sources=['metaflow-example-password'])
     @step
     def start(self):
         print(""Here's the password:"", os.environ['password'])
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     SecretFlow()
 ```
 
 In this case, `metaflow-example-password` is the name of the secret which
 contains a key `password`. The `sources` attribute, which defines the secret
 sources, could contain multiple names, in which case the union of all secret
 sets is exposed through environment variables.",H2,https://docs.metaflow.org/scaling/secrets#basic-usage,False,1216,211,https://docs.metaflow.org
248,Configuring a secrets backend,"To use `@secrets`, you need to inform Metaflow which secrets manager you want to
 use. Currently, the choice is easy since the only supported backend is AWS
 Secrets Manager.
 
 Make sure your Metaflow configuration contains the following line:
 
 ```json
 ""METAFLOW_DEFAULT_SECRETS_BACKEND_TYPE"": ""aws-secrets-manager""
 ```",H3,https://docs.metaflow.org/scaling/secrets#configuring-a-secrets-backend,False,324,44,https://docs.metaflow.org
249,Defining secrets on the command line,"Note that you can define `@secrets` on the command line using the `--with`
 option like any other decorator. This comes especially handy when moving
 between prototype and production: For instance, you can access a different
 database during development and production.
 
 Consider this example that connects to a Postgres database:
 
 ```python
 from metaflow import FlowSpec, step, secrets
 import os
 from psycopg import connect
 
 class DBFlow(FlowSpec):
 
     @step
     def start(self):
         with connect(user=os.environ['DB_USER'],  
                      password=os.environ['DB_PASSWORD'],
                      dbname=os.environ['DB_NAME'],
                      host=os.environ['DB_HOST']) as conn:
 
             with conn.cursor() as cur:
                 cur.execute(""SELECT * FROM data"")
                 print(cur.fetchall())
 
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     DBFlow()
 ```
 
 During development, you can run the flow locally, maybe reading credentials to a
 local database from environment variables - no need to use a secrets manager
 during early prototyping.
 
 To read data from a test database, you can fetch credentials from a secrets
 manager by running the flow like this:
 
 ```bash
 python dbflow.py
    –with 'secrets:sources=[“test-db-credentials”]'
    run
 ```
 
 And you can [deploy to production](/production/introduction) using a production
 database like this:
 
 ```bash
 python dbflow.py
   –with 'secrets:sources=[""prod-db-credentials”]'
   argo-workflows create
 ```",H3,https://docs.metaflow.org/scaling/secrets#defining-secrets-on-the-command-line,False,1589,347,https://docs.metaflow.org
250,Advanced topics,"The following topics come up occasionally when running flows in serious
 production environments.",H2,https://docs.metaflow.org/scaling/secrets#advanced-topics,False,97,13,https://docs.metaflow.org
251,Controlling access to secrets,"A major benefit of using a secrets manager is that you can control closely who
 gets to access which secrets. In the case of AWS Secrets Manager, access
 control is accomplished through IAM policies. For more details, [consult the
 section about access control in the AWS Secrets Manager
 documentation](https://docs.aws.amazon.com/secretsmanager/latest/userguide/auth-and-access.html).
 
 For instance, you can set up IAM policies so that only a test database is
 accessible to users directly, while production database can be only accessed
 by [tasks running on a production scheduler](/production/introduction).",H3,https://docs.metaflow.org/scaling/secrets#controlling-access-to-secrets,False,614,83,https://docs.metaflow.org
252,Using an alternative role,"By default, `@secrets` accesses secrets using the default IAM role available in
 the execution environment. For local runs, this is typically the role attached
 to the IAM user.
 
 If the default role doesn't have access to the specified secrets, you can define
 an alternative role through the `role` attribute:
 
 ```python
 @secrets(sources=['metaflow-example-password'],
          role='arn:aws:iam::123456789012:role/SecretsAccess')
 ```
 
 The default role needs to be able to assume the specified `role` for this
 to work.",H3,https://docs.metaflow.org/scaling/secrets#using-an-alternative-role,False,529,81,https://docs.metaflow.org
253,Accessing secrets from a non-default location,"AWS Secrets Manager is an account- and region-specific service. By default, when
 you specify a secret name in the `sources` list, `@secrets` assumes that the
 name is available in the current AWS account, in the current default region.
 
 If this is not the case, you can specify a full secrets ARN (available on the
 AWS Secrets Manager console) as a source:
 
 ```python
 @secrets(sources=['arn:aws:secretsmanager:us-west-2:001234556000:secret:some-secret'])
 ```",H3,https://docs.metaflow.org/scaling/secrets#accessing-secrets-from-a-non-default-location,False,466,66,https://docs.metaflow.org
254,Dealing with Failures,"Failures are a natural, expected part of data science workflows. Here are some typical
 reasons why you can expect your workflow to fail:
 
 1. **Misbehaving code:** no code is perfect. Your code may fail to handle edge cases or
    libraries behave differently than what you expected.
 2. **Unanticipated issues with data:** data is harder than science. Data is how Metaflow
    workflows interact with the chaotic, high entropy, outside world. It is practically
    impossible to anticipate all possible ways the input data can be broken.
 3. **Platform issues:** the best infrastructure is invisible. Unfortunately, every now
    and then platforms that Metaflow relies on, or Metaflow itself, make their existence
    painfully obvious by failing in creative ways.
 
 Metaflow provides straightforward tools for you to handle all these scenarios. If you
 are in a hurry, see [a quick summary of the tools](failures.md#summary).",H1,https://docs.metaflow.org/scaling/failures#dealing-with-failures,False,931,156,https://docs.metaflow.org
255,Retrying Tasks with the `retry` Decorator,"Retrying a failed task is the simplest way to try to handle errors. It is a particularly
 effective strategy with platform issues which are typically transient in nature.
 
 You can enable retries for a step simply by adding `retry` decorator in the step, like
 here:
 
 ```python
 from metaflow import FlowSpec, step, retry
 
 class RetryFlow(FlowSpec):
 
     @retry
     @step
     def start(self):
         import time
         if int(time.time()) % 2 == 0:
             raise Exception(""Bad luck!"")
         else:
             print(""Lucky you!"")
         self.next(self.end)
 
     @step
     def end(self):
         print(""Phew!"")
 
 if __name__ == '__main__':
     RetryFlow()
 ```
 
 When you run this flow you will see that sometimes it succeeds without a hitch, but
 sometimes the `start` step raises an exception and needs to be retried. By default,
 `retry` retries the step three times. Thanks to `retry`, this workflow will almost
 always succeed.
 
 It is recommended that you use `retry` every time you [run tasks
 remotely](/scaling/remote-tasks/introduction). Instead of annotating every step with a
 retry decorator, you can also automatically add a retry decorator to all steps that do
 not have one as follows:
 
 ```python
 python RetryFlow.py run --with retry
 ```",H2,https://docs.metaflow.org/scaling/failures#retrying-tasks-with-the-retry-decorator,False,1288,272,https://docs.metaflow.org
256,How to Prevent Retries,"If retries are such a good idea, why not enable them by default for all steps? First,
 retries only help with transient errors, like sporadic platform issues. If the input
 data or your code is broken, retrying will not help anything. Secondly, not all steps
 can be retried safely.
 
 Imagine a hypothetical step like this:
 
 ```python
 @step
 def withdraw_money_from_account(self):
     requests.post('bank.com/account/123/withdraw', data={'amount': 1000})
 ```
 
 If you run this code with:
 
 ```bash
 python MoneyFlow.py run --with retry
 ```
 
 you may end up withdrawing up to $4000 instead of the intended $1000. To make sure no
 one will accidentally retry a step with _destructive side effects_ like this, you should
 add `times=0` in the code:
 
 ```python
 @retry(times=0)
 @step
 def withdraw_money_from_account(self):
     requests.post('bank.com/account/123/withdraw', data={'amount': 1000})
 ```
 
 Now the code can be safely rerun, even using `--with retry`. All other steps will be
 retried as usual.
 
 Most data science workflows do not have to worry about this. As long as your step only
 reads and writes Metaflow artifacts and/or performs only read-only operations with
 external systems \(e.g. performs only `SELECT` queries, no `INSERT`s etc.\), your step
 is [idempotent](https://en.wikipedia.org/wiki/Idempotence#Computer_science_meaning) and
 can be retried without concern.",H3,https://docs.metaflow.org/scaling/failures#how-to-prevent-retries,False,1403,204,https://docs.metaflow.org
257,Maximizing Safety,"By default, `retry` will retry the step for three times before giving up. It waits for 2
 minutes between retries for [remote tasks](/scaling/remote-tasks/introduction). This
 means that if your code fails fast, any transient platform issues need to get resolved
 in less than 10 minutes or the whole run will fail. 10 minutes is typically more than
 enough, but sometimes you want both a belt and suspenders.
 
 If you have a sensitive production workflow which should not fail easily, there are four
 things you can do:
 
 1. You can increase the number of retries to `times=4`, which is the maximum number of
    retries currently.
 2. You can make the time between retries arbitrarily long, e.g. `times=4,
    minutes_between_retries=20.` This will give the task over an hour to succeed.
 3. You can use `catch`, described below, as a way to continue even after all retries
    have failed.
 4. You can use `timeout`, also described below, to make sure your code will not get
    stuck.
 
 You can use any combination of these four techniques, or all of them together, to build
 rock-solid workflows.",H3,https://docs.metaflow.org/scaling/failures#maximizing-safety,False,1104,194,https://docs.metaflow.org
258,Results of Retries,"If the same code is executed multiple times by `retry`, are there going to be duplicate
 artifacts? No, Metaflow manages retries so that only artifacts from the last retry are
 visible. If you use [the Client API ](/metaflow/client.md)to inspect results, you don't
 have to do anything special to deal with retries that may have happened. Each task will
 have only one set of results. Correspondingly, the logs returned by `task` show the
 output of the last attempt only.
 
 If you want to know if a task was retried, you can retrieve retry timestamps from `Task`
 metadata:
 
 ```python
 from metaflow import Run, namespace
 
 namespace(None)
 task = Run('RetryFlow/10')['start'].task
 attempts = [m for m in task.metadata if m.type == 'attempt']
 ```",H3,https://docs.metaflow.org/scaling/failures#results-of-retries,False,753,121,https://docs.metaflow.org
259,Catching Exceptions with the `catch` Decorator,"As mentioned above, `retry` is an appropriate tool for dealing with transient issues.
 What about issues that are not transient? Metaflow has another decorator, `catch` that
 catches any exceptions that occur during the step and then continues execution of
 subsequent steps.
 
 The main upside of `catch` is that it can make your workflows extremely robust: it will
 handle all error scenarios from faulty code and faulty data to platform issues. The main
 downside is that your code needs to be modified so that it can tolerate faulty steps.
 
 Let's consider issues caused by your code versus everything surrounding it separately.",H2,https://docs.metaflow.org/scaling/failures#catching-exceptions-with-the-catch-decorator,False,633,102,https://docs.metaflow.org
260,Exceptions Raised by Your Code,"By default, Metaflow stops execution of the flow when a step fails. It can't know what
 to do with failed steps automatically.
 
 You may know that some steps are error-prone. For instance, this can happen with a step
 inside a foreach loop that iterates over unknown data, such as the results of a query or
 a parameter matrix. In this case, it may be desirable to let some tasks fail without
 crashing the whole flow.
 
 Consider this example that is structured like a hyperparameter search:
 
 ```python
 from metaflow import FlowSpec, catch, step
 
 class CatchFlow(FlowSpec):
 
     @step
     def start(self):
         self.params = range(3)
         self.next(self.compute, foreach='params')
 
     @catch(var='compute_failed')
     @step
     def compute(self):
         self.div = self.input
         self.x = 5 / self.div
         self.next(self.join)
 
     @step
     def join(self, inputs):
         for input in inputs:
             if input.compute_failed:
                 print('compute failed for parameter: %d' % input.div)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     CatchFlow()
 ```
 
 As you can guess, the above flow raises an error. Normally, this would crash the whole
 flow. However, in this example the `catch` decorator catches the exception and stores it
 in an instance variable called `compute_failed`, and lets the execution continue. The
 next step, `join`, contains logic to handle the exception.
 
 The `var` argument is optional. The exception is not stored unless you specify it. You
 can also specify `print_exception=False` to prevent the `catch` decorator from printing
 out the caught exception on stdout.",H3,https://docs.metaflow.org/scaling/failures#exceptions-raised-by-your-code,False,1713,369,https://docs.metaflow.org
261,Platform Exceptions,"You could have dealt with the above error by wrapping the whole step in a `try ...
 except` block. In effect, this is how `catch` deals with errors raised in the user code.
 
 In contrast, platform issues happen outside of your code, so you can't handle them with
 a `try ... except` block.
 
 Let's simulate a platform issue like these with the following flow that kills itself
 without giving Python a chance to recover:
 
 ```python
 from metaflow import FlowSpec, step, retry, catch
 
 class SuicidalFlow(FlowSpec):
 
     @catch(var='start_failed')
     @retry
     @step
     def start(self):
         import os, signal
         # kill this process with the KILL signal
         os.kill(os.getpid(), signal.SIGKILL)
         self.next(self.end)
 
     @step
     def end(self):
         if self.start_failed is not None:
             print(""It seems 'start' did not survive."")
 
 if __name__ == '__main__':
     SuicidalFlow()
 ```
 
 Note that we use both `retry` and `catch` above. `retry` attempts to run the step three
 times, hoping that the issue is transient. The hope is futile. The task kills itself
 every time.
 
 After all retries are exhausted, `catch` takes over and records an exception in
 `start_failed`, notifying that all attempts to run `start` failed. Now it is up to the
 subsequent steps, `end` in this case, to deal with the scenario that `start` produced no
 results whatsoever. They can choose an alternative code path using the variable assigned
 by `catch`, `start_failed` in this example.",H3,https://docs.metaflow.org/scaling/failures#platform-exceptions,False,1523,307,https://docs.metaflow.org
262,Timing out with the `timeout` Decorator,"By default, there is no timeout for steps. If you cause an infinite loop accidentally or
 query an external service that hangs, the step will block the flow forever. This is
 undesirable especially in production runs that should not require human intervention.
 
 Metaflow provides a `timeout` decorator to address this issue:
 
 ```python
 from metaflow import FlowSpec, timeout, step
 import time
 
 class TimeoutFlow(FlowSpec):
 
     @timeout(seconds=5)
     @step
     def start(self):
         for i in range(100):
             print(i)
             time.sleep(1)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     TimeoutFlow()
 ```
 
 Here, the `start` step times out after five seconds. Besides `seconds`, you can specify
 `minutes` and/or `hours` as the timeout value. Note that all values specified are
 cumulative so specifying 10 seconds and 5 minutes will result in a timeout of 5 minutes
 and 10 seconds.
 
 The above example raises an exception if the step does not finish in the given time
 period. This is a good pattern if the timeout is a genuine error condition.
 
 In some cases you can handle a timeout in subsequent steps. Similar to `SuicidalFlow`
 above, you can use the `catch` decorator to catch the timeout exception:
 
 ```python
 from metaflow import FlowSpec, timeout, step, catch
 import time
 
 class CatchTimeoutFlow(FlowSpec):
 
     @catch(print_exception=False, var='timeout')
     @timeout(seconds=5)
     @step
     def start(self):
         for i in range(100):
             print(i)
             time.sleep(1)
         self.next(self.end)
 
     @step
     def end(self):
         if self.timeout:
             print('the previous step timed out')
         else:
             print('all ok!')
 
 if __name__ == '__main__':
     CatchTimeoutFlow()
 ```
 
 This example handles a timeout in `start` gracefully without showing any exceptions.",H2,https://docs.metaflow.org/scaling/failures#timing-out-with-the-timeout-decorator,False,1941,436,https://docs.metaflow.org
263,Summary,"Here is a quick summary of failure handling in Metaflow:
 
 * Use `retry` to deal with transient platform issues. You can do this easily on the
   command line with the `--with retry` option.
 * Use `retry` **with** `catch` for extra robustness if you have modified your code to
   deal with faulty steps which are handled by `catch`.
 * Use `catch` **without** `retry` to handle steps [that can't be retried
   safely](failures.md#how-to-prevent-retries). It is a good idea to use `times=0` for
   `retry` in this case.
 * Use `timeout` with any of the above if your code can get stuck.",H2,https://docs.metaflow.org/scaling/failures#summary,False,587,106,https://docs.metaflow.org
264,Managing External Libraries,"What if your step code wants to import an external library? When you run Metaflow code
 locally, it behaves as any other Python code, so all libraries available to your Python
 interpreter can be imported in steps.
 
 However, a core benefit of Metaflow is that the same code can be run in different
 environments without modifications. Clearly this promise does not hold if a step code
 depends on locally installed libraries. The topic of providing isolated and encapsulated
 execution environments is a surprisingly complex one. We recommend the following
 approaches for handling external libraries, in order of preference:
 
 1. If your code needs an additional Python module, for instance, a library module that
    you wrote by yourself, you can place the file in the same directory with your flow
    file. When Metaflow packages your code for remote execution, any `.py` files in the
    directory are included in the distribution automatically. In this case, you can
    simply `import mymodule` in the step code. This works even with packages with
    multiple files which can be included as subdirectories.
 2. If you need a custom package that is too complex to include in the flow directory,
    one approach is to install it on the fly in your step code:
 
    ```
    os.system('pip install my_package')
    import my_package
    ```
 
    This approach is, however, not encouraged for multiple reasons:
 
    1. It makes the results harder to reproduce since the version of `my_package` may
       change;
    2. `pip install`ing packages on the fly is brittle, especially if performed in tasks
       running in parallel.
 
    Instead, to define external dependencies for a step, you can instead use the `@conda`
    decorator which uses [conda](https://docs.conda.io/en/latest/) behind the scenes.",H1,https://docs.metaflow.org/scaling/dependencies#managing-external-libraries,False,1817,338,https://docs.metaflow.org
265,Managing dependencies with `@conda` decorator,"Reproducibility is a core value of Machine Learning Infrastructure. It is hard to
 collaborate on data science projects effectively without being able to reproduce past
 results reliably. Metaflow tries to solve several questions related to reproducible
 research, principle amongst them, dependency management: how can you, the data
 scientist, specify libraries that your code needs so that the results are reproducible?
 
 Note that reproducibility and dependency management are related but separate topics. We
 could solve either one individually. A classic `os.system(‘pip install pandas’)` is an
 example of dependency management without reproducibility (what if the version of
 `pandas` changes?). On the other hand, we could make code perfectly reproducible by
 forbidding external libraries - reproducibility without dependency management.
 
 Metaflow aims at solving both the questions at once: how can we handle dependencies so
 that the results are reproducible? Specifically, it addresses the following three
 issues:
 
 1. How to make external dependencies available locally during development?
 2. How to execute code remotely on Kubernetes or AWS Batch with external dependencies?
 3. How to ensure that anyone can reproduce past results even months later?
 
 Metaflow provides an execution environment context, `--environment=conda`, which runs
 every step in a separate environment that only contains dependencies that are explicitly
 listed as requirements for that step. The solution relies on
 [Conda](https://conda.io/docs/), a language-agnostic open-source package manager by the
 authors of Numpy.
 
 For instance:
 
 ```python
 @conda(libraries={""pandas"": ""0.22.0""})
 def fit_model(self):
     ...
 ```
 
 The above code snippet will execute the `fit_model` step in an automatically created
 conda environment that contains only specific pinned versions of `Python`, `Pandas`, and
 `Metaflow`(and its dependencies `boto3`, `click` and `requests`). No unspecified
 libraries outside of the standard Python library would be available. This isolates your
 code from any external factors, such as automatically upgrading libraries.
 
 Internally, Metaflow handles automatic dependency resolution, cross-platform support,
 environment snapshotting and caching in Amazon S3 (if enabled). We require that all
 dependencies are pinned to a specific version. This avoids any ambiguity about the
 version used and helps make deployments fully immutable; in other words, once you deploy
 a version in production, nothing will inadvertently change its behavior without explicit
 action.",H2,https://docs.metaflow.org/scaling/dependencies#managing-dependencies-with-conda-decorator,False,2599,362,https://docs.metaflow.org
266,Local Execution,"Let's look at the [LinearFlow](/metaflow/basics.md#linear) from before:
 
 ```python
 from metaflow import FlowSpec, step
 
 class LinearFlow(FlowSpec):
 
     @step
     def start(self):
         self.my_var = 'hello world'
         self.next(self.a)
 
     @step
     def a(self):
         print('the data artifact is: %s' % self.my_var)
         self.next(self.end)
 
     @step
     def end(self):
         print('the data artifact is still: %s' % self.my_var)
 
 if __name__ == '__main__':
     LinearFlow()
 ```
 
 You can execute this flow in a conda environment by executing:
 
 ```bash
 $ python LinearFlow.py --environment=conda run
 ```
 
 Metaflow will bootstrap a dedicated conda environment for each of the steps of the
 workflow, executing each of them in that isolated environment, resulting in an output
 like this -
 
 ```bash
 2019-11-27 20:04:27.579 Bootstrapping conda environment...(this could take a few minutes)
 2019-11-27 20:05:13.623 Workflow starting (run-id 164):
 2019-11-27 20:05:14.273 [164/start/4222215 (pid 14011)] Task is starting.
 2019-11-27 20:05:16.426 [164/start/4222215 (pid 14011)] Task finished successfully.
 2019-11-27 20:05:17.246 [164/a/4222216 (pid 14064)] Task is starting.
 2019-11-27 20:05:19.014 [164/a/4222216 (pid 14064)] the data artifact is: hello world
 2019-11-27 20:05:19.484 [164/a/4222216 (pid 14064)] Task finished successfully.
 2019-11-27 20:05:20.192 [164/end/4222217 (pid 14117)] Task is starting.
 2019-11-27 20:05:21.756 [164/end/4222217 (pid 14117)] the data artifact is still: hello world
 2019-11-27 20:05:22.436 [164/end/4222217 (pid 14117)] Task finished successfully.
 2019-11-27 20:05:22.512 Done!
 ```
 
 You might notice some delay when you execute this flow for the first time, as Metaflow
 performs dependency resolution, creates the environments and caches the results.
 Subsequent executions rely on this cache to reduce this overhead going forward.
 
 Let’s import the module `sklearn` in one of the steps -
 
 ```python
 from metaflow import FlowSpec, step
 
 class LinearFlow(FlowSpec):
 
     @step
     def start(self):
         import sklearn
         self.my_var = 'hello world'
         self.next(self.a)
 
     @step
     def a(self):
         print('the data artifact is: %s' % self.my_var)
         self.next(self.end)
 
     @step
     def end(self):
         print('the data artifact is still: %s' % self.my_var)
 
 if __name__ == '__main__':
     LinearFlow()
 ```
 
 Let's execute this flow in a conda environment, again, by executing:
 
 ```bash
 $ python LinearFlow.py --environment=conda run
 ```
 
 You will notice that the execution progresses fairly quickly compared to before since
 all the specified dependencies are already cached locally, but the flow fails at step
 `start`, with the error `` `ModuleNotFoundError: No module named ‘sklearn’` ``, even
 though you might have the module installed locally already.
 
 You can add an explicit dependency on the module `sklearn` by using the `@conda`
 decorator in the `start` step -
 
 ```python
 from metaflow import FlowSpec, step, conda
 
 class LinearFlow(FlowSpec):
 
     @conda(libraries={'scikit-learn':'0.21.1'})
     @step
     def start(self):
         import sklearn
         self.my_var = 'hello world'
         self.next(self.a)
 
     @step
     def a(self):
         print('the data artifact is: %s' % self.my_var)
         self.next(self.end)
 
     @step
     def end(self):
         print('the data artifact is still: %s' % self.my_var)
 
 if __name__ == '__main__':
     LinearFlow()
 ```
 
 Let’s execute this flow, in the conda environment again -
 
 ```bash
 $ python LinearFlow.py --environment=conda run
 ```
 
 You will notice that bootstrapping takes a little bit longer than before as we pull in
 the new set of dependencies (`scikit-learn` `0.21.1` and its dependencies) and the flow
 succeeds. `scikit-learn 0.21.1` is only available to the step `start` and no other step.
 
 Every subsequent execution of your flow is guaranteed to execute in the same environment
 unless you explicitly make a change to the contrary. Behind the scenes, we resolve the
 dependencies you have specified in your steps and cache both the resolution order and
 dependencies (stated and transitive) locally and on Amazon S3 to be used for subsequent
 executions. We do this to isolate your code from changes not related to your code. This
 also allows for isolation between runs, you should be able to use a different version of
 tensorflow for different flows and even across different steps of the same flow if that
 suits your use-case.",H3,https://docs.metaflow.org/scaling/dependencies#local-execution,False,4602,843,https://docs.metaflow.org
267,Remote Execution,"You can execute your flow on Kubernetes or AWS Batch, like before -
 
 ```bash
 $ python LinearFlow.py --environment=conda run --with kubernetes
 ```
 
 ```bash
 $ python LinearFlow.py --environment=conda run --with batch
 ```
 
 Since we cache the exact set of dependencies (stated and transitive) for your flow in
 Amazon S3, you are not at the mercy of an upstream package repository and can avoid
 overwhelming it, particularly while running multiple parallel tasks, while being
 guaranteed the same execution environment locally, on Kubernetes and on AWS Batch.
 
 Note that, the exact set of dependencies and their behavior might differ between an
 execution on macOS (darwin) and on Kubernetes/AWS Batch (linux).",H3,https://docs.metaflow.org/scaling/dependencies#remote-execution,False,719,111,https://docs.metaflow.org
269,"Can I use an alternate dependency manager, given that conda can be slow at resolving dependencies?","By default, Metaflow relies on conda for dependency resolution but for many data science
 packages, conda can be quite slow for [a variety of different
 reasons](https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/conda-performance.html#conda-performance).
 [Mamba](https://mamba.readthedocs.io/en/latest/) is another cross-platform package
 manager that is fully compatible with conda packages and [offers better performance and
 reliability compared to conda](https://stackoverflow.com/a/68043228/6510628). You can
 use mamba instead of conda by setting the environment variable
 `METAFLOW_CONDA_DEPENDENCY_RESOLVER=mamba` either in your execution environment or
 inside your metaflow config (usually located at `~/.metaflowconfig/`).",H4,https://docs.metaflow.org/scaling/dependencies#can-i-use-an-alternate-dependency-manager-given-that-conda-can-be-slow-at-resolving-dependencies,False,751,75,https://docs.metaflow.org
270,How do I specify the version of Python interpreter?,"By default, we take the version of the Python interpreter with which you invoke your
 flow. You can override it whatever version you choose, e.g, `@conda(python='3.6.5')`.",H4,https://docs.metaflow.org/scaling/dependencies#how-do-i-specify-the-version-of-python-interpreter,False,171,26,https://docs.metaflow.org
271,What about storing and retrieving data artifacts between steps in my flow?,"Metaflow relies on pickle for object serialization/deserialization. Make sure you have
 compatible versions (ideally the same version) of the object module as a dependency in
 your steps which rely on interacting with this object artifact.",H4,https://docs.metaflow.org/scaling/dependencies#what-about-storing-and-retrieving-data-artifacts-between-steps-in-my-flow,False,239,35,https://docs.metaflow.org
272,How do I specify flow-level dependencies?,"Using the flow-level `@conda_base` decorator you can specify, for the flow, explicit
 library dependencies, python version and also if you want to exclude all steps from
 executing within a conda environment. Some examples -
 
 ```python
 @conda_base(libraries={'numpy':'1.15.4'}, python=’3.6.5’)
 class LinearFlow(FlowSpec):
     ...
 ```
 
 ```python
 @conda_base(disabled=True)
 class LinearFlow(FlowSpec):
     ...
 ```
 
 Step-level `@conda` decorators, for the step, will directly update the explicit library
 dependencies, python version, and conda environment exclusion as specified by the
 `@conda_base` decorator. Some examples:
 
 ```python
 from metaflow import FlowSpec, step, conda, conda_base
 
 @conda_base(libraries={'numpy':'1.15.4'}, python='3.6.5')
 class MyFlow(FlowSpec):
     @step
     def a(self):
        ...
 
     @conda(libraries={'numpy':'1.16.3'})
     @step
     def b(self):
        ...
 
     @conda(disabled=True)
     @step
     def c(self):
        ...
 ```
 
 In this example, step `a` executes in the environment `libraries={'numpy':'1.15.4'},
 python=’3.6.5’`, step `b` executes in the environment `libraries={'numpy':'1.16.3'},
 python=’3.6.5’`, while step `c` executes outside the conda environment in the user
 environment.",H4,https://docs.metaflow.org/scaling/dependencies#how-do-i-specify-flow-level-dependencies,False,1266,201,https://docs.metaflow.org
273,Loading and Storing Data,"This chapter describes tools and patterns for moving data in and out of your Metaflow
 flows.
 
 Besides the mundane concern of loading data, there is also the question of how to
 organize code related to model-specific data transformations, such as feature
 engineering. Short answer: [keep data access separate from feature
 engineering](http://en.wikipedia.org/wiki/Separation\_of\_concerns).
 
 In a perfect world, the data scientist could design and test features without having to
 concern themselves with the underlying mechanics of data transfer and processing.
 Unfortunately the larger the dataset, the more intermingled the two concerns become.
 
 Metaflow can not make the world perfect yet. However, we recommend that data science
 workflows try to keep the two concerns as separate as possible. In practice, you should
 use the solutions presented in this chapter purely to load a clean dataset in your
 workflow. Then, you should perform any model-specific data transformations in your
 Python code. In particular, we recommend that you use SQL only for data access, not for
 model-specific data manipulation.
 
 There are multiple benefits in keeping data access separate from model-specific data
 manipulation:
 
 * It is easier to keep a model and its features in sync when they are computed together.
   [Metaflow's built-in versioning](/scaling/tagging.md#tagging) makes it easy to iterate
   on multiple concurrent versions of the model safely. However, Metaflow can't protect
   you against stale input data. It is frustrating to troubleshoot bad model results that
   are caused by out-of-sync features.
 * It is quicker to iterate on your model. Testing and debugging Python is easier than
   testing and debugging SQL.
 * You can request [arbitrary amount of resources](/scaling/remote-tasks/introduction)
   for your data manipulation needs.
 * Instead of having data manipulation code in two places (SQL and Python), all code can
   be clearly laid out in a single place, in a single language, for maximum readability.
 * It is easier to optimize your code for performance when IO bottlenecks can be profiled
   separately from CPU bottlenecks.
 
 Keep this guideline in mind when choosing the right data access method below.&#x20;",H1,https://docs.metaflow.org/scaling/data#loading-and-storing-data,False,2258,352,https://docs.metaflow.org
274,Data in Tables,"Accessing data in tables (most often Hive) is by far the most common way to load input
 data to Metaflow workflows. A common paradigm is to issue arbitrary SQL queries against
 the data warehouse to fetch data.
 
 :::info
 
 See [Accessing Secrets](/scaling/secrets) if your database or query engine requires
 authentication.
 
 :::
 
 However, depending on the data volume and the complexity of the query, queries
 can be slow to execute and can potentially congest the query engine. It is not
 uncommon for a data science workflow to hit these limitations. Even if your
 data set is not huge, you may want to build multiple models in parallel, e.g.
 one per country. In this case, each model needs to load a shard of data. If you
 used SQL to load the shards, it will very quickly overload your query engine.
 
 As a solution, [`metaflow.S3`](data.md#data-in-s3-metaflows3) provides a way to load
 data directly from S3, bypassing any query engines such as Spark. Combined with a
 [metadata catalog](https://github.com/Netflix/metacat), it is easy to write shims on top
 of `metaflow.S3` to directly interface with data files on S3 backing your tables. Since
 data is loaded directly from S3, there is no limitation to the number of parallel
 processes. The size of data is only limited by the size of your instance, which can be
 easily controlled with [the `@resources`
 decorator](/scaling/remote-tasks/introduction#requesting-resources-with-resources-decorator).
 The best part is that this approach is blazingly fast compared to executing SQL.
 
 The main downside of this approach is that the table needs to have partitions that match
 your access pattern. For small and medium-sized tables, this isn't necessarily an issue
 as you can afford loading extra data. Additional filtering can be performed in your
 Python code. With larger tables this approach is not feasible, so you may need to run an
 extra SQL query to repartition data properly.",H2,https://docs.metaflow.org/scaling/data#data-in-tables,False,1953,309,https://docs.metaflow.org
275,Use cases,"* Workflows that need to process large amounts of data.
 * Workflows that build many models in parallel.
 * Performance-oriented workflows.",H3,https://docs.metaflow.org/scaling/data#use-cases,False,139,21,https://docs.metaflow.org
276,Data in S3: `metaflow.S3`,"*This section contains an overview of `metaflow.S3`. For a complete API, see [the API
 reference for the S3 class](/api/s3).*
 
 It is not always appropriate to store data in a table. For instance, Netflix has many
 systems that communicate via JSON files in S3. Or, there is little benefit in storing a
 large Keras model serialized with
 [`model.save()`](https://keras.io/getting-started/faq/#how-can-i-save-a-%20keras-model)
 in a table.
 
 When you assign anything to `self` in your Metaflow flow, the object gets automatically
 persisted in S3 as [a Metaflow artifact](/metaflow/basics.md#linear). Hence, in most
 cases you do not need to worry about saving data or models to S3 explicitly. We
 recommend that you use Metaflow artifacts whenever possible, since they are easily
 accessible through [the Client API](/metaflow/client.md) by you, by other people, and by
 other workflows.
 
 However, there are valid reasons for interacting with S3 directly. For instance, you may
 need to consume or produce data to a 3rd party system that knows nothing about Metaflow.
 For use cases like this, we provide a high-performance S3 client, `metaflow.S3`.
 
 The sole benefit of `metaflow.S3` over Metaflow artifacts is that you get to see and
 control the S3 locations for data. Also, you must take care of object serialization by
 yourself: `metaflow.S3` only deals with objects of type `str`, `unicode`, and `bytes`.
 
 Compared to other S3 clients `metaflow.S3` provides two key benefits: First, when used
 in Metaflow flows, it can piggyback on Metaflow versioning, which makes it easy to track
 the lineage of an object back to the Metaflow run that produced it. Secondly,
 `metaflow.S3` provides better throughput than any other S3 client that we are aware of.
 In other words, it is very fast at loading and storing large amounts of data in S3.",H2,https://docs.metaflow.org/scaling/data#data-in-s3-metaflows3,False,1851,288,https://docs.metaflow.org
277,**Pros**,"* Load and store data to/from arbitrary S3 locations.
 * Built-in support for lineage and versioning.
 * Maximum throughput between S3 and a compute instance.",H4,https://docs.metaflow.org/scaling/data#pros,False,158,25,https://docs.metaflow.org
278,**Cons**,"* Don't use `metaflow.S3` if you can use Metaflow artifacts instead. In contrast to
   Metaflow artifacts, `metaflow.S3` is more tedious to use, uses space more wastefully,
   and it is less suitable for [moving data between Metaflow steps
   reliably](data.md#caution-overwriting-data-in-s3).",H4,https://docs.metaflow.org/scaling/data#cons,False,293,44,https://docs.metaflow.org
279,Use cases,"* Communication with external systems through files in S3.
 * Special corner cases where you need more control over object serialization than what
   Metaflow artifacts provide by default.
 
 We recommend that you use `metaflow.S3` in a `with` scope in Python. Objects retrieved
 from S3 are stored in local temporary files for the lifetime of the `with` scope, not in
 memory. You can use `metaflow.S3` without `with` but in this case you need to call
 `s3.close()` to get rid of the temporary files. See examples of this below.
 
 Note that in order to get the maximum performance out of `metaflow.S3`, you need to set
 your `@resources` properly. However, don't request more resources than what your
 workload actually needs.",H3,https://docs.metaflow.org/scaling/data#use-cases,False,728,121,https://docs.metaflow.org
280,Choosing the context,"To benefit from the built-in support for versioning, first you need to tell
 `metaflow.S3` whether it is being used in the context of a Metaflow run. A run can refer
 to a currently running flow (`run=self`) or a past run, `run=Run(...)`. If `run` is not
 specified, `metaflow.S3` can be used to access data without versioning in arbitrary S3
 locations.",H3,https://docs.metaflow.org/scaling/data#choosing-the-context,False,354,59,https://docs.metaflow.org
281,**Store and load objects in a Metaflow flow**,"We expect that the most common use case for `metaflow.S3` is to store auxiliary data in
 a Metaflow flow. Here is an example:
 
 ```python
 from metaflow import FlowSpec, step, S3
 import json
 
 class S3DemoFlow(FlowSpec):
 
     @step
     def start(self):
         with S3(run=self) as s3:
             message = json.dumps({'message': 'hello world!'})
             url = s3.put('example_object', message)
             print(""Message saved at"", url)
         self.next(self.end)
 
     @step
     def end(self):
         with S3(run=self) as s3:
             s3obj = s3.get('example_object')
             print(""Object found at"", s3obj.url)
             print(""Message:"", json.loads(s3obj.text))
 
 if __name__ == '__main__':
     S3DemoFlow()
 ```
 
 Running the flow produced the following output:
 
 ```bash
 Workflow starting (run-id 3):
 [3/start/646436 (pid 30559)] Task is starting.
 [3/start/646436 (pid 30559)] Message saved at s3://my-bucket/metaflow/userdata/v1/S3DemoFlow/3/example_object
 [3/start/646436 (pid 30559)] Task finished successfully.
 [3/end/646437 (pid 30619)] Task is starting.
 [3/end/646437 (pid 30619)] Object found at s3://my-bucket/metaflow/userdata/v1/S3DemoFlow/3/example_object
 [3/end/646437 (pid 30619)] Message: {'message': 'hello world!'}
 [3/end/646437 (pid 30619)] Task finished successfully.
 ```
 
 Now you could share the URL,
 `s3://my-bucket/metaflow/userdata/v1/S3DemoFlow/3/example_object`, with external
 systems. Note that the URL includes both the flow name, `S3DemoFlow`, as well as its
 unique run id, `3`, which allow us to track the lineage of the object back to the run
 that produced it.
 
 Note that `metaflow.S3` provides a default S3 location for storing data. You could
 change the location by defining `S3(bucket='my-bucket', prefix='/my/prefix')` for the
 constructor. Metaflow versioning information would be concatenated to the `prefix`.",H4,https://docs.metaflow.org/scaling/data#store-and-load-objects-in-a-metaflow-flow,False,1905,337,https://docs.metaflow.org
282,**Load external objects produced by a Metaflow run**,"What if you want to inspect S3 data produced by a flow afterwards? Just use [the Client
 API](/metaflow/client.md) as usual to locate the desired `Run` and use it to initialize
 an `S3` object:
 
 ```python
 from metaflow import S3
 with S3(run=Flow('S3DemoFlow').latest_run) as s3:
     print(s3.get('example_object').text)
 
 {""message"": ""hello world!""}
 ```
 
 This pattern is particularly convenient for notebooks.",H4,https://docs.metaflow.org/scaling/data#load-external-objects-produced-by-a-metaflow-run,False,418,61,https://docs.metaflow.org
283,**Store and load objects to/from a known S3 location**,"The above examples inferred the S3 location based on the current or an existing Metaflow
 run. What if you want to load data that has nothing to do with Metaflow? Easy:
 
 ```python
 from metaflow import S3
 with S3() as s3:
     res = s3.get('s3://my-bucket/savin/tmp/external_data')
     print('an alien message: %s' % res.text)
 
 an alien message: I know nothing about Metaflow
 ```
 
 If `S3` is initialized without any arguments, all operations require a full S3 URL.
 
 If you need to operate on multiple files, it may be more convenient to specify a custom
 S3 prefix with the `s3root` argument:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo/') as s3:
     s3.put('fruit', 'pineapple')
     s3.put('animal', 'mongoose')
 with S3() as s3:
     s3.get('s3://my-bucket/savin/tmp/s3demo/fruit').text
 
 pineapple
 ```
 
 If the requested URL does not exist, the `get` call will raise an exception. You can
 call `get` with `return_missing=True` if you want to return a missing URL as an ordinary
 result object, as described in the section below.
 
 By default, `put_*` calls will overwrite existing keys in S3. To avoid this behavior you
 can invoke your `put_*` calls with `overwrite=False`. Refer to [this
 section](data.md#caution-overwriting-data-in-s3) for some of the pitfalls involved with
 overwriting keys in S3.",H4,https://docs.metaflow.org/scaling/data#store-and-load-objects-to-from-a-known-s3-location,False,1367,219,https://docs.metaflow.org
284,The S3 result object,"All `get` operations return an `S3Object`, backed by a temporary file on local disk,
 which exposes a number of attributes about the object:
 
 ```python
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo/') as s3:
     s3obj = s3.get('fruit')
     print('location', s3obj.url)
     print('key', s3obj.key)
     print('size', s3obj.size)
     print('local path', s3obj.path)
     print('bytes', s3obj.blob)
     print('unicode', s3obj.text)
     print('metadata', s3obj.metadata)
     print('content-type', s3obj.content_type)
     print('downloaded', s3obj.downloaded)
 
 location s3://my-bucket/savin/tmp/s3demo/fruit
 key fruit
 size 9
 local path /data/metaflow/metaflow.s3.5agi129m/metaflow.s3.one_file.pih_iseg
 bytes b'pineapple'
 unicode pineapple
 metadata None
 content-type application/octet-stream
 downloaded True
 ```
 
 Note that you can not access data behind `s3obj` outside the `with` scope as the
 temporary file pointed at `s3obj.path` will get deleted as the scope exits.
 
 The `S3Object` may also refer to an S3 URL that does not correspond to an object in S3.
 These objects have `exists` property set to `False`. Non-existent objects may be
 returned by a `list_path` call, if the result refers to an S3 prefix, not an object.
 Listing operations also set `downloaded` property to `False`, to distinguish them from
 operations that download data locally. Also `get` and `get_many` may return non-existent
 objects if you call these methods with an argument `return_missing=True`.",H3,https://docs.metaflow.org/scaling/data#the-s3-result-object,False,1502,221,https://docs.metaflow.org
285,**Querying objects without downloading them**,"The above information about an object, like `size` and `metadata`, can be useful even
 without downloading the file itself. To just get the metadata, use the `info` and
 `info_many` calls that work like `get` and `get_many` but avoid the potentially
 expensive downloading part. The info calls set `downloaded=False` in the result object.",H4,https://docs.metaflow.org/scaling/data#querying-objects-without-downloading-them,False,338,52,https://docs.metaflow.org
286,Operations on multiple objects,"After you have instantiated the object given the right context information, all `get`
 and `put` operations work equally. The context is only used to construct an appropriate
 S3 URL.
 
 Besides loading individual files with `.get()` and `.put()` as shown above,
 `metaflow.S3` really shines at operating multiple files at once.
 
 It is guaranteed that the list of `S3Objects` returned is always in the same order as
 long as the underlying data does not change. This can be important e.g. if you use
 `metaflow.S3` to feed data for a model. The input data will be in a deterministic order
 so results should be easily reproducible.",H3,https://docs.metaflow.org/scaling/data#operations-on-multiple-objects,False,633,105,https://docs.metaflow.org
287,**Load multiple objects in parallel**,"Use `get_many()` to load arbitrarily many objects at once:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo/') as s3:
     s3.get_many(['fruit', 'animal'])
 
 [<S3Object s3://my-bucket/savin/tmp/s3demo/fruit (9 bytes)>,
  <S3Object s3://my-bucket/savin/tmp/s3demo/animal (8 bytes)>]
 ```
 
 Here, `get_many()` loads objects in parallel, which is much faster than loading
 individual objects sequentially. You can achieve the optimal throughput with S3 only
 when you operate on many files in parallel.
 
 If one of the requested URLs doesn't exist, the `get_many` call will raise an exception.
 If you don't want to fail all objects because of missing URLs, call `get_many` with
 `return_missing=True`. This will make `get_many` return missing URLs amongst other
 results. You can distinguish between the found and not found URLs using the `exists`
 property of `S3Object`.",H4,https://docs.metaflow.org/scaling/data#load-multiple-objects-in-parallel,False,911,127,https://docs.metaflow.org
288,**Load all objects recursively under a prefix**,"We can load all objects under a given prefix:
 
 ```python
 from metaflow import S3
 with S3() as s3:
     s3.get_recursive(['s3://my-bucket/savin/tmp/s3demo'])
 
 [<S3Object s3://my-bucket/savin/tmp/s3demo/animal (8 bytes)>,
  <S3Object s3://my-bucket/savin/tmp/s3demo/fruit (9 bytes)>]
 ```
 
 Note that `get_recursive` takes a list of prefixes. This is useful for achieving the
 maximum level of parallelism when retrieving data under multiple prefixes.
 
 If you have specified a custom `s3root`, you can use `get_all()` to get all files
 recursively under the given prefix.",H4,https://docs.metaflow.org/scaling/data#load-all-objects-recursively-under-a-prefix,False,578,81,https://docs.metaflow.org
289,Loading parts of files,"A performance-sensitive application may want to read only a part of a large file.
 Instead of a string, the `get` and `get_many` calls also accept an object with `key`,
 `offset`, `length` attributes that specify a part of a file to download. You can use an
 object called `S3GetObject` provided by Metaflow for this purpose.
 
 This example loads two 1KB chunks of a file in S3:
 
 ```python
 from metaflow import S3
 from metaflow.datatools.s3 import S3GetObject
 
 URL = 's3://ursa-labs-taxi-data/2014/12/data.parquet'
 
 with S3() as s3:
     res = s3.get_many([S3GetObject(key=URL, offset=0, length=1024),
                        S3GetObject(key=URL, offset=1024, length=1024)])
 
     for obj in res:
         print(obj.path, obj.size)
 ```",H4,https://docs.metaflow.org/scaling/data#loading-parts-of-files,False,746,140,https://docs.metaflow.org
290,**Store multiple objects or files**,"If you need to store multiple objects, use `put_many`:
 
 ```python
 from metaflow import S3
 many = {'first_key': 'foo', 'second_key': 'bar'}
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_put/') as s3:
     s3.put_many(many.items())
 
 [('first_key', 's3://my-bucket/savin/tmp/s3demo_put/first_key'),
  ('second_key', 's3://my-bucket/savin/tmp/s3demo_put/second_key')]
 ```
 
 You may want to store more data to S3 than what you can fit in memory at once. This is a
 good use case for `put_files`:
 
 ```python
 from metaflow import S3
 with open('/tmp/1', 'w') as f:
     f.write('first datum')
 with open('/tmp/2', 'w') as f:
     f.write('second datum')
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_put/') as s3:
     s3.put_files([('first_file', '/tmp/1'), ('second_file', '/tmp/2')])
 
 [('first_file', 's3://my-bucket/savin/tmp/s3demo_put/first_file'),
  ('second_file', 's3://my-bucket/savin/tmp/s3demo_put/second_file')]
 ```
 
 Objects are stored in S3 in parallel for maximum throughput.",H4,https://docs.metaflow.org/scaling/data#store-multiple-objects-or-files,False,1005,122,https://docs.metaflow.org
291,**Listing objects in S3**,"To get objects with `get` and `get_many`, you need to know the exact names of the
 objects to download. S3 is optimized for looking up specific names, so it is preferable
 to structure your code around known names. However, sometimes this is not possible and
 you need to check first what is available in S3.
 
 Metaflow provides two ways to list objects in S3: `list_paths` and `list_recursive`. The
 first method provides the next level of prefixes (directories) in S3, directly under the
 given prefix. The latter method provides all objects under the given prefix. Since
 `list_paths` returns a subset of prefixes returned by `list_recursive`, it is typically
 a much faster operation.
 
 Here's an example: First, let's create files in S3 in a hierarchy like this:
 
 ```
 first/a/object1
 first/b/x/object2
 second/c/object3
 ```
 
 ```python
 from metaflow import S3
 many = {'first/a/object1': 'data',
         'first/b/x/object2': 'data',
         'second/c/object3': 'data'}
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_list/') as s3:
     s3.put_many(many.items())
 ```
 
 Next, let's list all directories using `list_paths`:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_list/') as s3:
     for key in s3.list_paths():
         print key.key
 
 first
 second
 ```
 
 You can list multiple prefixes in parallel by giving `list_paths` a list of prefixes:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_list/') as s3:
     for key in s3.list_paths(['first', 'second']):
         print key.key
 
 a
 b
 c
 ```
 
 Listing may return either prefixes (directories) or objects. To distinguish between the
 two, use the `.exists` property of the returned `S3Object`:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_list/') as s3:
     for key in s3.list_paths(['first/a', 'first/b']):
         print key.key, 'object' if key.exists else 'prefix'
 
 object1 object
 x prefix
 ```
 
 If you want all objects under the given prefix, use the `list_recursive` method:
 
 ```python
 from metaflow import S3
 with S3(s3root='s3://my-bucket/savin/tmp/s3demo_list/') as s3:
     for key in s3.list_recursive():
         print key.key
 
 first/a/object1
 first/b/x/object2
 second/c/object3
 ```
 
 Similar to `list_paths`, `list_recursive` can take a list of prefixes to process in
 parallel.
 
 A common pattern is to list objects using either `list_paths` or `list_recursive`,
 filter out some keys from the listing, and provide the pruned list to `get_many` for
 fast parallelized downloading.",H4,https://docs.metaflow.org/scaling/data#listing-objects-in-s3,False,2614,417,https://docs.metaflow.org
292,Caution: Overwriting data in S3,"You should avoid overwriting data in the same key (URL) in S3. S3 guarantees that new
 keys always reflect the latest data. In contrast, when you overwrite data in an existing
 key, there is a short period of time when a reader may see either the old version or the
 new version of the data.
 
 In particular, when you use `metaflow.S3` in your Metaflow flows, make sure that every
 task and step writes to a unique key. Otherwise you may find results unpredictable and
 inconsistent.
 
 Note that specifying `overwrite=False` in your `put_*` calls changes the behavior of S3
 slightly compared to the default mode of `overwrite=True`. There may be a small delay
 (typically in the order of milliseconds) before the key becomes available for reading.
 
 This is an important reason to rely on Metaflow artifacts, which handle this
 complication for you, whenever possible. If you absolutely need to handle this by
 yourself, one way to guarantee uniqueness is to use `current.task_id` from [the
 `current` module](/scaling/tagging.md#accessing-current-ids-in-a-flow) as a part of your
 S3 keys.",H3,https://docs.metaflow.org/scaling/data#caution-overwriting-data-in-s3,False,1094,175,https://docs.metaflow.org
293,Maximizing S3 performance,"S3 can provide massive download speeds, tens of gigabits per second on large instances,
 when using `metaflow.S3`. In order to achieve the maximum throughput, pay attention to
 the following dimensions:",H2,https://docs.metaflow.org/scaling/data#maximizing-s3-performance,False,202,30,https://docs.metaflow.org
294,Using `metaflow.S3` for in-memory processing,"For maximum performance, ensure that
 [the `@resources(memory=)`
 setting](/scaling/remote-tasks/introduction#requesting-resources-with-resources-decorator)
 is higher than the amount of data you are downloading with `metaflow.S3`.
 
 If the amount of data is higher than the available disk space, you can use the
 `use_tmpfs=True` with [`@batch`](/api/step-decorators/batch) an
 [`@kubernetes`](/api/step-decorators/kubernetes) to create an in-memory
 filesystem which `metaflow.S3` will use automatically.
 
 These options are available for `tmpfs`:
 
  - `use_tmpfs=True` enabled a `tmpfs` mountpoint and instructs `metaflow.S3` to use it
    as a destination for downloads. Note that you must ensure that the `tmpfs` size is
    large enough for all data downloaded.
 
  - `tmpfs_tempdir=False` will instruct `metaflow.S3` **to not use** the `tmpfs`. Use
    this option if you want to reserve the `tmpfs` mount for your own use only.
 
  - `tmpfs_size=N` allocates at most `N` megabytes for `tmpfs`. Note that unused space
    doesn't count towards actual memory usage, so you can safely overallocate space. By
    default, 50% of the available memory is made available for `tmpfs`.
 
  - `tmpfs_path=P` allows you to use an alternative mount point for `tmpfs`.
 
 You can access the current `tmpfs` mountpoint in your tasks with
 [`current.tempdir`](/api/current#current.tempdir). You can use it as fast
 temporary disk space for your own needs as well.",H3,https://docs.metaflow.org/scaling/data#using-metaflows3-for-in-memory-processing,False,1459,218,https://docs.metaflow.org
295,Data in Local Files,"Similarly to [Parameters](/metaflow/basics.md#how-to-define-parameters-for-flows), you
 can define a data file to include as input for your flow. Metaflow will version the file
 and make it accessible to all the steps directly through the `self` object in your flow.
 
 This example allows the user to include a data file and compute its hash:
 
 ```python
 from metaflow import FlowSpec, step, IncludeFile
 
 class HashFileFlow(FlowSpec):
     myfile = IncludeFile(
         'myfile',
         is_text=False,
         help='My input',
         default='/Users/bob/myinput.bin')
 
     @step
     def start(self):
         import hashlib
         print('Hello from start')
         print('Hash of file is %s' % \
             str(hashlib.sha1(self.myfile).hexdigest()))
         self.next(self.end)
 
     @step
     def end(self):
         print('Goodbye')
 
 if __name__ == '__main__':
     HashFileFlow()
 ```
 
 You can specify the file to use by using:
 
 ```bash
 python hash_flow.py run --myfile '/path/to/input/file'
 ```",H2,https://docs.metaflow.org/scaling/data#data-in-local-files,False,1029,227,https://docs.metaflow.org
296,Scalable Compute and Data,"After you have [prototyped a flow locally](/metaflow/introduction) and iterated with it
 for a while, you may face questions like these: How can I test the flow with more data
 without running out of memory? Or, how can I make the model train faster? You could try
 to optimize the code to work better on your laptop, but such [premature
 optimization](https://xkcd.com/1691/) is probably not the best use of your time.
 
 Instead, you can leverage the cloud to get a bigger laptop or more laptops (virtually,
 not literally). This is the Stage II in Metaflow development: Scaling flows with the
 cloud. Luckily Metaflow makes this trivially easy - no changes in the code required -
 after you have done the initial legwork to [configure infrastructure for
 Metaflow](/getting-started/infrastructure).
 
 ![](/assets/intro-cartoon-2.svg)",H1,https://docs.metaflow.org/scaling/introduction#scalable-compute-and-data,False,837,128,https://docs.metaflow.org
297,Supersizing Flows,"Here's how Metaflow can help make your project more scalable:
 
 1. You can make your existing flows more scalable just by adding a line of code,
 `@resources`. This way you can request more CPUs, memory, or GPUs in your flows. Or, you
 can parallelize processing over multiple instances, even thousands of them.
 
 2. Once your project starts showing promise with realistic-size workloads, it may start
 attracting interest from colleagues too. Metaflow contains a number of features, such as
 [namespaces](/scaling/tagging), which make collaboration smoother by allowing many
 people contribute without interfering with each other's work accidentally.",H2,https://docs.metaflow.org/scaling/introduction#supersizing-flows,False,653,97,https://docs.metaflow.org
298,Toolbox of Scalability,"There is no single magic formula for scalability. Instead of proposing a novel paradigm
 to make your Python code faster, Metaflow provides a set of pragmatic tools, leveraging
 the best off-the-shelf components and services, which help you make code more scalable
 and performant depending on your specific needs. 
 
 The scalability tools fall into three categories:",H3,https://docs.metaflow.org/scaling/introduction#toolbox-of-scalability,False,368,57,https://docs.metaflow.org
299,What You Will Learn,"In this section, you will learn how to make your flows capable of handling more data and
 execute faster. You will also learn how to scale projects over multiple people by
 organizing results better. We cover five topics:
 
 1. [Executing tasks remotely with Kubernetes or AWS
    Batch](/scaling/remote-tasks/introduction)
 2. [Dealing with failures](/scaling/failures)
 3. [Managing execution environments](/scaling/dependencies)
 4. [Loading and storing data efficiently](/scaling/data)
 5. [Organizing results for smoother collaboration](/scaling/tagging)
 
 Before you proceed, make sure to [configure infrastructure for
 Metaflow](/getting-started/infrastructure) or sign up for a [Metaflow
 Sandbox](https://outerbounds.com/sandbox/).",H2,https://docs.metaflow.org/scaling/introduction#what-you-will-learn,False,741,89,https://docs.metaflow.org
300,Organizing Results,"A boring, under-appreciated part of high-quality science (or any project work in
 general), is keeping results organized. This is the key to effective collaboration,
 versioning of parallel lines of work, and reproducibility.
 
 The good news is that Metaflow does 80% of this work for you without you having to do
 anything. This document explains how Metaflow keeps things organized with a concept
 called **namespaces** and how you can optionally make results even neater with **tags**.",H1,https://docs.metaflow.org/scaling/tagging#organizing-results,False,489,76,https://docs.metaflow.org
301,Namespaces,"As explained in [Creating Flows](/metaflow/basics), Metaflow persists all runs and all
 the data artifacts they produce. Every run gets a unique run ID, e.g. `HelloFlow/546`,
 which can be used to refer to a specific set of results. You can access these results
 with the [Client API](/metaflow/client).
 
 Many users can use Metaflow concurrently. Imagine that Anne and Will are collaborating
 on a project that consists of two flows, `PredictionFlow` and `FeatureFlow`. As they,
 amongst other people, run their versions independently they end up with the following
 runs:
 
 ![](/assets/assets_metaflow_-lpjn0yp7r49jrnxca_5_-lpjryuuy7v5kovmxtsv_namespace1.png)
 
 Anne could analyze her latest `PredictionFlow` results in a notebook by remembering that
 her latest run is `PredictionFlow/8`. Fortunately, Metaflow makes this even easier
 thanks to **namespaces**:
 
 ![](/assets/assets_metaflow_-lpjn0yp7r49jrnxca_5_-lpjryuvqmspdu9w5imb_namespace2.png)
 
 When Anne runs `PredictionFlow`, her runs are automatically **tagged** with her
 username, prefixed with `user:`. By default, when Anne uses the [Client
 API](/metaflow/client) in a notebook or in a Python script, the API only returns results
 that are tagged with `user:anne`. Instead of having to remember the exact ID of her
 latest run, she can simply say:
 
 ```python
 from metaflow import Flow
 
 run = Flow('PredictionFlow').latest_run
 ```
 
 For Anne, this will return `'PredictionFlow/8'`. For Will, this will return
 `'PredictionFlow/5'`.",H2,https://docs.metaflow.org/scaling/tagging#namespaces,False,1509,201,https://docs.metaflow.org
302,Switching Namespaces,"Namespaces are not about security or access control. They help you to keep results
 organized. During development, organizing results by the user who produced them is a
 sensible default.
 
 You can freely explore results produced by other people. In a notebook (for example),
 Anne can write
 
 ```python
 from metaflow import Flow, namespace
 
 namespace('user:will')
 run = Flow('PredictionFlow').latest_run
 ```
 
 to see Will's latest results, in this case, `'PredictionFlow/5'`.
 
 You can also access a specific run given its ID directly:
 
 ```python
 from metaflow import Flow, namespace
 
 run = Run('PredictionFlow/5')
 ```
 
 However, this will fail for Anne, since `PredictionFlow/5` is in Will's namespace. An
 important feature of namespaces is to make sure that you can't accidentally use someone
 else's results, which could lead to hard-to-debug, incorrect analyses.
 
 If Anne wants to access Will's results, she must do so explicitly by switching to Will's
 namespace:
 
 ```python
 from metaflow import Flow, namespace
 
 namespace('user:will')
 run = Run('PredictionFlow/5')
 ```
 
 In other words, you can use the Client API freely without having to worry about using
 incorrect results by accident.
 
 If you use the Client API in your flows to access results of other flows, you can use
 the `--namespace` flag on the command line to switch between namespaces. This is a
 better approach than hardcoding a `namespace()` function call in the code that defines
 your Metaflow workflow.",H3,https://docs.metaflow.org/scaling/tagging#switching-namespaces,False,1508,232,https://docs.metaflow.org
303,Global Namespace,"What if you know a run ID, but you don't know whose namespace it belongs to? No worries,
 you can access all results in the Metaflow universe in the **global namespace**:
 
 ```python
 from metaflow import Flow, namespace
 
 namespace(None)
 run = Run('PredictionFlow/5')
 ```
 
 Setting `namespace(None)` allows you to access all results without limitations. Be
 careful though: relative references like `latest_run` make little sense in the global
 namespace since anyone can produce a new run at any time.",H3,https://docs.metaflow.org/scaling/tagging#global-namespace,False,508,79,https://docs.metaflow.org
304,Production Namespaces,"During development, namespacing by the username feels natural. However, when you
 [schedule your flow to run
 automatically](../production/scheduling-metaflow-flows/introduction/), runs are not
 related to a specific user anymore. It is typical for multiple people to collaborate on
 a project that has a canonical production version. It is not obvious which user ""owns""
 the production version.
 
 Moreover, it is critical that you, and all other people, can keep experimenting on the
 project without having to worry about breaking the production version. If the production
 flow ran in the namespace of any individual, relative references like `latest_run` could
 break the production easily as the user keeps executing experimental runs.
 
 As a solution, by default the production namespace is made separate from the
 usernamespace:
 
 ![](</assets/namespace4_(3).png>)
 
 Isolated production namespaces have three main benefits:
 
 1. Production tokens allow all users of Metaflow to **experiment freely** with any
    project without having to worry about accidentally breaking a production deployment.
    Even if they ran step-functions create, they could not overwrite a production version
    without explicit consent, via a shared production token, by the person who did the
    previous authorized deployment.
 2. An isolated production namespace makes it easy to **keep production results separate
    from any experimental runs** of the same project running concurrently. You can rest
    assured that when you switch to a production namespace, you will see only results
    related to production - nothing more, nothing less.
 3. By having control over the production namespace, you can **alter data that is seen by
    production flows**. For instance, if you have separate training and prediction flows
    in production, the prediction flow can access the previously built model as long as
    one exists in the same namespace. By changing the production namespace, you can make
    sure that a new deployment isn't tainted by old results.
 
 If you are a single developer working on a new project, you don't have to do anything
 special to deal with production namespaces. You can rely on the default behavior of
 `step-functions create`.",H2,https://docs.metaflow.org/scaling/tagging#production-namespaces,False,2258,367,https://docs.metaflow.org
305,Production tokens,"When you deploy a Flow to production for the first time, Metaflow creates a new,
 isolated production namespace for your production flow. This namespace is identified by
 a **production token**, which is a random identifier that identifies a production
 deployment, e.g. production:PredictionFlow3 above. You can examine production results in
 a notebook by switching to the production namespace.
 
 If another person wants to deploy a new version of the flow to production, they must use
 the same production token. You, or whoever has the token, are responsible for sharing it
 with users who are authorized to deploy new versions to production. This manual step
 should prevent random users from deploying versions to production inadvertently.
 
 After you have shared the production token with another person, they can deploy a new
 version on AWS Step Functions with
 
 ```bash
 python production_flow.py step-functions create --authorize TOKEN_YOU_SHARED_WITH_THEM
 ```
 
 or on Argo Workflows with
 
 ```bash
 python production_flow.py argo-workflows create --authorize TOKEN_YOU_SHARED_WITH_THEM
 ```
 
 or on Airflow with
 
 ```bash
 python production_flow.py airflow create --authorize TOKEN_YOU_SHARED_WITH_THEM
 ```
 
 They need to use the `--authorize` option only once. Metaflow stores the token for them
 after the first deployment, so they need to do this only once.",H3,https://docs.metaflow.org/scaling/tagging#production-tokens,False,1382,202,https://docs.metaflow.org
306,Resetting a production namespace,"If you call `step-functions create` (or `argo-workflow create`) again, it will deploy an
 updated version of your code in the existing production namespace of the flow.
 
 Sometimes the code has changed so drastically that you want to recreate a fresh
 namespace for its results. You can do this as follows for AWS Step Functions:
 
 ```bash
 python production_flow.py step-functions create --generate-new-token
 ```
 
 and equivalently for Argo Workflows:
 ```bash
 python production_flow.py argo-workflows create --generate-new-token
 ```
 or Airflow:
 ```bash
 python production_flow.py airflow create --generate-new-token
 ```
 
 This will deploy a new version in production using a fresh, empty namespace.",H3,https://docs.metaflow.org/scaling/tagging#resetting-a-production-namespace,False,710,99,https://docs.metaflow.org
307,Resuming across namespaces,"[The `resume` command](/metaflow/debugging#how-to-use-the-resume-command) is smart
 enough to work across production and personal namespaces. You can `resume` a production
 workflow without having to do anything special with namespaces.
 
 You can resume runs of other users, and you can resume any production runs. The results
 of your resumed runs are always created in your personal namespace.",H2,https://docs.metaflow.org/scaling/tagging#resuming-across-namespaces,False,396,55,https://docs.metaflow.org
308,Tagging,"The `user:` tag is assigned by Metaflow automatically. In addition to automatically
 assigned tags, you can add and remove arbitrary tags in objects. Tags are an excellent
 way to add extra annotations to runs, tasks etc., which makes it easier for you and
 other people to find and retrieve results of interest.",H2,https://docs.metaflow.org/scaling/tagging#tagging,False,312,52,https://docs.metaflow.org
309,"If you know a tag to be attached before a run starts, you can add it using the `run","instance, this will annotate a `HelloFlow` run with a tag `crazy_test`.
 
 ```bash
 python helloworld.py run --tag crazy_test
 ```
 
 Often, you may want to add or change tags after a run has completed. In contrast to
 artifacts, tags can be mutated any time: Consider them as mutating interpretations of
 immutable (arti)facts. You can mutate tags either [using the Client
 API](/metaflow/client#adding-removing-and-replacing-tags) or the command line.
 
 Add a tag on the command line like this:
 
 ```
 python helloworld.py tag add --run-id 2 crazy_test
 ```
 
 Remove works symmetrically:
 ```
 python helloworld.py tag remove --run-id 2 crazy_test
 ```
 
 You can see the current set of tags with
 ```
 python helloworld.py tag list
 ```
 
 Note that the above command lists also [system tags](/metaflow/client#system-tags) that
 can not be mutated, but they can be used for filtering.",H2,https://docs.metaflow.org/scaling/tagging#if-you-know-a-tag-to-be-attached-before-a-run-starts-you-can-add-it-using-the-run,False,890,136,https://docs.metaflow.org
310,Filtering by tags,"You can access runs (or steps or tasks) with a certain tag easily using the Client API:
 
 ```python
 from metaflow import Flow
 run = list(Flow('HelloFlow').runs('crazy_test'))[0]
 ```
 
 This will return the latest run of `HelloFlow` with a tag `crazy_test` in your
 namespace. Filtering is performed both based on the current `namespace()` and the tag
 filter.
 
 You can also filter by multiple tags:
 
 ```python
 from metaflow import Flow
 run = list(Flow('HelloFlow').runs('crazy_test', 'date:20180301'))[0]
 ```
 
 This requires that all the tags listed, and the current namespace, are present in the
 object.
 
 You can see the set of tags assigned to an object with the `.tags` property. In the
 above case, `run.tags` would return a set with a string `crazy_test` amongst other
 automatically assigned tags.",H3,https://docs.metaflow.org/scaling/tagging#filtering-by-tags,False,818,126,https://docs.metaflow.org
311,Tags as Namespaces,"Let's consider again the earlier example with Anne and Will. They are working on their
 own versions of `PredictionFlow` but they want to collaborate on `FeatureFlow`. They
 could add a descriptive tag, say `xyz_features`, to `FeatureFlow` runs.
 
 ![](/assets/namespace3.png)
 
 Now, they can easily get the latest results of `FeatureFlow` regardless of the user who
 ran the flow:
 
 ```python
 from metaflow import Flow
 namespace('xyz_features')
 run = Flow('FeatureFlow').latest_run
 ```
 
 This will return `FeatureFlow/34` which happened to be run by Anne. If Will runs the
 flow again, his results will be the latest results in this namespace.
 
 We encourage you to use a combination of namespaces, domain-specific tags, and filtering
 by tags to design a workflow that works well for your project.",H3,https://docs.metaflow.org/scaling/tagging#tags-as-namespaces,False,807,123,https://docs.metaflow.org
312,Accessing Current IDs in a Flow,"*This section contains an overview of `current`. For a complete API, see [the API
 reference for `current`](/api/current).*
 
 Tagging and namespaces, together with the [Client API](/metaflow/client), are the main
 ways for accessing results of past runs. Metaflow uses these mechanisms to organize and
 isolate results automatically, so in most cases you don't have to do anything.
 
 However, in some cases you may need to deal with IDs explicitly. For instance, if your
 flow interacts with external systems, it is a good idea to inform the external system
 about the identity of the run, so you can trace back any issues to a specific run. Also
 IDs can come in handy if you need to version externally stored data.
 
 For this purpose, Metaflow provides a singleton object `current` that represents the
 identity of the currently running task. Use it in your `FlowSpec` to retrieve current
 IDs of interest:
 
 ```python
 from metaflow import FlowSpec, step, current
 
 class CurrentFlow(FlowSpec):
 
     @step
     def start(self):
         print(""flow name: %s"" % current.flow_name)
         print(""run id: %s"" % current.run_id)
         print(""origin run id: %s"" % current.origin_run_id)
         print(""step name: %s"" % current.step_name)
         print(""task id: %s"" % current.task_id)
         print(""pathspec: %s"" % current.pathspec)
         print(""namespace: %s"" % current.namespace)
         print(""username: %s"" % current.username)
         print(""flow parameters: %s"" % str(current.parameter_names))
         self.next(self.end)
 
     @step
     def end(self):
         print(""end has a different step name: %s"" % current.step_name)
         print(""end has a different task id: %s"" % current.task_id)
         print(""end has a different pathspec: %s"" % current.pathspec)
 
 if __name__ == '__main__':
     CurrentFlow()
 ```
 
 In particular, the value of `current.pathspec` is convenient as an unambiguous
 identifier of a task. For instance, the above script printed out
 
 ```
 pathspec: CurrentFlow/1/start/550539
 ```
 
 Now you can inspect this particular task using[ the Client API](/metaflow/client) by
 instantiating a `Task` object as follows:
 
 ```python
 from metaflow import Task
 task = Task('CurrentFlow/1/start/550539')
 print task.stdout
 ```
 
 This prints out the output of the task identified by the `pathspec`.
 
 The `current` singleton also provides programmatic access to the CLI option
 `--origin-run-id` used by the
 [resume](/metaflow/debugging#how-to-use-the-resume-command) within your flow code.
 
 If a user explicitly overrides the CLI option `--origin-run-id`, the `current` singleton
 would reflect that value.
 
 If not, it would be the id of the last invocation of `run` (successful or not).
 
 :::info
 
 This value would remain the same even after multiple successful `resume` invocations. If
 you don't want this behavior, you can always override the CLI option `origin-run-id` and
 `resume` a specific run.
 
 :::
 
 For regular `run` invocations, the value of `current.origin_run_id` is `None`.
 
 Suppose we invoked `resume` for the above script to re-run everything from `start`
 without explicitly overriding the CLI option `origin-run-id`, we can see the value
 chosen by Metaflow using the `current` singleton:
 
 ```bash
 python current_flow.py resume start
 ```
 
 You should see the `origin_run_id` used by the `resume` in the output (the exact value
 for you might be different):
 
 ```
 origin run id: 4
 ```",H2,https://docs.metaflow.org/scaling/tagging#accessing-current-ids-in-a-flow,False,3478,611,https://docs.metaflow.org
313,Using Kubernetes,"Here are some useful tips and tricks related to running Metaflow on Kubernetes. See our
 engineering resources for additional information about [setting up and operating
 Kubernetes for Metaflow](https://outerbounds.com/docs/engineering-welcome/).",H1,https://docs.metaflow.org/scaling/remote-tasks/kubernetes#using-kubernetes,False,247,28,https://docs.metaflow.org
314,What value of `@timeout` should I set?,"Metaflow sets a default timeout of 5 days so that you tasks don't get stuck infinitely
 while running on Kubernetes. For more details on how to use `@timeout` please read
 [this.](../failures.md#timing-out-with-the-timeout-decorator)",H2,https://docs.metaflow.org/scaling/remote-tasks/kubernetes#what-value-of-timeout-should-i-set,False,233,31,https://docs.metaflow.org
315,How much `@resources` can I request?,"Here are the current defaults for different resource types:
 
 * `cpu`: 1
 * `memory`: 4096 \(4GB\)
 * `disk`: 10240 \(10GB\)
 
 When setting `@resources`, keep in mind the configuration of your Kubernetes cluster.
 Your pod will be stuck in an unschedulable state if Kubernetes is unable to provision
 the requested resources. Additionally, as a good measure, don't request more resources
 than what your workflow actually needs. On the other hand, never optimize resources
 prematurely.
 
 You can place your Kubernetes pod in a specific namespace by using the `namespace`
 argument. By default, all pods execute on a vanilla [python docker
 image](https://hub.docker.com/_/python/) corresponding to the version of Python
 interpreter used to launch the flow and can be overridden using the `image` argument.
 
 You can also specify the resource requirements on command line as well:
 
 ```bash
 $ python BigSum.py run --with kubernetes:cpu=4,memory=10000,namespace=foo,image=ubuntu:latest
 ```",H2,https://docs.metaflow.org/scaling/remote-tasks/kubernetes#how-much-resources-can-i-request,False,996,144,https://docs.metaflow.org
316,Accessing Kubernetes logs,"As a convenience feature, you can also see the logs of any past step as follows:
 
 ```bash
 $ python bigsum.py logs 15/end
 ```",H2,https://docs.metaflow.org/scaling/remote-tasks/kubernetes#accessing-kubernetes-logs,False,128,24,https://docs.metaflow.org
317,Disk space,"You can request higher disk space for pods by using the `disk` attribute of
 `@kubernetes`.",H2,https://docs.metaflow.org/scaling/remote-tasks/kubernetes#disk-space,False,91,15,https://docs.metaflow.org
318,Executing Tasks Remotely,"There are two ways to handle larger amounts of data and compute:
 
 1. _Scale up_ by running your code on a larger machine with more memory, CPU cores, and
    GPUs, or
 2. _Scale out_ by using more machines in parallel.
 
 As described below, Metaflow supports the former through the `@resources` decorator and
 the latter through [foreach](/metaflow/basics#foreach) when flows are run on Kubernetes
 or AWS Batch.
 
 Everything described on this page applies to all compute platforms supported by
 Metaflow. The data scientist can write their flows using foreaches and the `@resource`
 decorator knowing that the code will execute on any supported platforms. For additional
 tips and tricks related to specific systems, see [Using AWS Batch](aws-batch) and [Using
 Kubernetes](kubernetes).",H1,https://docs.metaflow.org/scaling/remote-tasks/introduction#executing-tasks-remotely,False,791,123,https://docs.metaflow.org
319,Requesting resources with `resources` decorator,"Consider the following example:
 
 ```python
 from metaflow import FlowSpec, step, resources
 
 class BigSum(FlowSpec):
 
     @resources(memory=60000, cpu=1)
     @step
     def start(self):
         import numpy
         import time
         big_matrix = numpy.random.ranf((80000, 80000))
         t = time.time()
         self.sum = numpy.sum(big_matrix)
         self.took = time.time() - t
         self.next(self.end)
 
     @step
     def end(self):
         print(""The sum is %f."" % self.sum)
         print(""Computing it took %dms."" % (self.took * 1000))
 
 if __name__ == '__main__':
     BigSum()
 ```
 
 This example creates a huge 80000x80000 random matrix, `big_matrix`. The matrix requires
 about 80000^2 \* 8 bytes = 48GB of memory. 
 
 If you attempt to run this on your local machine, it is likely that the following will
 happen:
 
 ```bash
 $ python BigSum.py run
 
 2019-11-29 02:43:39.689 [5/start/21975 (pid 83812)] File ""BugSum.py"", line 11, in start
 2018-11-29 02:43:39.689 [5/start/21975 (pid 83812)] big_matrix = numpy.random.ranf((80000, 80000))
 2018-11-29 02:43:39.689 [5/start/21975 (pid 83812)] File ""mtrand.pyx"", line 856, in mtrand.RandomState.random_sample
 2018-11-29 02:43:39.689 [5/start/21975 (pid 83812)] File ""mtrand.pyx"", line 167, in mtrand.cont0_array
 2018-11-29 02:43:39.689 [5/start/21975 (pid 83812)] MemoryError
 2018-11-29 02:43:39.689 [5/start/21975 (pid 83812)]
 2018-11-29 02:43:39.844 [5/start/21975 (pid 83812)] Task failed.
 2018-11-29 02:43:39.844 Workflow failed.
     Step failure:
     Step start (task-id 21975) failed.
 ```
 
 This fails quickly due to a `MemoryError` on most laptops as we are unable to allocate
 48GB of memory. 
 
 The `@resources` decorator suggests resource requirements for a step. The `memory`
 argument specifies the amount of RAM in megabytes and `cpu` the number of CPU cores
 requested. It does not produce the resources magically, which is why the run above
 failed. The `@resources` decorator takes effect only when combined with another
 decorator that describes what compute platform, like Kubernetes or AWS Batch, to use.
 
 Let's use the `--with` option to attach a desired decorator to all steps on the command
 line. Choose one of the commands in the tabs below corresponding to whichever you use-
 Kubernetes or AWS Batch. This assumes that you have [configured one of these systems
 work with Metaflow](/getting-started/infrastructure).
 
 import Tabs from '@theme/Tabs';
 import TabItem from '@theme/TabItem';
 
 <Tabs>
 <TabItem value=""k8s"" label=""Kubernetes"">
 
 ```batch
 $ python BigSum.py run --with kubernetes
 ```
 
 </TabItem>
 
 <TabItem value=""batch"" label=""AWS Batch"">
 
 ```k8s
 $ python BigSum.py run --with batch
 ```
 
 </TabItem>
 </Tabs>
 
 The `--with batch` or `--with kubernetes` option instructs Metaflow to run all tasks as
 separate jobs on the chosen compute platform, instead of using a local process for each
 task. It has the same effect as adding the decorator above all steps in the source code.
 
 This time the run should succeed thanks to the large enough instance, assuming a large
 enough instance is available in your compute environment. In this case the `resources`
 decorator is used as a prescription for the size of the instance that the job should run
 on. Make sure that this resource requirement can be met. If a large enough instance is
 not available, the task won't start executing.
 
 You should see an output like this:
 
 ```bash
 The sum is 3200003911.795288.
 Computing it took 4497ms.
 ```
 
 In addition to `cpu` and `memory` you can specify `gpu=N` to request N GPUs for the
 instance.",H2,https://docs.metaflow.org/scaling/remote-tasks/introduction#requesting-resources-with-resources-decorator,False,3641,621,https://docs.metaflow.org
320,Running only specific steps remotely,"The `resources` decorator is an annotation that signals how much resources are required
 by a step. By itself, it does not force the step to be executed on any particular
 platform. This is convenient as you can make the choice later, executing the same flow
 on different environments without changes.
 
 Sometimes it is useful to make sure that a step always executes on a certain compute
 platform, maybe using a platform-specific configuration. You can achieve this by adding
 either `@batch` or `@kubernetes` above steps that should be executed remotely. The
 decorators accept the same keyword arguments as `@resources` as well as
 platform-specific arguments that you can find listed in [the API
 reference](/api/step-decorators).
 
 For instance, in the example above, replace `@resources` with `@batch` or `@kubernetes`
 and run it as follows:
 
 ```bash
 $ python BigSum.py run
 ```
 
 You will see that the `start` step gets executed on a remote instance but the `end`
 step, which does not need special resources, is executed locally. You could even mix
 decorators so that some steps execute on `@kubernetes`, some on `@batch`, and some
 locally.",H3,https://docs.metaflow.org/scaling/remote-tasks/introduction#running-only-specific-steps-remotely,False,1159,183,https://docs.metaflow.org
321,Parallelization over multiple cores,"When running locally, tasks are executed as separate processes. The operating system
 takes care of allocating them to separate CPU cores, so they will actually execute in
 parallel assuming that enough CPU cores are available. Hence, your flow can utilize
 multiple cores without you having to do anything special besides defining branches in
 the flow.
 
 When running remotely on `@batch` or `@kubernetes`, branches are mapped to separate jobs
 that are executed in parallel, allowing you to *scale horizontally* to any number of
 parallel tasks. In addition, you may take advantage of multiple CPU cores inside a task.
 This may happen automatically if you use a modern ML library like PyTorch or Scikit
 Learn, or you may parallelize functions explicitly, as explained below.",H3,https://docs.metaflow.org/scaling/remote-tasks/introduction#parallelization-over-multiple-cores,False,780,123,https://docs.metaflow.org
322,Parallel map,"Metaflow provides a utility function called `parallel_map` that helps take advantage of
 multiple CPU cores. This function is almost equivalent to `Pool().map` in the Python's
 built-in
 [multiprocessing](https://docs.python.org/2/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool.map)
 library. The main differences are the following:
 
 * `parallel_map` supports lambdas and any other callables of Python.
 * `parallel_map` does not suffer from bugs present in `multiprocessing`.
 * `parallel_map` can handle larger amounts of data.
 
 You may also use `parallel_map` to parallelize simple operations that might be too
 cumbersome to implement as separate steps.
 
 Here is an extension of our previous example that implements a multicore `sum()` by
 partitioning the matrix by row:
 
 ```python
 from metaflow import FlowSpec, step, batch, parallel_map
 
 class BigSum(FlowSpec):
 
     @resources(memory=60000, cpu=8)
     @step
     def start(self):
         import numpy
         import time
         big_matrix = numpy.random.ranf((80000, 80000))
         t = time.time()
         parts = parallel_map(lambda i: big_matrix[i:i+10000].sum(),
                              range(0, 80000, 10000))
         self.sum = sum(parts)
         self.took = time.time() - t
         self.next(self.end)
 
     @step
     def end(self):
         print(""The sum is %f."" % self.sum)
         print(""Computing it took %dms."" % (self.took * 1000))
 
 if __name__ == '__main__':
     BigSum()
 ```
 
 Note that we use `cpu=8` to request enough CPU cores, so our `parallel_map` can benefit
 from optimal parallelism. Disappointingly, in this case the parallel `sum` is not faster
 than the original simple implementation due to the overhead of launching separate
 processes in `parallel_map`. A less trivial operation might see a much larger
 performance boost.",H4,https://docs.metaflow.org/scaling/remote-tasks/introduction#parallel-map,False,1871,362,https://docs.metaflow.org
323,**Safeguard flags**,"It is almost too easy to execute tasks remotely using Metaflow. Consider a foreach loop
 defined as follows:
 
 ```python
 self.params = range(1000)
 self.next(self.fanned_out, foreach='params')
 ```
 
 When run with `--with batch` or `--with kubernetes`, this code would launch up to 1000
 parallel instances which may turn out to be quite expensive.
 
 To safeguard against inadvertent launching of many parallel jobs, the `run` and `resume`
 commands have a flag `--max-num-splits` which fails the task if it attempts to launch
 more than 100 splits by default. Use the flag to increase the limit if you actually need
 more tasks.
 
 ```bash
 $ python myflow.py run --max-num-splits 200
 ```
 
 Another flag, `--max-workers`, limits the number of tasks run in parallel. Even if a
 foreach launched 100 splits, `--max-workers` would make only 16 \(by default\) of them
 run in parallel at any point in time. If you want more parallelism, increase the value
 of `--max-workers`.
 
 ```bash
 $ python myflow.py run --max-workers 32
 ```",H2,https://docs.metaflow.org/scaling/remote-tasks/introduction#safeguard-flags,False,1036,163,https://docs.metaflow.org
324,Big Data,"Thus far, we have focused on CPU and memory-bound steps. Loading and processing big data
 is often an IO-bound operation which requires a different approach. Read [Loading and
 Storing Data](/scaling/data) for more details about how to build efficient data
 pipelines in Metaflow.",H2,https://docs.metaflow.org/scaling/remote-tasks/introduction#big-data,False,280,42,https://docs.metaflow.org
325,Using AWS Batch,"Here are some useful tips and tricks related to running Metaflow on AWS Batch. See our
 engineering resources for additional information about [setting up and operating AWS
 Batch for Metaflow](https://outerbounds.com/docs/engineering-welcome/).",H1,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#using-aws-batch,False,245,30,https://docs.metaflow.org
326,What value of `@timeout` should I set?,"Metaflow sets a default timeout of 5 days so that you tasks don't get stuck infinitely
 while running on AWS Batch. For more details on how to use `@timeout` please read
 [this.](../failures.md#timing-out-with-the-timeout-decorator)",H2,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#what-value-of-timeout-should-i-set,False,232,32,https://docs.metaflow.org
327,How much `@resources` can I request?,"Here are the current defaults for different resource types:
 
 * `cpu`: 1
 * `memory`: 4000 \(4GB\)
 
 When setting `@resources`, keep in mind the configuration of your AWS Batch Compute
 Environment. Your job will be stuck in a `RUNNABLE` state if AWS is unable to provision
 the requested resources. Additionally, as a good measure, don't request more resources
 than what your workflow actually needs. On the other hand, never optimize resources
 prematurely.
 
 You can place your AWS Batch task in a specific queue by using the `queue` argument. By
 default, all tasks execute on a vanilla [python docker
 image](https://hub.docker.com/_/python/) corresponding to the version of Python
 interpreter used to launch the flow and can be overridden using the `image` argument.
 
 You can also specify the resource requirements on command line as well:
 
 ```bash
 $ python BigSum.py run --with batch:cpu=4,memory=10000,queue=default,image=ubuntu:latest
 ```",H2,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#how-much-resources-can-i-request,False,958,143,https://docs.metaflow.org
329,Listing and killing AWS Batch tasks,"If you interrupt a Metaflow run, any AWS Batch tasks launched by the run get killed by
 Metaflow automatically. Even if something went wrong during the final cleanup, the tasks
 will finish and die eventually, at the latest when they hit the maximum time allowed for
 an AWS Batch task.
 
 If you want to make sure you have no AWS Batch tasks running, or you want to manage them
 manually, you can use the `batch list` and `batch kill` commands.
 
 You can easily see what AWS Batch tasks were launched by your latest run with
 
 ```bash
 $ python myflow.py batch list
 ```
 
 You can kill the tasks started by the latest run with
 
 ```bash
 $ python myflow.py batch kill
 ```
 
 If you have started multiple runs, you can make sure there are no orphaned tasks still
 running with
 
 ```bash
 $ python myflow.py batch list --my-runs
 ```
 
 You can kill the tasks started by the latest run with
 
 ```bash
 $ python myflow.py batch kill --my-runs
 ```
 
 If you see multiple runs running, you can cherry-pick a specific job, e.g. 456, to be
 killed as follows
 
 ```bash
 $ python myflow.py batch kill --run-id 456
 ```
 
 If you are working with another person, you can see and kill their tasks related to this
 flow with
 
 ```bash
 $ python myflow.py batch kill --user willsmith
 ```
 
 Note that all the above commands only affect the flow defined in your script. You can
 work on many flows in parallel and be confident that `kill` kills tasks only related to
 the flow you called `kill` with.",H2,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#listing-and-killing-aws-batch-tasks,False,1499,273,https://docs.metaflow.org
330,Accessing AWS Batch logs,"As a convenience feature, you can also see the logs of any past step as follows:
 
 ```bash
 $ python bigsum.py logs 15/end
 ```",H2,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#accessing-aws-batch-logs,False,128,24,https://docs.metaflow.org
331,Disk space,"You can request higher disk space on AWS Batch instances by using an unmanaged Compute
 Environment with a custom AMI.",H2,https://docs.metaflow.org/scaling/remote-tasks/aws-batch#disk-space,False,118,20,https://docs.metaflow.org
332,Installing Metaflow,"Metaflow is available as a Python package for macOS and Linux. You can visit our [GitHub
 repository](https://github.com/Netflix/metaflow) or get the latest version from
 [PyPI](https://pypi.org/):
 
 ```bash
 pip install metaflow
 ```
 
 We highly recommend using **Python 3** for new projects. Metaflow supports Python 2.7
 for legacy applications, but Python 3 has fewer bugs and is better supported than [the
 deprecated Python 2.7](http://pythonclock.org).
 
 :::info
 
 If you want to get a feel of Metaflow and the infrastructure behind it without having to
 install anything locally, you can do in the browser by signing up for [a Metaflow
 Sandbox](https://outerbounds.com/sandbox/).
 
 :::
 
 
 Now you are ready to get your hands dirty with the [Tutorials](tutorials/).",H1,https://docs.metaflow.org/getting-started/install#installing-metaflow,False,780,114,https://docs.metaflow.org
333,Upgrading Metaflow,"If you have installed Metaflow previously, you can upgrade to the latest version with:
 
 ```bash
 pip install --upgrade metaflow
 ```",H2,https://docs.metaflow.org/getting-started/install#upgrading-metaflow,False,134,21,https://docs.metaflow.org
334,Deploying Infrastructure for Metaflow,"While you can [get started with Metaflow easily](/getting-started/install) on your
 laptop, the main benefits of Metaflow lie in its ability to [scale out to external
 compute clusters](/scaling/introduction) and to [deploy to production-grade workflow
 orchestrators](/production/introduction). To benefit from these features, you need to
 configure Metaflow and the infrastructure behind it appropriately. A separate guide,
 [Metaflow Resources for Engineers](https://outerbounds.com/engineering/welcome/) covers
 everything related to such deployments. This page provides a quick overview.",H1,https://docs.metaflow.org/getting-started/infrastructure#deploying-infrastructure-for-metaflow,False,592,69,https://docs.metaflow.org
335,Supported infrastructure components,"Since modern data science / ML applications are powered by a number of interconnected
  systems, it is useful to organize them as an infrastructure stack like the one
 illustrated below ([Why? See here](/introduction/why-metaflow)). You can see logos of
 all supported systems which you can use to enable each layer.
 
 Consider this illustration as a menu that allows you to build your own pizza: You get to
 customize your own crust, sauce, toppings, and cheese. You can make the choices based on
 your existing business infrastructure and the requirements and preferences of your
 organization. Fortunately, Metaflow provides a consistent API for all these
 combinations, so you can even change the choices later without having to rewrite your
 flows.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack.svg""></object>
 
 The table below explains the five major deployment options for Metaflow and what
 components of the stack are supported in each. You can choose to deploy Metaflow on:
 
 1. **Only local** environment - [just `pip install metaflow` on any
    workstation](/getting-started/install).
 2. **AWS** either on [EKS as a Kubernetes
    platform](https://outerbounds.com/engineering/deployment/aws-k8s/deployment/) or
    [using AWS-managed
    services](https://outerbounds.com/engineering/deployment/aws-managed/introduction/).
 3. **Azure** on [AKS as a Kubernetes
    platform](https://outerbounds.com/engineering/deployment/azure-k8s/deployment/).
 4. **Google Cloud** on [GKE as a Kubernetes
    platform](https://outerbounds.com/engineering/deployment/gcp-k8s/deployment/).
 4. [Any **Kubernetes**
    cluster](https://outerbounds.com/engineering/deployment/aws-k8s/deployment/)
    including on-premise deployments.
 
 | Layer         | Component                                                                                                    | Description                                        | Only Local | AWS | Azure | GCP | K8s |
 | ------------- | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------- | ---------- | --- | ----- | --- | --- |
 | Modeling      | <img src=""/assets/infra-python.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Python libraries**      | Any Python libraries                               | 🟢          | 🟢   | 🟢     | 🟢   | 🟢   |
 | Deployment    | <img src=""/assets/infra-argo.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Argo Workflows**          | Open-source production-grade workflow orchestrator |            | 🟢   | 🟢     | 🟢   | 🟢   |
 | Deployment    | <img src=""/assets/infra-sfn.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Step Functions**           | AWS-managed production-grade workflow orchestrator |            | 🟢   |       |     |     |
 | Deployment    | <img src=""/assets/infra-airflow.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Apache Airflow**       | Popular open-source workflow orchestrator          |            | 🟢   | 🟢     | 🟢   | 🟢   |
 | Versioning    | <img src=""/assets/infra-mflocal.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Local Metadata**       | Metaflow's tracking in local files                 | 🟢          | 🟢   | 🟢     | 🟢   | 🟢   |
 | Versioning    | <img src=""/assets/infra-metaflow.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Metadata Service**    | Metaflow's tracking in a central database          |            | 🟢   | 🟢     | 🟢   | 🟢   |
 | Orchestration | <img src=""/assets/infra-mflocal.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Local Orchestrator**   | Metaflow's local workflow orchestrator             | 🟢          | 🟢   | 🟢     | 🟢   | 🟢   |
 | Compute       | <img src=""/assets/infra-mflocal.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Local Processes**      | Metaflow tasks as local processes                  | 🟢          | 🟢   | 🟢     | 🟢   | 🟢   |
 | Compute       | <img src=""/assets/infra-batch.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **AWS Batch**              | AWS-managed batch compute service                  |            | 🟢   |       |     |
 | Compute       | <img src=""/assets/infra-k8s.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Kubernetes**               | Open-source batch compute platform                 |            | 🟢   | 🟢     | 🟢   | 🟢   |
 | Data          | <img src=""/assets/infra-mflocal.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Local Datastore**      | Metaflow artifacts in local files                  | 🟢          | 🟢   | 🟢     | 🟢   | 🟢   |
 | Data          | <img src=""/assets/infra-s3.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **AWS S3**                    | Metaflow artifacts in AWS-managed storage          |            | 🟢   |       |     | 🟢   |
 | Data          | <img src=""/assets/infra-azureblob.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Azure Blob Storage** | Metaflow artifacts in Azure-managed storage        |            |     | 🟢     |     | 🟢   |
 | Data          | <img src=""/assets/infra-gcs.png"" width="" 30"" style={{verticalAlign:""middle""}}/> **Google Cloud Storage**     | Metaflow artifacts in Google-managed storage       |            |     |       | 🟢   | 🟢   |
 Note that fast prototyping with the Local Orchestrator is supported in all these
 options, but the **only local** option doesn't support scalability with an external
 compute layer, nor production-grade deployments.
 
 :::info
 
 You can test the AWS/Azure/GCP/Kubernetes stack easily in your browser for free
 by signing up for a [Metaflow Sandbox](https://outerbounds.com/sandbox/).
 
 :::",H2,https://docs.metaflow.org/getting-started/infrastructure#supported-infrastructure-components,False,5709,1458,https://docs.metaflow.org
336,Example stacks,Here are some typical deployments that we have seen in action:,H2,https://docs.metaflow.org/getting-started/infrastructure#example-stacks,False,62,11,https://docs.metaflow.org
337,Local: Effortless prototyping,"**Just `pip install metaflow` to deploy this stack**
 
 This is the stack you get by default when you [install Metaflow
 locally](/getting-started/install). It's main benefit is zero configuration and
 maintenance - it works out of the box. It is a great way to get started with Metaflow.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack-all-local.svg""></object>
 
 When you want to start [collaborating with multiple people](/scaling/tagging) which
 requires a central metadata service, or you want to start running [larger-scale
 workloads](/scaling/introduction), or you want to [deploy your
 workflows](/production/introduction) so that they run even when your laptop is asleep,
 look into more featureful stacks below.",H3,https://docs.metaflow.org/getting-started/infrastructure#local-effortless-prototyping,False,754,100,https://docs.metaflow.org
338,"Low-maintenance scalable prototyping, powered by AWS","**[Click here to deploy this
 stack](https://outerbounds.com/engineering/deployment/aws-managed/introduction/)**
 
 If you are looking for the easiest and the most affordable way to scale out compute to
 the cloud, including cloud-based GPUs, this stack is a great option. Consider the
 benefits:",H3,https://docs.metaflow.org/getting-started/infrastructure#low-maintenance-scalable-prototyping-powered-by-aws,False,296,38,https://docs.metaflow.org
339,"Low-maintenance full stack, powered by AWS","**[Click here to deploy this
 stack](https://outerbounds.com/engineering/deployment/aws-managed/introduction/)**
 
 If you need the full stack of data science/ML infrastructure but want to spend a minimal
 amount of effort to set up and manage it, choose this option. You get all the benefits
 of AWS Batch as described above, as well as production deployments on [AWS Step
 Functions](https://aws.amazon.com/step-functions/) which is a highly-available, scalable
 workflow orchestrator managed by AWS. Metaflow tracks everything in a central metadata
 service, making collaboration straightforward.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack-aws-native.svg""></object>
 
 Here are the main reasons for not using this stack:",H3,https://docs.metaflow.org/getting-started/infrastructure#low-maintenance-full-stack-powered-by-aws,False,760,93,https://docs.metaflow.org
340,"Customizable full stack on AWS, powered by Kubernetes","**[Click here to deploy this
 stack](https://outerbounds.com/engineering/deployment/aws-k8s/deployment/)**
 
 If your engineering team has prior experience with Kubernetes, they might prefer a
 familiar stack that works with their existing security policies, observability tools,
 and deployment mechanisms. In this case, this Kubernetes-native stack featuring compute
 on Kubernetes and deployments on reliable, scalable, open-source [Argo
 Workflows](https://argoproj.github.io/argo-workflows/) is a good option.
 
 This stack can be [easily deployed on EKS on
 AWS](https://outerbounds.com/engineering/deployment/aws-k8s/deployment/), leveraging S3
 as the datastore. Alternatively, some companies run this stack on-premise using
 [Minio](https://min.io/) as an S3-compatible datastore.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack-aws-k8s.svg""></object>
 
 This stack requires more maintenance than the AWS-native stack above, although the basic
 setup is quite manageable if your organization is already familiar with Kubernetes.",H3,https://docs.metaflow.org/getting-started/infrastructure#customizable-full-stack-on-aws-powered-by-kubernetes,False,1069,117,https://docs.metaflow.org
341,"Customizable full stack on Azure, powered by Kubernetes","**[Click here to deploy this
 stack](https://outerbounds.com/engineering/deployment/azure-k8s/deployment/)**
 
 If you need a full-stack DS/ML platform on Azure, this Kubernetes-based stack is a good
 option. It is the same stack as the one running on EKS on AWS, with the S3-based
 datastore replaced with Azure Blob Storage.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack-azure.svg""></object>
 
 This stack incurs a typical maintenance overhead of an AKS-based Kubernetes cluster,
 which shouldn't add much burden if your organization uses AKS already.",H3,https://docs.metaflow.org/getting-started/infrastructure#customizable-full-stack-on-azure-powered-by-kubernetes,False,587,75,https://docs.metaflow.org
342,"Customizable full stack on Google Cloud, powered by Kubernetes","**[Click here to deploy this
 stack](https://outerbounds.com/engineering/deployment/gcp-k8s/deployment/)**
 
 If you need a full-stack DS/ML platform on Google Cloud, this Kubernetes-based stack is
 a good option. It is the same stack as the one running on EKS on AWS, with the S3-based
 datastore replaced with Google Cloud Storage.
 
 <object style={{width: 700}} type=""image/svg+xml""
 data=""/assets/infra-stack-gcp.svg""></object>
 
 This stack incurs a typical maintenance overhead of an GKE-based Kubernetes cluster,
 which shouldn't add much burden if your organization uses GKE already.
 
 
 
 If you are unsure about the stacks, just run `pip install metaflow` to install the local
 stack and move on to [the tutorials](/getting-started/tutorials). Flows you create will
 work without changes on any of these stacks.",H3,https://docs.metaflow.org/getting-started/infrastructure#customizable-full-stack-on-google-cloud-powered-by-kubernetes,False,823,114,https://docs.metaflow.org
344,"Look Mom, We're in the Cloud.","This flow is a simple linear workflow that verifies your cloud configuration. The
 `start` and `end` steps will run locally, while the `hello` step will [run
 remotely](/scaling/remote-tasks/introduction). After [configuring
 Metaflow](/getting-started/infrastructure) to run in the cloud, data and metadata about
 your runs will be stored remotely. This means you can use the client to access
 information about any flow from anywhere.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/05-hello-cloud)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-2-scaling-out-and-up/episode05#look-mom-we-re-in-the-cloud,False,585,71,https://docs.metaflow.org
346,Scheduling Compute in the Cloud.,"This example revisits [Episode 06-statistics-redux: Computing in the
 Cloud](episode06.md). Wi th Metaflow, you don't need to make any code changes to
 schedule your flow in the cloud. In this example, we will schedule the `stats.py`
 workflow using the `argo-workflows create` command-line argument. This instructs
 Metaflow to schedule your flow on [Argo
 Workflows](https://argoproj.github.io/argo-workflows/) without changing any code. You
 can execute your flow on Argo Workflows by using the `argo-workflows trigger`
 command-line argument. You can use a notebook to set up a simple dashboard to monitor
 all of your Metaflow flows.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/08-autopilot)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-2-scaling-out-and-up/episode08#scheduling-compute-in-the-cloud,False,785,100,https://docs.metaflow.org
348,Way up here.,"This episode shows how you can use a notebook to set up a simple dashboard to monitor
 all of your Metaflow flows.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/07-worldview)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-2-scaling-out-and-up/episode07#way-up-here,False,261,33,https://docs.metaflow.org
350,Computing in the Cloud.,"This example revisits [Episode 02-statistics: Is this Data
 Science?](../season-1-the-local-experience/episode02). With Metaflow, you don't need to
 make any code changes to scale up your flow by running on remote compute. In this
 example, we re-run the `stats.py` workflow adding the `--with kubernetes` command line
 argument. This instructs Metaflow to run all your steps in the cloud without changing
 any code. You can control the behavior with additional arguments, like
 `--max-workers`**.** For this example, `max-workers` is used to limit the number of
 parallel genre-specific statistics computations. You can then access the data artifacts
 \(even the local CSV file\) from anywhere because the data is being stored in the
 cloud-based datastore.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/06-statistics-redux)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-2-scaling-out-and-up/episode06#computing-in-the-cloud,False,912,119,https://docs.metaflow.org
352,Let's build you a movie playlist.,"This flow loads a movie metadata CSV file and builds a playlist for your favorite movie
 genre. Everything in Metaflow is versioned, so you can run it multiple times and view
 all the historical playlists with the Metaflow client in a Notebook.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/01-playlist)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode01#let-s-build-you-a-movie-playlist,False,390,53,https://docs.metaflow.org
354,The Final Showdown.,"Now that we've improved our genre-based playlist generator. We expose a _**hint**_
 parameter allowing the user to suggest a better bonus movie. The bonus movie is chosen
 from the movie that has the most similar name to the _**hint**_.
 
 This is achieved by importing a string edit distance package using Metaflow's conda
 based dependency management feature. Dependency management builds isolated and
 reproducible environments for individual steps.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/04-playlist-plus)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode04#the-final-showdown,False,603,78,https://docs.metaflow.org
356,Metaflow says Hi!,"This flow is a simple linear workflow that verifies your installation by printing out
 _**Metaflow says: Hi!**_ to the terminal.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/00-helloworld)",H2,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode00#metaflow-says-hi,False,257,29,https://docs.metaflow.org
358,To play this episode:,"1. `cd metaflow-tutorials`
 2. `python 00-helloworld/helloworld.py show`
 3. `python 00-helloworld/helloworld.py run`
 
 <TutorialsLink link=""../../tutorials""/>",H4,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode00#to-play-this-episode,False,160,14,https://docs.metaflow.org
360,Follow the Money.,"Use Metaflow to load the statistics generated from [Episode 2](episode02) and improve
 our playlist generator by only recommending top box office grossing movies.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/03-playlist-redux)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode03#follow-the-money,False,314,34,https://docs.metaflow.org
362,Is this Data Science?,"Use metaflow to load the movie metadata CSV file into a dataframe and compute some movie
 genre-specific statistics. These statistics are then used in later examples to improve
 our playlist generator. You can optionally use the Metaflow client to eyeball the
 results in a Notebook, and make some simple plots using the Matplotlib library.
 
 You can find the tutorial code on
 [GitHub](https://github.com/Netflix/metaflow/tree/master/metaflow/tutorials/02-statistics)
 
 **Showcasing:**",H2,https://docs.metaflow.org/getting-started/tutorials/season-1-the-local-experience/episode02#is-this-data-science,False,488,65,https://docs.metaflow.org
363,Production Deployments,"What does *production* mean exactly? Surely the answer depends on who you ask and what
 application they are working on. There are so many different ways to produce business
 value with machine learning and data science that there can't be a single unambiguous
 definition or a way to deploy projects to production.
 
 However, there are characteristics that are common to all production deployments:
 
  - Production deployments should **run without human intervention**. It is not very
  practical to use results that require you to execute `run` on your laptop to power
  serious business processes or products.
 
  - Production deployments should **run reliably** in a highly available manner. Results
    should appear predictably, even if infrastructure encounters spurious failures.
 
 Consider the Metaflow journey
 
 ![](/assets/intro-cartoon-3.svg)
 
 Thus far the steps have involved a human in the loop, from [local
 development](/metaflow/introduction) to [scalable flows](/scaling/introduction). In
 contrast, a defining feature of production deployments is that they are fully automated.
 We achieve this by *scheduling flows* to run automatically on *a production-grade
 workflow orchestrator*, so you don't need to write `run` manually to produce the desired
 results.",H1,https://docs.metaflow.org/production/introduction#production-deployments,False,1285,192,https://docs.metaflow.org
364,"Reliably Running, Automated Flows","What about the second characteristic of production deployments - reliability? Firstly, a
 big benefit of [Stage II](/scaling/introduction) is that you can test your workflows at
 scale, and add [reliability-enhancing](/scaling/failures)
 [features](/scaling/dependencies), making sure your flows can cope with production-scale
 workloads. Secondly, your flow needs to be orchestrated by a system that by itself runs
 reliably, which is [harder than it
 sounds](https://netflixtechblog.com/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280).
 Such a production-grade orchestrator needs to be
 
  - **Highly available**: The orchestrator itself must not crash, even if a server it
    runs on hits a random failure.
 
  - **Highly scalable**: We shouldn't have to worry about the number flows orchestrated
    by the system.
 
  - **Capable of triggering flows based on different conditions**: We should be able to
    automate flow execution flexibly.
 
  - **Easy to monitor and operate**: To minimize the time spent on occasional human
    interventions.
 
 Fortunately, a few systems are able to fulfill these requirements, judging by their
 track record. Metaflow integrates with two of them: [Argo
 Workflows](https://argoproj.github.io/argo-workflows/) that runs on Kubernetes and [AWS
 Step Functions](https://aws.amazon.com/step-functions/), a managed service by AWS. As
 of today, Argo Workflows is the only orchestrator that supports
 [Metaflow's powerful event-triggering functionality](/production/event-triggering),
 which makes it a good default choice.
 
 In addition, Metaflow integrates with a popular open-source workflow orchestrator,
 [Apache Airflow](https://airflow.apache.org/). While Airflow has more limitations than
 the two aforementioned orchestrators, it is a good choice if you have many DAGs deployed
 on it already and you don't want to introduce a new orchestrator in your environment.
 
 While all of these systems are quite complex under the hood, Metaflow makes using them
 trivial: You can deploy your flows literally with a single command - no changes in the
 code required. Also, this means that you can switch between schedulers easily. For
 instance, you can start with Apache Airflow to stay compatible with your existing data
 pipelines and migrate to Argo Workflows over time without having to pay any migration
 tax.",H2,https://docs.metaflow.org/production/introduction#reliably-running-automated-flows,False,2394,338,https://docs.metaflow.org
365,Patterns of production deployments,"Once flows run reliably, you can leverage the results - like freshly trained models - on
 various systems:
 
 1. You can use deployed workflows as building blocks to compose larger systems using
    [event triggering](/production/event-triggering).
 2. You can write fresh predictions or other results in a data warehouse, e.g. to power a
    dashboard.
 3. You can populate fresh results in a cache e.g. for a recommendation system.
 4. You can deploy models on a *model hosting* platform of your choosing, e.g.
    [Seldon](https://www.seldon.io/) or [AWS
    Sagemaker](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html).
 
 The exact pattern depends on your use case. Importantly, creating these integrations
 become much easier when you can trust your flows to run reliably. We are happy to help
 you on [the Metaflow support Slack](http://slack.outerbounds.co) to find a pattern that
 works for your needs.",H3,https://docs.metaflow.org/production/introduction#patterns-of-production-deployments,False,939,142,https://docs.metaflow.org
366,To Production And Back,"While the journey illustration above looks like a linear path from prototype to
 production, realistically the picture should illustrate loops everywhere. In particular,
 there is constant interaction between local development and production deployments, as
 you troubleshoot production issues (inevitably), as well as keep working on newer
 versions of flows. 
 
 When it comes to troubleshooting, a hugely convenient feature is the ability to
 [`resume` failed production runs
 locally](/metaflow/debugging#reproducing-production-issues-locally). Also, remember that
 you can inspect the state of any production run with
 [cards](/metaflow/visualizing-results) and [notebooks](/metaflow/client), in real-time.
 
 When it comes to working on newer versions, how do you know if a newer version performs
 better than the latest production deployment? Often, the best way to answer the question
 is to deploy the new version to run concurrently with the existing production version
 and compare the results, as in an A/B test. This pattern is enabled by [the `@project`
 decorator](coordinating-larger-metaflow-projects). Also, [Metaflow
 tags](https://outerbounds.com/blog/five-ways-to-use-the-new-metaflow-tags/) come in
 handy when designing processes around production deployments.",H2,https://docs.metaflow.org/production/introduction#to-production-and-back,False,1283,162,https://docs.metaflow.org
367,What You Will Learn,":::info
 
 You can get a feel of all these concepts and test them hands-on without having to
 install anything locally by signing up for
 [a Metaflow Sandbox](https://outerbounds.com/sandbox/)!
 
 :::
 
 In this section, you will learn how to make your flows run automatically without any
 human intervention. 
 
 1. The basics of [scheduling Metaflow flows](/production/scheduling-metaflow-flows/introduction):
    - Depending on the [infrastructure you have
      installed](/getting-started/infrastructure), pick a section below:
       - [Scheduling flows with Argo
         Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows)
         - Choose this if running on Kubernetes.
       - [Scheduling flows with AWS Step
         Functions](/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions)
         - Choose for minimal operational overhead.
       - [Scheduling flows with Apache
         Airflow](/production/scheduling-metaflow-flows/scheduling-with-airflow)
         - Choose to stay compatible with your existing Airflow deployment.
 
  2. [Coordinating larger Metaflow
     projects](/production/coordinating-larger-metaflow-projects) is a more advanced pattern
     that enables multiple parallel production deployments.
 
 3. [Connecting flows via events](/production/event-triggering) shows how you can
    make workflows start automatically based on real-time events. This pattern
    allows you to build reactive systems using flows as building blocks.",H2,https://docs.metaflow.org/production/introduction#what-you-will-learn,False,1517,248,https://docs.metaflow.org
368,Coordinating Larger Metaflow Projects,":::info
 
 This page applies equally to all [production
 orchestrators](/production/scheduling-metaflow-flows/introduction) supported by
 Metaflow, i.e. AWS Step Functions, Argo Workflows, and Airflow. Examples below mention
 `step-functions` but you can replace `step-functions` with `argo-workflows` or `airflow`
 to get equivalent behavior on your orchestrator of choice (except the last part about
 event triggering, which applies only to Argo Workflows).
 
 :::
 
 
 Most Metaflow projects start as a simple Python script that is developed by a single
 data scientist. Metaflow takes care of [keeping results organized
 automatically](../scaling/tagging), so you can focus on developing models and the
 business logic around them.
 
 Over time, the project matures to the point that you want to deploy it to [a production
 orchestrator](/production/scheduling-metaflow-flows/introduction) to test how the model
 works with real-life, updating data. In Metaflow, this is a matter of executing a single
 command like `step-functions create`. Having the workflow run automatically with fresh
 data is a great way to surface unforeseen issues in the code.
 
 After a few iterations, the workflow starts to work reliably. If the results are
 promising enough, stakeholders can start relying on the results of your workflow. Often,
 success attracts more developers to join the project. At this point, you will need to
 start thinking about how to coordinate work amongst multiple people and how to iterate
 on new, experimental versions of the workflow while providing stable results to your
 stakeholders. This is where the `@project` decorator comes in.",H1,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#coordinating-larger-metaflow-projects,False,1655,239,https://docs.metaflow.org
369,The `@project` decorator,"During development, multiple people can work on the same workflow simultaneously as
 Metaflow keeps executions isolated through [independently stored artifacts and
 namespaces](../scaling/tagging). However, by default, all production deployments are
 bound to the name of the workflow. If multiple people call `step-functions create`
 independently, each deployment will overwrite the previous one.
 
 In the early stages of a project, this simple model is convenient but as the project
 grows, it is desirable that multiple people can test their own production deployments
 without interference. Or, as a single developer, you may want to experiment with
 multiple independent deployments of your workflow.
 
 Metaflow provides a `@project` decorator to address this need. The `@project` decorator
 is used at the `FlowSpec`-level to bind a Flow to a specific project. All flows with the
 same project name belong to the same project.
 
 You can test this by executing the following flow.
 
 ```python title=""project_flow.py""
 from metaflow import FlowSpec, step, project, current
 
 @project(name='example_project')
 class ProjectFlow(FlowSpec):
 
     @step
     def start(self):
         print('project name:', current.project_name)
         print('project branch:', current.branch_name)
         print('is this a production run?', current.is_production)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     ProjectFlow()
 ```
 
 Save the above snippet in a file, `project_flow.py`. Now you can run the flow as usual:
 
 ```python
 python project_flow.py run
 ```
 
 The `@project` decorator exposes new project-related attributes, `project_name`,
 `branch_name`, and `is_production` in [the current
 object](../scaling/tagging#accessing-current-ids-in-a-flow) which you can use to alter
 the behavior of the flow depending on the execution context. Besides the new attributes
 in current, the flow works exactly as before when executed outside a production
 orchestrator.",H2,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#the-project-decorator,False,2034,323,https://docs.metaflow.org
370,Projects in production,"The main benefit of `@project` relates to deployments on [a production
 orchestrator](/production/scheduling-metaflow-flows/introduction). Below, we will cover
 this case: How to manage a production project with multiple developers collaborating.",H2,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#projects-in-production,False,246,28,https://docs.metaflow.org
371,"Single Flow, multiple developers","If `ProjectFlow` did not have a `@project decorator`, it would get deployed as a
 workflow called `ProjectFlow` on AWS Step Functions by `step-functions create`. Only one
 version of `ProjectFlow` could exist on a production orchestrator at a time. Everyone
 deploying the flow would need to know [the production
 token](../scaling/tagging#production-namespaces) assigned to the deployment.
 
 On the UI of your production orchestrator, you would see one workflow called
 `ProjectFlow`:
 
 ![](/assets/project_old.png)
 
 The `@project` decorator changes this behavior. Let's deploy `ProjectFlow`:
 
 ```python
 python project_flow.py step-functions create
 ```
 
 The `@project` decorator adds a user-specific prefix in the workflow name: the workflow
 gets deployed with a name like `example_project.user.YOURNAME.ProjectFlow` where
 `YOURNAME` is your username. Metaflow gets the username by looking, in order, at the
 following environment variables: `METAFLOW_USER`, `SUDO_USER`, `USERNAME` and `USER`.
 
 This allows multiple developers to deploy their workflows on a production orchestrator
 without fear that they might interfere with someone else's deployment. Imagine Alice,
 Bob, and Carol collaborating on a project. Each one of them can call `step-functions
 create` independently, which results in three separate workflows in production:
 
 ![](/assets/project_user.png)
 
 Note that each one of these deployments gets [an isolated namespace](../scaling/tagging)
 and [a separate production token](../scaling/tagging#production-tokens). This means that
 if your code refers to `Flow('ProjectFlow').latest_run` in production, it is guaranteed
 to refer to a run that corresponds to its own isolated deployment. The deployments don't
 interfere with each other.",H3,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#single-flow-multiple-developers,False,1773,232,https://docs.metaflow.org
372,Main production deployment,"In addition to user-specific deployments, most projects have a single blessed production
 version which represents the official results of the workflow.
 
 The `@project` decorator exposes a new top-level command-line argument, `--production`
 that denotes a production run or deployment. See what happens when you run ProjectFlow
 with `--production`:
 
 ```python
 python project_flow.py --production run
 ```
 
 The `current.branch_name` will be set to prod and `current.is_production` is set to
 True. For instance, you could write results to a production table only if
 `current.is_production`.
 
 You can deploy a production version to AWS Step Functions as follows:
 
 ```python
 python project_flow.py --production step-functions create
 ```
 
 Instead of deploying the flow with a user-specific prefix, this will deploy the flow as
 `example_project.prod.ProjectFlow`. You will get a warning about missing production
 token if you are not authorized to deploy the flow to production.
 
 The production deployment gets a separate, isolated namespace of its own:
 
 ![](/assets/project_prod.png)",H3,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#main-production-deployment,False,1102,154,https://docs.metaflow.org
373,Custom branches,"Imagine that ProjectFlow has a stable version in production. Now, Alice and Bob want to
 start developing a new, experimental version of the flow. They can work on a common
 codebase and run the code locally independently. Eventually, they will want to deploy
 the experimental version to a production orchestrator and let it run in parallel with
 the production version for a while, to see that it works correctly.
 
 Alice and Bob could deploy the experimental version under a user-specific namespace of
 theirs but this would make it hard to keep iterating on the code, as one of the
 usernamespaces would be reserved for the long-running experiment. A better approach is
 to deploy the experimental code under a custom branch.
 
 Try the following:
 
 ```python
 python project_flow.py --branch better_version run
 ```
 
 The flow reports that the branch name is `test.better_version`. You can deploy the
 custom branch to AWS Step Functions:
 
 ```python
 python project_flow.py --branch better_version step-functions create
 ```
 
 which will result in another separate, isolated namespace:
 
 ![](/assets/project_branch.png)
 
 Alice and Bob can share the production token corresponding to the branch, so either of
 them can redeploy the branch when needed.",H3,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#custom-branches,False,1264,196,https://docs.metaflow.org
374,Custom branches for production deployments,"There are scenarios where Alice might need to run multiple variants of ProjectFlow in
 production. Alice can very simply use custom branches to run multiple production
 versions -
 
 Try the following:
 
 ```python
 python project_flow.py --branch better_version --production run
 ```
 
 The flow reports that the branch name is `prod.better_version`. You can deploy the
 custom branch to AWS Step Functions:
 
 ```python
 python project_flow.py --branch better_version --production step-functions create
 ```",H3,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#custom-branches-for-production-deployments,False,509,71,https://docs.metaflow.org
375,`@project` and event triggering,"Importantly, workflows connected through
 [the `@trigger_on_finish` decorator](/production/event-triggering/flow-events)
 respect the `@project` decorator. Besides deploying individual workflows as branches,
 as shown above, you can deploy flows-of-flows as isolated branches. Read more about
 this pattern in
 [Deploying Variants of Event-Triggered Flows](/production/event-triggering/project-events).",H3,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#project-and-event-triggering,False,402,38,https://docs.metaflow.org
376,Summary,"The `@project` decorator makes available three classes of namespaces that will affect
 the behavior of a production deployment:",H2,https://docs.metaflow.org/production/coordinating-larger-metaflow-projects#summary,False,127,18,https://docs.metaflow.org
377,Inspecting Events,"Events provide an additional layer of observability in production systems. By
 following a trail of events, you can inspect what was triggered, when, and by
 whom.",H1,https://docs.metaflow.org/production/event-triggering/inspect-events#inspecting-events,False,163,26,https://docs.metaflow.org
378,Accessing events through Client API,"You can inspect the event(s) with the Client API that exposes
 [the `MetaflowTrigger` object](/api/client#metaflowtrigger) for every
 event-triggered run. For instance, we can inspect the event that triggered a
 production run `ModelRefreshFlow/argo-modelrefreshflow-rlpgc`:
 
 ```python
 from metaflow import namespace, Run
 namespace(None)
 Run('ModelRefreshFlow/argo-modelrefreshflow-rlpgc').trigger.event
 ```
 
 Remember that `namespace(None)` sets
 [the global namespace](/scaling/tagging#global-namespace) which is
 required to inspect production runs e.g. in a notebook. This will print
 out metadata about the event:
 
 ```
 MetaflowEvent(name='data_updated',
 			  id='ca75a1a4-91de-40c2-944c-0b39436c721e',
 			  timestamp=datetime.datetime(2023, 5, 15, 19, 50, 43),
 			  type='event')
 ```
 
 Find a description of all fields in [the related API documentation](#).",H2,https://docs.metaflow.org/production/event-triggering/inspect-events#accessing-events-through-client-api,False,877,98,https://docs.metaflow.org
379,Dealing with multiple triggers,"If a run was triggered by multiple events, you can [inspect specific
 `MetaflowEvent` by name](/api/client#Trigger.__getitem__):
 
 ```
 run.trigger['data_updated'].name
 ```
 
 Or, if a run was triggered by multiple flows when using `@trigger_on_finish`,
 you can inspect a specific triggering `Run` by its flow name:
 
 ```
 run.trigger['FirstFlow'].data.model
 ```",H3,https://docs.metaflow.org/production/event-triggering/inspect-events#dealing-with-multiple-triggers,False,367,47,https://docs.metaflow.org
380,Following a trail of runs,"When flows are connected with `@trigger_on_finish`, you can use
 `MetaflowTrigger` to follow a chain of triggered runs. Consider this chain of
 flows:
 
 ```
 ETLFlow → TrainingFlow → PredictionFlow
 ```
 
 We can walk backwards from the latest run of `PredictionFlow` back to the
 triggering run of `ETLFlow`:
 
 ```python
 etl_run = Flow('PredictionFlow').latest_run.trigger.run.trigger.run
 ```",H3,https://docs.metaflow.org/production/event-triggering/inspect-events#following-a-trail-of-runs,False,397,54,https://docs.metaflow.org
381,Events in the Metaflow UI,"If you have deployed
 [the Metaflow
 GUI](https://netflixtechblog.com/open-sourcing-a-monitoring-gui-for-metaflow-75ff465f0d60),
 you can view metadata about triggers right in the UI. The circles with arrows
 inside indicate event-triggered runs:
 
 ```mdx-code-block
 import ReactPlayer from 'react-player';
 ```
 
 <ReactPlayer playing controls muted loop url='/assets/mfgui-event.mp4' width='100%' height='100%'/>",H2,https://docs.metaflow.org/production/event-triggering/inspect-events#events-in-the-metaflow-ui,False,416,41,https://docs.metaflow.org
382,Deploying Variants of Event-Triggered Flows,"Consider this advanced scenario: You have deployed two flows [linked together
 via `@trigger_on_finish`](/production/event-triggering/flow-events#passing-data-across-flows).
 The flows run happily in production. At some point, you want to experiment with a new
 modeling approach. In order to know if the new approach works better than the
 current production version, you'd like to run them concurrently using the same
 data, maybe powering an A/B test.
 
 It is critical that the experimental variant doesn't interfere with the
 production version. Conceptually, you would like to have two isolated
 deployments like here:
 
 ```mdx-code-block
 import ReactPlayer from 'react-player';
 ```
 
 <ReactPlayer playing controls muted loop url='/assets/et-variants.mp4' width='100%' height='100%'/>
 
 Fortunately, you can achieve such isolated deployments by using [the `@project`
 decorator](/production/coordinating-larger-metaflow-projects) in conjunction
 with `@trigger_on_finish`.",H1,https://docs.metaflow.org/production/event-triggering/project-events#deploying-variants-of-event-triggered-flows,False,983,119,https://docs.metaflow.org
383,Using `@project` and `@trigger_on_finish` together,"```python
 from metaflow import FlowSpec, step, current, project
 
 @project(name='variant_demo')
 class FirstProjectFlow(FlowSpec):
 
     @step
     def start(self):
         print(""This deployment is called"", current.project_flow_name)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     FirstProjectFlow()
 ```
 
 and 
 
 ```python
 from metaflow import FlowSpec, step, trigger_on_finish, current, project
 
 @trigger_on_finish(flow='FirstProjectFlow')
 @project(name='variant_demo')
 class SecondProjectFlow(FlowSpec):
 
     @step
     def start(self):
         print(""This deployment is called"", current.project_flow_name)
         print(""This run was triggered by"", current.trigger.event)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     SecondProjectFlow()
 ```
 
 Deploy both the flows on Argo Workflows:
 ```
 python firstproject.py argo-workflows create
 python secondproject.py argo-workflows create
 ```
 
 and trigger the first one manually:
 
 ```
 python firstproject.py argo-workflows trigger
 ```
 
 Thanks to `@project`, the flows are deployed with a special name that includes a
 branch prefix. By default,
 [each user gets their own
 prefix](/production/coordinating-larger-metaflow-projects#single-flow-multiple-developers),
 so you should the output of the `start` step of `FirstProjectFlow` should look
 like:
 
 ```
 The deployment is called variant_demo.user.alice.FirstProjectFlow
 ```
 
 The `SecondProjectFlow` starts automatically when `FirstProjectFlow` completes.
 It should show output like here:
 
 
 ```
 This deployment is called variant_demo.user.alice.SecondProjectFlow
 This run was triggered by
 MetaflowEvent(name='metaflow.variant_demo.user.alice.FirstProjectFlow.end', ...)
 ```
 which indicates that the event triggering the run is specific to Alice.",H2,https://docs.metaflow.org/production/event-triggering/project-events#using-project-and-trigger-on-finish-together,False,1916,297,https://docs.metaflow.org
384,Deploying a parallel branch,"To deploy a parallel variant or *a branch* - in the sense of Git branches -
 execute the following commands:
 
 ```
 python firstproject.py --branch new_model argo-workflows create
 python secondproject.py --branch new_model argo-workflows create
 ```
 and trigger the branch like here:
 ```
 python firstproject.py --branch new_model argo-workflows trigger
 ```
 
 You should see a corresponding output for these runs. Importantly, triggering
 the `new_model` branch doesn't have any effect on Alice's deployment, which is
 [fully isolated in its own namespace](/scaling/tagging).",H3,https://docs.metaflow.org/production/event-triggering/project-events#deploying-a-parallel-branch,False,581,79,https://docs.metaflow.org
385,Triggering across branches,"As shown above, `@project` guarantees that all flows linked together within the
 same project and branch are isolated from other deployments. However, sometimes
 you may want to depend on an upstream flow that is deployed outside of your
 branch. For instance, you may want to deploy a variant of a downstream
 workflow, like `SecondProjectFlow` above, while reusing results from an
 existing upstream flow, like `FirstProjectFlow`.
 
 You can accomplish this by specifying explicitly the project-branch name that
 you want to depend on. For instance, this line makes a flow depend on Alice's
 deployment regardless of the branch the flow is deployed on:
 
 ```python
 @trigger_on_finish(flow='variant_demo.user.alice.FirstProjectFlow')
 ```",H2,https://docs.metaflow.org/production/event-triggering/project-events#triggering-across-branches,False,741,106,https://docs.metaflow.org
386,Triggering Flows Based on Other Flows,"Besides triggering flows based on external events, you can trigger a flow when
 another flow completes. Metaflow provides a special decorator to support the
 pattern, [`@trigger_on_finish`](/api/flow-decorators/trigger_on_finish), which
 allows you to build arbitrarily complex systems of interconnected flows.
 
 Here, the completion of `FirstFlow` triggers a run of `SecondFlow`:
 
 ```mdx-code-block
 import ReactPlayer from 'react-player';
 ```
 
 <ReactPlayer playing controls muted loop url='/assets/et-flows.mp4' width='100%' height='100%'/>
 
 Let's demonstrate the case with two simple flows:
 
 ```python
 from metaflow import FlowSpec, step
 
 class FirstFlow(FlowSpec):
 
     @step
     def start(self):
         print(""This is the first flow"")
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     FirstFlow()
 ```
 
 and 
 
 ```python
 from metaflow import FlowSpec, step, trigger_on_finish
 
 @trigger_on_finish(flow='FirstFlow')
 class SecondFlow(FlowSpec):
 
     @step
     def start(self):
         print(""This is the second flow"")
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     SecondFlow()
 ```
 
 Deploy both the flows on Argo Workflows:
 ```
 python firstflow.py argo-workflows create
 python secondflow.py argo-workflows create
 ```
 
 Since we didn't specify a trigger or `@schedule` for `FirstFlow`, we must start it manually:
 ```
 python firstflow.py argo-workflows trigger
 ```
 
 After `FirstFlow` completes, you should see `SecondFlow` starting automatically.
 
 :::warning
 
 You can create infinite loops with `@trigger_on_finish`. For instance, if you
 specify `@trigger_on_finish(flow='SecondFlow')` for `FirstFlow` above, the
 flows will trigger each other infinitely, consuming resources on the cluster.
 If this happens, you can open the Argo Workflows UI and delete the workflow.
 
 :::",H1,https://docs.metaflow.org/production/event-triggering/flow-events#triggering-flows-based-on-other-flows,False,1947,327,https://docs.metaflow.org
387,Triggering based on multiple flows,"You can also depend on multiple flows completing before starting a flow. Simply define a list of flows:
 ```python
 @trigger_on_finish(flows=['FirstFlow', 'AnotherFlow'])
 ```
 all of the flows need to complete within a configured time windows for the flow to trigger.",H3,https://docs.metaflow.org/production/event-triggering/flow-events#triggering-based-on-multiple-flows,False,268,39,https://docs.metaflow.org
388,Passing data across flows,"Consider an extension of `ModelRefreshFlow` that was featured
 [on the previous
 page](/production/event-triggering/external-events#passing-parameters-in-events).
 This time, we want to use the newly trained model to run inference for the
 latest data. This requires passing the model object from `TrainingFlow` to
 `InferenceFlow`:
 
 <ReactPlayer playing controls muted loop url='/assets/et-combo.mp4' width='100%' height='100%'/>
 
 Whenever a flow is triggered by an event, information about the event is made
 available through
 [the `MetaflowTrigger`object](/api/client#metaflowtrigger)
 that is accessible at `current.trigger`. See the
 API documentation for [`MetaflowEvent` for all available event-related
 metadata](/api/client#metaflowevent).
 
 When using `@trigger_on_finish`, you can access information about the triggering
 runs through
 [`current.trigger.run`](/api/current#trigger-and-trigger_on_finish) or
 [`current.trigger.runs`](/api/current#trigger-and-trigger_on_finish) in
 the case of multiple flows, which return one or more
 [`Run` objects](/metaflow/client#properties-related-to-runs). Use the
 `Run` object to access artifacts as you do when
 [using the Client API directly](/metaflow/client).
 
 In this example, we access the `model` artifact created in `ModelRefreshFlow`:
 
 ```python
 from metaflow import FlowSpec, step, trigger_on_finish, current
 
 @trigger_on_finish(flow='ModelRefreshFlow')
 class InferenceFlow(FlowSpec):
 
     @step
     def start(self):
         print(""Triggering run"", current.trigger.run)
         self.model = current.trigger.run.data.model
         print('Model', self.model)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     InferenceFlow()
 ```",H2,https://docs.metaflow.org/production/event-triggering/flow-events#passing-data-across-flows,False,1771,238,https://docs.metaflow.org
389,Testing flow triggering locally,"You may have noticed one issue with `InferenceFlow` above. If you `run` it
 locally, it will fail as `current.trigger` is not defined. Obviously, it would
 be convenient to be able to test the flow before deploying to Argo Workflows.
 
 During development, you can manually assign the triggering run on the command line:
 
 ```
 python inferenceflow.py --trigger ModelRefreshFlow/233 run
 ```
 
 This will run the flow as if it was triggered by a run `ModelRefreshFlow/233`.
 This allows you to quickly iterate on the flow locally, testing it with
 different upstream data providers.",H2,https://docs.metaflow.org/production/event-triggering/flow-events#testing-flow-triggering-locally,False,583,93,https://docs.metaflow.org
390,Triggering Flows Based on External Events,"You can configure flows
 [deployed on Argo Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows)
 to start automatically when an event occurs in an external system. For instance, you
 could start a flow whenever new data is available in a data warehouse:
 
 ```mdx-code-block
 import ReactPlayer from 'react-player';
 ```
 
 <ReactPlayer playing controls muted loop url='/assets/et-basic-event.mp4' width='100%' height='100%'/>
 
 All you have to do is to add [a decorator, `@trigger`](/api/flow-decorators/trigger), with
 a desired event name above the flow:
 
 ```python
 from metaflow import FlowSpec, step, trigger
 
 @trigger(event='data_updated')
 class FreshDataFlow(FlowSpec):
 
     @step
     def start(self):
         # load data from the data warehouse
         print('processing fresh data!')
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     FreshDataFlow()
 ```
 
 You can develop and test the flow locally as usual: `@trigger` doesn't have any
 effect on local runs. To test triggering, deploy the flow to Argo Workflows:
 
 ```
 python freshdata.py argo-workflows create
 ```
 
 The output should state something along the lines of
 ```
 What will trigger execution of the workflow:
     This workflow triggers automatically when the upstream
     data_updated event is/are published.
 ```
 indicating that the deployment has been linked to the desired event.",H1,https://docs.metaflow.org/production/event-triggering/external-events#triggering-flows-based-on-external-events,False,1464,246,https://docs.metaflow.org
391,Defining events,"In the above example, we used `data_updated` as the name of the event that triggers the flow. You
 can choose the name freely. By using different names, you can make flows react to different events.
 
 If you are familiar with streaming systems like Kafka or queues like AWS SQS, you can think of the
 event name as *a topic* in these systems.",H3,https://docs.metaflow.org/production/event-triggering/external-events#defining-events,False,343,63,https://docs.metaflow.org
392,Depending on multiple events,"You can require that multiple events must be present before the flow gets
 triggered. Simply define a list of events:
 
 ```python
 @trigger(events=['data_updated', 'phase_of_the_moon'])
 ```
 
 all the events need to be occur within a configured time window for the flow to trigger.",H3,https://docs.metaflow.org/production/event-triggering/external-events#depending-on-multiple-events,False,283,43,https://docs.metaflow.org
393,Creating events,"In order to trigger the flow deployed with `@trigger`, we need an event.
 Metaflow comes with a utility class, [`ArgoEvent`](/api/argoevent), which
 makes it easy to create suitable events from any environment. You can call
 it as a part of your ETL pipeline running outside Metaflow, in a microservice,
 or in a notebook - wherever and whenever you want to trigger a Metaflow execution.
 
 ```python
 from metaflow.integrations import ArgoEvent
 
 ArgoEvent(name=""data_updated"").publish()
 ```
 
 This line will create an event that will trigger **all flows** deployed on Argo Workflows that are
 waiting for the event `data_updated`.
 
 Note that `publish()` only publishes an event and returns immediately. It does not guarantee that
 a run will start -- it's possible that no flow is waiting for the particular event. Correspondingly,
 if you call `ArgoEvent` many times, you can trigger arbitrarily many runs of connected flows.
 
 :::info
 
 Before calling `ArgoEvent` make sure that you have a valid Metaflow
 configuration and a connection to the Kubernetes cluster set up in the
 environment where you call `.publish()`. If you call it from systems outside
 Metaflow, make sure that these prerequisites are met.
 
 :::",H2,https://docs.metaflow.org/production/event-triggering/external-events#creating-events,False,1227,191,https://docs.metaflow.org
394,Advanced case: Publishing events inside a flow,"It is not common to publish events inside a Metaflow flow, since
 [the `@trigger_on_finish` decorator](/production/event-triggering/flow-events)
 takes care of flow-to-flow
 triggering conveniently. Should you have a more advanced use case that requires
 publishing events inside a flow, it is recommended that you use [the
 `ArgoEvent.safe_publish` method](/api/argoevent#ArgoEvent.safe_publish):
 
 ```python
 from metaflow.integrations import ArgoEvent
 
 ArgoEvent(name=""data_updated"").safe_publish()
 ```
 
 The only difference to `publish()` is that events won't be created during local
 runs. This means that you can include `safe_publish()` in your code safely and
 develop and test it locally as usual, knowing that you won't be causing
 unintended side-effects in surrounding systems that may depend on the event.",H3,https://docs.metaflow.org/production/event-triggering/external-events#advanced-case-publishing-events-inside-a-flow,False,823,105,https://docs.metaflow.org
395,Passing parameters in events,"Besides simply starting runs through events, you can change their behavior on
 the fly by letting the event
 [define `Parameters` of the flow](/metaflow/basics#how-to-define-parameters-for-flows).
 
 Consider this typical machine learning system that implements a continuously refreshing model:
 
 <ReactPlayer playing controls muted loop url='/assets/et-model.mp4' width='100%' height='100%'/>
 
 1. An event is created whenever new data is available in the data warehouse.
 2. The event contains information about the latest data available in the warehouse.
 3. Using the information, a model is refreshed with a training set containing the
 last N days of data.
 
 The corresponding flow could look like this, ignoring details of data loading and the actual
 training:
 
 ```python
 from metaflow import FlowSpec, step, trigger, Parameter
 from datetime import datetime, timedelta
 
 @trigger(event=""data_updated"")
 class ModelRefreshFlow(FlowSpec):
     latest = Parameter(""latest"", default=""2023-05-01"")
     window = Parameter(""window"", default=3)
 
     def load_data(self):
         # replace this with an actual data loader
         SQL = f""select * from data where time > to_date('{self.start_date}')""
         print(""loading data since %s"" % self.start_date)
         return [1, 2, 3]
 
     def train_model(self, df):
         # replace this with actual model training
         return df
 
     @step
     def start(self):
         self.latest_date = datetime.fromisoformat(self.latest)
         self.start_date = self.latest_date - timedelta(days=self.window)
         self.next(self.train)
 
     @step
     def train(self):
         df = self.load_data()
         self.model = self.train_model(df)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == ""__main__"":
     ModelRefreshFlow()
 ```
 
 To pass in parameters, we can simply define them in the `payload` of `ArgoEvent`:
 ```python
 from metaflow.integrations import ArgoEvent
 from datetime import datetime
 
 ArgoEvent(name=""data_updated"").publish(payload={'latest': datetime.now().isoformat()})
 ```",H2,https://docs.metaflow.org/production/event-triggering/external-events#passing-parameters-in-events,False,2114,391,https://docs.metaflow.org
396,Mapping parameter names,"Above, the payload field matches the parameter name `latest` exactly. In certain situations you may want
 to define manually how parameters get their values. For instance, a common event may be used to trigger
 various kinds of flows and it may be hard to coordinate parameter names across all consumers of the event.
 
 In this situation, you can remap payload fields to parameter names through the `parameters` argument:
 ```python
 @trigger(event={'name':'some_event', 'parameters': {'window': 'how_many_days'}})
 ```
 Here, we define that `Parameter('window')` gets its value from the event payload field `how_many_days`.
 Note that you need to remap all `parameters` that you want to assign through the event. Default assignments
 are disabled when `parameters` is specified, which allows you to stay in full control of parameter mappings.
 
 Parameter mapping comes in handy when multiple events are present:
 ```python
 @trigger(events=[{'name':'one_event', 'parameters': {'window': 'how_many_days'}},
                  {'name':'another_event', 'parameters': {'latest': 'timestamp'}}])
 ```
 In this case, `window` gets its value through the event `one_event` and `latest` through `another_event`.",H3,https://docs.metaflow.org/production/event-triggering/external-events#mapping-parameter-names,False,1204,177,https://docs.metaflow.org
397,Scheduling Metaflow Flows,"While the `run` command is convenient during development, you can't keep executing it
 manually in production. An old-school solution would be to use a time-based scheduler
 like [Cron](https://en.wikipedia.org/wiki/Cron) to execute the command automatically at
 a set schedule, but this approach has a number of serious downsides:
 
 What if the server running cron fails? If the scheduled command fails, how do you know
 it has failed? How do you see its error logs? Does the Cron server have enough capacity
 to handle another command? And most importantly, how should you orchestrate schedules of
 multiple commands so that their mutual dependencies are handled correctly?
 
 Metaflow currently integrates with [Argo
 Workflows](../scheduling-metaflow-flows/scheduling-with-argo-workflows.md) ([a modern,
 Kubernetes-native workflow orchestrator](https://argoproj.github.io/workflows)), [AWS
 Step Functions](../scheduling-metaflow-flows/scheduling-with-aws-step-functions.md) ([a
 managed general-purpose orchestrator](https://aws.amazon.com/step-functions/)), and
 [Apache Airflow](../scheduling-metaflow-flows/scheduling-with-airflow.md) ([a
 widely-known open-source orchestrator](https://airflow.apache.org/)) which can answer
 these questions.
 
 Learn more about how to deploy your Metaflow flows to these orchestrators in the
 following subsections:",H1,https://docs.metaflow.org/production/scheduling-metaflow-flows/introduction#scheduling-metaflow-flows,False,1361,151,https://docs.metaflow.org
398,Scheduling Metaflow Flows with Apache Airflow,"[Apache Airflow](https://airflow.apache.org/) is a popular open-source workflow
 orchestrator. It has a number of limitations compared to [Argo
 Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows) and
 [AWS Step
 Functions](/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions), so
 we mainly recommend it if you are an existing Airflow user and you want to avoid
 introducing a new orchestrator in your environment.
 
 The Metaflow-Airflow integration is a great way to modernize your Airflow deployment. It
 provides a more user-friendly and productive development API for data scientists and
 data engineers, without needing to change anything in your existing pipelines or
 operational playbooks, as described in [its announcement blog
 post](https://outerbounds.com/blog/better-airflow-with-metaflow/). To learn how to
 deploy and operate the integration, see [Using Airflow with
 Metaflow](https://outerbounds.com/engineering/operations/airflow/).
 
 Here are the main benefits of using Metaflow with Airflow:
 
  - You get to use the human-friendly API of Metaflow to define and test workflows.
    Almost all features of Metaflow work with Airflow out of the box, except nested
    foreaches, which are not supported by Airflow, and `@batch` as the current
    integration only supports `@kubernetes`.
  - You can deploy Metaflow flows to your existing Airflow server without having to
  change anything operationally. From the Airflow's point of view, Metaflow flows look
  like any other Airflow DAG.
  - If you want to consider moving to another orchestrator supported by Metaflow, you can
    test them easily just by changing one command to deploy to [Argo
    Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows) or
    [AWS Step
    Functions](/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions).
 
 When running on Airflow, Metaflow code works exactly as it does locally: No changes are
 required in the code. All data artifacts produced by steps run on Airflow are available
 using the [Client API](../../metaflow/client.md). All tasks are run on Kubernetes
 respecting the `@resources` decorator, as if the `@kubernetes` decorator was added to
 all steps, as explained in [Executing Tasks
 Remotely](/scaling/remote-tasks/introduction#safeguard-flags).
 
 This document describes the basics of Airflow scheduling. If your project involves
 multiple people, multiple workflows, or it is becoming business-critical, check out the
 section around [coordinating larger Metaflow
 projects](../coordinating-larger-metaflow-projects.md).",H1,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#scheduling-metaflow-flows-with-apache-airflow,False,2647,345,https://docs.metaflow.org
399,Pushing a flow to production,"Let's use [the flow from the section about
 parameters](../../metaflow/basics#how-to-define-parameters-for-flows) as an example:
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 
 class ParameterFlow(FlowSpec):
     alpha = Parameter('alpha',
                       help='Learning rate',
                       default=0.01)
 
     @step
     def start(self):
         print('alpha is %f' % self.alpha)
         self.next(self.end)
 
     @step
     def end(self):
         print('alpha is still %f' % self.alpha)
 
 if __name__ == '__main__':
     ParameterFlow()
 ```
 
 Save this script to a file `parameter_flow.py`. To deploy a version to Airflow, simply
 run
 ```
 python parameter_flow.py --with retry airflow create parameter_dag.py 
 ```
 
 This command takes a snapshot of your code in the working directory, as well as the
 version of Metaflow used, and creates an Airflow DAG in `parameter_dag.py` for
 scheduling on Airflow. You should deploy `parameter_dag.py` to your Airflow instance
 like you would do with any other user-written DAG.
 
 Metaflow automatically maps the Parameters of your flow to corresponding parameters on
 Airflow. You can execute your Metaflow flow deployed on Airflow like any other Airflow
 DAG - seamlessly getting all the benefits of Airflow alongside all the benefits of
 Metaflow.",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#pushing-a-flow-to-production,False,1337,265,https://docs.metaflow.org
400,Hardening deployments,"It is highly recommended that you [enable
 retries](../../scaling/failures#retrying-tasks-with-the-retry-decorator) when deploying
 to Airflow, which you can do easily with `--with retry` as shown above. However, make
 sure that all your steps are safe to retry before you do this. If some of your steps
 interact with external services in ways that can't tolerate automatic retries, decorate
 them with retry with times set to zero \(times=0\) as described in [How to Prevent
 Retries](../../scaling/failures#how-to-prevent-retries).
 
 
 If you want to test on Airflow without interfering with a production flow, you can
 change the name of your class, e.g. from `ParameterFlow` to `ParameterFlowStaging`, and
 airflow create the dag under a new name or [use the @project
 decorator](../coordinating-larger-metaflow-projects.md).
 
 Note that airflow create creates a new isolated production namespace for your production
 flow. Read [Organizing Results](/scaling/tagging) to learn all about namespace behavior.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#hardening-deployments,False,1013,137,https://docs.metaflow.org
401,Limiting the number of concurrent tasks,"By default, Metaflow configures Airflow to execute at most 100 tasks concurrently within
 a foreach step. This should ensure that most workflows finish quickly without
 overwhelming your Kubernetes cluster, the execution backend.
 
 If your workflow includes a large foreach and you need results faster, you can increase
 the default with the `--max-workers` option. For instance, `airflow create --max-workers
 500` allows 500 tasks to be executed concurrently for every foreach step.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#limiting-the-number-of-concurrent-tasks,False,485,71,https://docs.metaflow.org
403,Deploy-time parameters,"You can customize Airflow deployments through Parameters that are evaluated at the
 deployment time, i.e. when `airflow create` is executed.
 
 For instance, you can change the default value of a `Parameter` based on who deployed
 the workflow or what Git branch the deployment was executed in. Crucially, the function
 in Parameter is evaluated only once during `airflow create` and not during the execution
 of the flow.
 
 You can run the flow locally as usual. The function inside `Parameter` is called only
 once when the execution starts.
 
 ```python
 from metaflow import FlowSpec, Parameter, step, JSONType
 from datetime import datetime
 import json
 
 def deployment_info(context):
     return json.dumps({'who': context.user_name,
                        'when': datetime.now().isoformat()})
 
 class DeploymentInfoFlow(FlowSpec):
     info = Parameter('deployment_info',
                      type=JSONType,
                      default=deployment_info)
 
     @step
     def start(self):
         print('This flow was deployed at %s by %s'\
               % (self.info['when'], self.info['who']))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     DeploymentInfoFlow()
 ```
 
 When `airflow create` is called, `deployment_info` is evaluated which captures your
 username and the time of deployment. This information remains constant on Airflow
 Workflows, although the user may override the default value.
 
 The `context` object is passed to any function defined in Parameter. It contains various
 fields related to the flow being deployed. By relying on the values passed in context,
 you can create generic deploy-time functions that can be reused by multiple flows.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#deploy-time-parameters,False,1744,354,https://docs.metaflow.org
404,Scheduling a flow,"By default, a flow on Airflow does not run automatically. You need to set up a trigger
 to launch the flow when an event occurs.
 
 On Airflow, Metaflow provides built-in support for triggering Metaflow flows
 through time-based \(cron\) triggers, which, as the name implies, triggers the
 workflow at a certain time. As of today, [event-based triggering]
 (/production/event-triggering) is not supported on Airflow.
 
 Time-based triggers are implemented at the FlowSpec-level using the `@schedule`
 decorator. This flow is triggered hourly:
 
 ```python
 from metaflow import FlowSpec, schedule, step
 from datetime import datetime
 
 @schedule(hourly=True)
 class HourlyFlow(FlowSpec):
 
     @step
     def start(self):
         now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
         print('time is %s' % now)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     HourlyFlow()
 ```
 
 You can define the schedule with `@schedule` in one of the following ways:",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#scheduling-a-flow,False,1025,188,https://docs.metaflow.org
405,Reproducing failed production runs,"Let's use [`DebugFlow` from the debugging
 section](/metaflow/debugging#how-to-use-the-resume-command) as an example. The flow
 contains a bug in the step `b`. When you run it, the failed run will look like this on
 the Airflow UI:
 
 ![](/assets/airflow_debug.png)
 
 The graph visualization shows that step b failed, as expected. First, you should inspect
 the logs of the failed step in the Airflow UI (or the Metaflow UI) to get an idea of why
 it failed.
 
 Notice the Metaflow Run ID of `airflow-ec19e85042a1` that is available from the Rendered
 Template page for the failed task in the Airflow UI (look for the `metaflow_run_id`
 attribute). You can use this Run ID to locate the execution in the Metaflow UI as well
 if needed.
 
 ![](/assets/airflow_debug1.png)
 
 Next, we want to reproduce the above error locally. We do this by resuming the specific
 Airflow run that failed:
 
 ```
 python debug.py resume --origin-run-id airflow-ec19e85042a1
 ```
 This will reuse the results of the start and a step from the Airflow run. It will try to
 rerun the step `b` locally, which fails with the same error as it does in production.
 
 You can fix the error locally, as above. In the case of this simple flow, you can run
 the whole flow locally to confirm that the fix works. After validating the results, you
 would deploy a new version to production with airflow create.
 
 However, this might not be a feasible approach for complex production flow. For
 instance, the flow might process large amounts of data that can not be handled in your
 local instance. We have better approaches for staging flows for production:",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#reproducing-failed-production-runs,False,1627,271,https://docs.metaflow.org
406,Staging flows for production,"The easiest approach to test a demanding flow is to run it on Kubernetes. This works
 even with resume:
 ```
 python debug.py resume --origin-run-id airflow-ec19e85042a1 --with kubernetes
 ```
 
 This will resume your flow and run every step on Kubernetes. When you are ready to test
 a fixed flow end-to-end, just run it as follows:
 ```
 python debug.py run --with kubernetes
 ```
 
 Alternatively, you can change the name of the flow temporarily, e.g. from DebugFlow to
 DebugFlowStaging. Then you can run `airflow create` with the new name, which will create
 a separate staging flow on Airflow. You can also use the
 [`@project`](/production/coordinating-larger-metaflow-projects.md#the-project-decorator)
 decorator.
 
 You can test the staging flow freely without interfering with the production flow. Once
 the staging flow runs successfully, you can confidently deploy a new version to
 production.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-airflow#staging-flows-for-production,False,907,133,https://docs.metaflow.org
407,Scheduling Metaflow Flows with AWS Step Functions,"[AWS Step Functions](https://aws.amazon.com/step-functions/) is a general-purpose
 workflow orchestrator - you can [read AWS Step Functions documentation to learn all
 about it](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html). If you
 just want to get your flow in production, this document contains everything you need to
 know.
 
 In Metaflow's point of view, the main benefits of AWS Step Functions are the following:",H1,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#scheduling-metaflow-flows-with-aws-step-functions,False,439,55,https://docs.metaflow.org
408,Pushing a flow to production,"Let's use [the flow from the section about
 parameters](../../metaflow/basics#how-to-define-parameters-for-flows) as an example:
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 
 class ParameterFlow(FlowSpec):
     alpha = Parameter('alpha',
                       help='Learning rate',
                       default=0.01)
 
     @step
     def start(self):
         print('alpha is %f' % self.alpha)
         self.next(self.end)
 
     @step
     def end(self):
         print('alpha is still %f' % self.alpha)
 
 if __name__ == '__main__':
     ParameterFlow()
 ```
 
 Save this script to a file `parameter_flow.py`. To deploy a version to AWS Step
 Functions, simply run
 
 ```bash
 python parameter_flow.py --with retry step-functions create
 ```
 
 This command takes a snapshot of your code in the working directory, as well as the
 version of Metaflow used and exports the whole package to AWS Step Functions for
 scheduling.
 
 It is highly recommended that you [enable
 retries](../../scaling/failures#retrying-tasks-with-the-retry-decorator) when deploying
 to AWS Step Functions, which you can do easily with --with retry as shown above.
 However, make sure that all your steps are safe to retry before you do this. If some of
 your steps interact with external services in ways that can't tolerate automatic
 retries, decorate them with retry with times set to zero \(times=0\) as described in
 [How to Prevent Retries](../../scaling/failures#how-to-prevent-retries).
 
 The command will export your workflow to AWS Step Functions. You can also search for the
 flow by name within the AWS Step Functions UI. You should see a visualization of the
 exported flow, like here:
 
 ![](/assets/image2.png)
 
 ![](/assets/image5.png)
 
 You can click the orange Start Execution button to execute the flow on AWS Step
 Functions. It pops up a dialog asking for an input. You can specify your parameters as
 an escaped JSON string with `Parameters` as the key - \*\*\*\*
 
 ```bash
 {
     ""Parameters"" : ""{\""alpha\"": 0.5}""
 }
 ```
 
 Metaflow automatically maps Parameters of your flow to corresponding parameters on AWS
 Step Functions.
 
 After you click Start Execution on the Input dialog, AWS Step Functions starts running
 the flow:
 
 ![](/assets/image6.png)
 
 In this case, the run should succeed without problems. If there were errors, you could
 reproduce them locally as explained in [Debugging with
 Metaflow](../../metaflow/debugging#reproducing-production-issues-locally).
 
 You can trigger the workflow through command line as well:
 
 ```bash
 python parameter_flow.py step-functions trigger --alpha 0.5
 ```
 
 If you run `step-functions create` again, it will create a new version of your flow on
 AWS Step Functions. The newest version becomes the production version automatically
 \(due to the consistency guarantees provided by AWS Step Functions, it might be a couple
 of seconds before this happens\). If you want to test on AWS Step Functions without
 interfering with a production flow, you can change the name of your class, e.g. from
 ParameterFlow to ParameterFlowStaging, and `step-functions create` the flow under a new
 name or use the
 [@project](../coordinating-larger-metaflow-projects.md/#projects-on-aws-step-functions--argo-workflows)
 decorator.
 
 Note that `step-functions create` creates a new isolated [production
 namespace](../../scaling/tagging#production-namespaces) for your production flow. Please
 read [Organizing Results](../../scaling/tagging) to learn all about namespace behavior.
 
 In case your flow doesn't accept any parameters, and you would like to execute it from
 within the AWS Step Functions UI, you would need to pass in the following in the input
 dialog box:
 
 ```bash
 {
     ""Parameters"" : ""{}""
 }
 ```",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#pushing-a-flow-to-production,False,3793,620,https://docs.metaflow.org
409,Limiting the number of concurrent tasks,"By default, Metaflow configures AWS Step Functions to execute at most 100 tasks
 concurrently within a foreach step. This should ensure that most workflows finish
 quickly without overwhelming your AWS Batch queue, the execution backend.
 
 If your workflow includes a large foreach and you need results faster, you can increase",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#limiting-the-number-of-concurrent-tasks,False,328,51,https://docs.metaflow.org
412,Deploy-time parameters,"You can customize AWS Step Functions deployments through Parameters that are evaluated
 at the deployment time, i.e. when `step-functions create` is executed.
 
 For instance, you can change the default value of a Parameter based on who deployed the
 workflow or what Git branch the deployment was executed in. Crucially, the function in
 Parameter is evaluated only once during `step-functions create` and not during the
 execution of the flow.
 
 You can run the flow locally as usual. The function inside Parameter is called only once
 when the execution starts.
 
 ```python
 from metaflow import FlowSpec, Parameter, step, JSONType
 from datetime import datetime
 import json
 
 def deployment_info(context):
     return json.dumps({'who': context.user_name,
                        'when': datetime.now().isoformat()})
 
 class DeploymentInfoFlow(FlowSpec):
     info = Parameter('deployment_info',
                      type=JSONType,
                      default=deployment_info)
 
     @step
     def start(self):
         print('This flow was deployed at %s by %s'\
               % (self.info['when'], self.info['who']))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     DeploymentInfoFlow()
 ```
 
 When `step-functions create` is called, `deployment_info` is evaluated which captures
 your username and the time of deployment. This information remains constant on AWS Step
 Functions, although the user may override the default value.
 
 The `context` object is passed to any function defined in Parameter. It contains various
 fields related to the flow being deployed. By relying on the values passed in context,
 you can create generic deploy-time functions that can be reused by multiple flows.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#deploy-time-parameters,False,1773,357,https://docs.metaflow.org
413,Scheduling a flow,"By default, a flow on AWS Step Functions does not run automatically. You need to set up
 a trigger to launch the flow when an event occurs.
 
 On Step Functions, Metaflow provides built-in support for triggering Metaflow
 flows through time-based \(cron\) triggers, which, as the name implies,
 triggers the workflow at a certain time. As of today, [event-based triggering]
 (/production/event-triggering) is not supported on Step Functions.
 
 Time-based triggers are implemented at the FlowSpec-level using the `@schedule`
 decorator. This flow is triggered hourly:
 
 ```python
 from metaflow import FlowSpec, schedule, step
 from datetime import datetime
 
 @schedule(hourly=True)
 class HourlyFlow(FlowSpec):
 
     @step
     def start(self):
         now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
         print('time is %s' % now)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     HourlyFlow()
 ```
 
 You can define the schedule with `@schedule` in one of the following ways:",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#scheduling-a-flow,False,1050,192,https://docs.metaflow.org
414,Reproducing failed production runs,"Let's use [`DebugFlow` from the debugging
 section](/metaflow/debugging#how-to-use-the-resume-command) as an example. The flow
 contains a bug in the step `b`. When you run it, the failed run will look like this on
 the AWS Step Functions UI:
 
 ![](/assets/image1.png)
 
 ![](</assets/image3_(1).png>)
 
 Notice the execution ID of `5ca85f96-8508-409d-a5f5-b567db1040c5`. When running on AWS
 Step Functions, Metaflow uses the AWS Step Functions execution ID (prefixed with `sfn-`)
 as the run id.
 
 The graph visualization shows that step `b` failed, as expected. First, you should
 inspect the logs of the failed step to get an idea of why it failed. You can access AWS
 Batch step logs in the AWS Step Functions UI by looking for the `JobId` in the `Error`
 blob that can be accessed by clicking on the `Exception` pane on the right side of the
 UI. You can use this `JobId` in the AWS Batch console to check the job logs. This
 `JobId` is also the metaflow task ID for the step.
 
 Next, we want to reproduce the above error locally. We do this by resuming the specific
 AWS Step Functions run that failed:
 
 ```bash
 python debug.py resume --origin-run-id sfn-5ca85f96-8508-409d-a5f5-b567db1040c5
 ```
 
 This will reuse the results of the `start` and `a` step from the AWS Step Functions run.
 It will try to rerun the step `b` locally, which fails with the same error as it does in
 production.
 
 You can fix the error locally as above. In the case of this simple flow, you can run the
 whole flow locally to confirm that the fix works. After validating the results, you
 would deploy a new version to production with `step-functions create`.
 
 However, this might not be a feasible approach for complex production flow. For
 instance, the flow might process large amounts of data that can not be handled in your
 local instance. We have better approaches for staging flows for production:",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#reproducing-failed-production-runs,False,1901,316,https://docs.metaflow.org
415,Staging flows for production,"The easiest approach to test a demanding flow is to run it with AWS Batch. This works
 even with resume:
 
 ```bash
 python debug.py resume --origin-run-id sfn-5ca85f96-8508-409d-a5f5-b567db1040c5 --with batch
 ```
 
 This will resume your flow and run every step on AWS Batch. When you are ready to test a
 fixed flow end-to-end, just run it as follows:
 
 ```bash
 python debug.py run --with batch
 ```
 
 Alternatively, you can change the name of the flow temporarily, e.g. from DebugFlow to
 DebugFlowStaging. Then you can run `step-functions create` with the new name, which will
 create a separate staging flow on AWS Step Functions. You can also use the
 [`@project`](/production/coordinating-larger-metaflow-projects.md#the-project-decorator)
 decorator.
 
 You can test the staging flow freely without interfering with the production flow. Once
 the staging flow runs successfully, you can confidently deploy a new version to
 production.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#staging-flows-for-production,False,947,139,https://docs.metaflow.org
416,Scheduling Metaflow Flows with Argo Workflows,"[Argo Workflows](https://argoproj.github.io/workflows) is a Kubernetes-native workflow
 orchestrator - you can [read Argo Workflows documentation to learn all about
 it](https://argoproj.github.io/argo-workflows/core-concepts/). If you just want to get
 your flow in production, this document contains everything you need to know.
 
 In Metaflow's point of view, the main benefits of Argo Workflows are the following:",H1,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#scheduling-metaflow-flows-with-argo-workflows,False,417,52,https://docs.metaflow.org
417,Pushing a flow to production,"Let's use [the flow from the section about
 parameters](../../metaflow/basics#how-to-define-parameters-for-flows) as an example:
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 
 class ParameterFlow(FlowSpec):
     alpha = Parameter('alpha',
                       help='Learning rate',
                       default=0.01)
 
     @step
     def start(self):
         print('alpha is %f' % self.alpha)
         self.next(self.end)
 
     @step
     def end(self):
         print('alpha is still %f' % self.alpha)
 
 if __name__ == '__main__':
     ParameterFlow()
 ```
 
 Save this script to a file `parameter_flow.py`. To deploy a version to Argo Workflows,
 simply run
 
 ```bash
 python parameter_flow.py --with retry argo-workflows create
 ```
 
 This command takes a snapshot of your code in the working directory, as well as the
 version of Metaflow used and exports the whole package to Argo Workflows for scheduling.
 
 It is highly recommended that you [enable
 retries](../../scaling/failures#retrying-tasks-with-the-retry-decorator) when deploying
 to Argo Workflows, which you can do easily with --with retry as shown above. However,
 make sure that all your steps are safe to retry before you do this. If some of your
 steps interact with external services in ways that can't tolerate automatic retries,
 decorate them with retry with times set to zero \(times=0\) as described in [How to
 Prevent Retries](../../scaling/failures#how-to-prevent-retries).
 
 The command will export your workflow to  Argo Workflows as a _workflow template_. You
 can also search for the _workflow template_ by name within the Argo Workflows UI. 
 
 ![](/assets/argo-ui.png)
 
 You can click on _Submit new workflow_ to submit your generated _Workflow Template_ for
 execution
 
 ![](/assets/argo-ui-0.png)
 
 Metaflow automatically maps Parameters of your flow to corresponding parameters on Argo
 Workflows.
 
 ![](/assets/argo-ui-1.png)
 
 After you click _Submit_, Argo Workflow starts running the flow:
 
 ![](/assets/argo-ui-2.png)
 
 In this case, the run should succeed without problems. If there were errors, you could
 reproduce them locally as explained in [Debugging with
 Metaflow](../../metaflow/debugging#reproducing-production-issues-locally).
 
 You can trigger the workflow through command line as well:
 
 ```bash
 python parameter_flow.py argo-workflows trigger --alpha 0.5
 ```
 
 If you run `argo-workflows create` again, it will create a new version of your flow on
 Argo Workflows. The newest version becomes the production version automatically. If you
 want to test on Argo Workflows without interfering with a production flow, you can
 change the name of your class, e.g. from ParameterFlow to ParameterFlowStaging, and
 `argo-workflows create` the flow under a new name or use the
 [@project](../coordinating-larger-metaflow-projects.md/#projects-on-aws-step-functions--argo-workflows)
 decorator.
 
 Note that `argo-workflows create` creates a new isolated [production
 namespace](../../scaling/tagging#production-namespaces) for your production flow. Please
 read [Organizing Results](../../scaling/tagging) to learn all about namespace behavior.",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#pushing-a-flow-to-production,False,3185,496,https://docs.metaflow.org
418,Limiting the number of concurrent tasks,"By default, Metaflow configures Argo Workflows to execute at most 100 tasks concurrently
 within a foreach step. This should ensure that most workflows finish quickly without
 overwhelming your Kubernetes cluster, the execution backend.
 
 If your workflow includes a large foreach and you need results faster, you can increase",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#limiting-the-number-of-concurrent-tasks,False,327,49,https://docs.metaflow.org
421,Deploy-time parameters,"You can customize Argo Workflows deployments through Parameters that are evaluated at
 the deployment time, i.e. when `argo-workflows create` is executed.
 
 For instance, you can change the default value of a Parameter based on who deployed the
 workflow or what Git branch the deployment was executed in. Crucially, the function in
 Parameter is evaluated only once during `argo-workflows create` and not during the
 execution of the flow.
 
 You can run the flow locally as usual. The function inside Parameter is called only once
 when the execution starts.
 
 ```python
 from metaflow import FlowSpec, Parameter, step, JSONType
 from datetime import datetime
 import json
 
 def deployment_info(context):
     return json.dumps({'who': context.user_name,
                        'when': datetime.now().isoformat()})
 
 class DeploymentInfoFlow(FlowSpec):
     info = Parameter('deployment_info',
                      type=JSONType,
                      default=deployment_info)
 
     @step
     def start(self):
         print('This flow was deployed at %s by %s'\
               % (self.info['when'], self.info['who']))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     DeploymentInfoFlow()
 ```
 
 When `argo-workflows create` is called, `deployment_info` is evaluated which captures
 your username and the time of deployment. This information remains constant on Argo
 Workflows, although the user may override the default value.
 
 The `context` object is passed to any function defined in Parameter. It contains various
 fields related to the flow being deployed. By relying on the values passed in context,
 you can create generic deploy-time functions that can be reused by multiple flows.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#deploy-time-parameters,False,1765,355,https://docs.metaflow.org
422,Scheduling a flow,"By default, a flow on Argo Workflows does not run automatically. You need to set up a
 trigger to launch the flow when an event occurs. With Argo Workflows, Metaflow supports
 two kinds of triggering:
 
 1. [Triggering based on events (using `@trigger` and `@trigger_on_finish`)](/production/event-triggering).
 2. Triggering based on time (using `@schedule`), described below.",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#scheduling-a-flow,False,377,54,https://docs.metaflow.org
423,Time-based triggering,"Metaflow provides built-in support for triggering Metaflow flows through time-based
 \(cron\) triggers. Use a time-based trigger if you want to trigger the workflow at a
 certain time.
 
 Time-based triggers are implemented at the FlowSpec-level using the `@schedule`
 decorator. This flow is triggered hourly:
 
 ```python
 from metaflow import FlowSpec, schedule, step
 from datetime import datetime
 
 @schedule(hourly=True)
 class HourlyFlow(FlowSpec):
 
     @step
     def start(self):
         now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
         print('time is %s' % now)
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     HourlyFlow()
 ```
 
 You can define the schedule with `@schedule` in one of the following ways:",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#time-based-triggering,False,793,152,https://docs.metaflow.org
424,Reproducing failed production runs,"Let's use [`DebugFlow` from the debugging
 section](/metaflow/debugging#how-to-use-the-resume-command) as an example. The flow
 contains a bug in the step `b`. When you run it, the failed run will look like this on
 the Argo Workflows UI:
 
 ![](/assets/argo-ui-fail.png)
 
 Notice the execution ID of `branchflow-r8qcn`. When running on Argo Workflows, Metaflow
 uses the Argo Workflows _workflow execution_ name (prefixed with `argo-`) as the run id.
 
 The graph visualization shows that step `b` failed, as expected. First, you should
 inspect the logs of the failed step to get an idea of why it failed. You can access
 Kubernetes step logs in the Argo Workflows UI by selecting the failed task and clicking
 on the logs button. 
 
 Next, we want to reproduce the above error locally. We do this by resuming the specific
 Argo Workflows run that failed:
 
 ```bash
 python debug.py resume --origin-run-id argo-branchflow-r8qcn
 ```
 
 This will reuse the results of the `start` and `a` step from the Argo Workflows run. It
 will try to rerun the step `b` locally, which fails with the same error as it does in
 production.
 
 You can fix the error locally as above. In the case of this simple flow, you can run the
 whole flow locally to confirm that the fix works. After validating the results, you
 would deploy a new version to production with `argo-workflows create`.
 
 However, this might not be a feasible approach for complex production flow. For
 instance, the flow might process large amounts of data that can not be handled in your
 local instance. We have better approaches for staging flows for production:",H2,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#reproducing-failed-production-runs,False,1624,268,https://docs.metaflow.org
425,Staging flows for production,"The easiest approach to test a demanding flow is to run it with Kubernetes. This works
 even with resume:
 
 ```bash
 python debug.py resume --origin-run-id argo-branchflow-r8qcn --with kubernetes
 ```
 
 This will resume your flow and run every step on Kubernetes. When you are ready to test
 a fixed flow end-to-end, just run it as follows:
 
 ```bash
 python debug.py run --with kubernetes
 ```
 
 Alternatively, you can change the name of the flow temporarily, e.g. from DebugFlow to
 DebugFlowStaging. Then you can run `argo-workflows create` with the new name, which will
 create a separate staging flow on Argo Workflows. You can also use the
 [`@project`](/production/coordinating-larger-metaflow-projects.md#the-project-decorator)
 decorator.
 
 You can test the staging flow freely without interfering with the production flow. Once
 the staging flow runs successfully, you can confidently deploy a new version to
 production.",H3,https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#staging-flows-for-production,False,936,136,https://docs.metaflow.org
426,FlowSpec - Constructing flows,"Metaflow [flows are defined](/metaflow/basics) by inhering from the `FlowSpec` class:
 ```python
 from metaflow import FlowSpec, step
 
 class MyFlow(FlowSpec):
 
     @step
     def start(self):
         self.next(self.end)
        
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     MyFlow()
 ```
 
 This class has no other uses. It can't be instantiated directly.
 
 `FlowSpec` exposes a few methods and attributes that you can use to construct a flow, which are listed below. You can add more functionality in your flows through [step-level decorators](step-decorators) and [flow-level decorators](flow-decorators).
 
 You can parametrize flows through the [`Parameter`](#parameters) object that are defined as class variables inside a flow. You can also include files as parameters through the [`IncludeFile`](#includefile) object.
 
 To query and manipulate the currently executing run inside your flow, see the [`current`](current) object. To access results produced by a flow, see the [Client API](client).",H1,https://docs.metaflow.org/api/flowspec#flowspec-constructing-flows,False,1043,181,https://docs.metaflow.org
427,Defining a workflow,"Annotate methods that are a part of your Metaflow workflow with [the `@step` decorator](/api/step-decorators/step). Use `FlowSpec.next` to define transitions between steps:
 
 
 <DocSection type=""method"" name=""FlowSpec.next"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/flowspec.py#L502"">
 <SigArgSection>
 <SigArg name=""*dsts, foreach=None"" />
 </SigArgSection>
 <Description summary=""Indicates the next step to execute after this step has completed."" extended_summary=""This statement should appear as the last statement of each step, except\nthe end step.\n\nThere are several valid formats to specify the next step:\n\n- Straight-line connection: `self.next(self.next_step)` where `next_step` is a method in\n  the current class decorated with the `@step` decorator.\n\n- Static fan-out connection: `self.next(self.step1, self.step2, ...)` where `stepX` are\n  methods in the current class decorated with the `@step` decorator.\n\n- Foreach branch:\n  ```\n  self.next(self.foreach_step, foreach='foreach_iterator')\n  ```\n  In this situation, `foreach_step` is a method in the current class decorated with the\n  `@step` decorator and `foreach_iterator` is a variable name in the current class that\n  evaluates to an iterator. A task will be launched for each value in the iterator and\n  each task will execute the code specified by the step `foreach_step`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""dsts"" type=""Method"" desc=""One or more methods annotated with `@step`."" />
 </ParamSection>
 <ParamSection name=""Raises"">
 	<Parameter type=""InvalidNextException"" desc=""Raised if the format of the arguments does not match one of the ones given above."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/flowspec#defining-a-workflow,False,1781,214,https://docs.metaflow.org
428,Working with foreaches,"Use the operations below, `FlowSpec.input`, `FlowSpec.index`, and `FlowSpec.foreach_stack` to query the status of the currently executing foreach branch. Use `FlowSpec.merge_artifacts()` to handle incoming artifacts in a join step.
 
 
 <DocSection type=""property"" name=""FlowSpec.input"" module=""metaflow.flowspec"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""The value of the foreach artifact in this foreach branch.\n\nIn a foreach step, multiple instances of this step (tasks) will be executed,\none for each element in the foreach. This property returns the element passed\nto the current task. If this is not a foreach step, this returns None.\n\nIf you need to know the values of the parent tasks in a nested foreach, use\n`FlowSpec.foreach_stack`.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""object, optional"" desc=""Input passed to the foreach task."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""FlowSpec.index"" module=""metaflow.flowspec"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""The index of this foreach branch.\n\nIn a foreach step, multiple instances of this step (tasks) will be executed,\none for each element in the foreach. This property returns the zero based index\nof the current task. If this is not a foreach step, this returns None.\n\nIf you need to know the indices of the parent tasks in a nested foreach, use\n`FlowSpec.foreach_stack`.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""int, optional"" desc=""Index of the task in a foreach step."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""FlowSpec.foreach_stack"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/flowspec.py#L276"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Returns the current stack of foreach indexes and values for the current step."" extended_summary=""Use this information to understand what data is being processed in the current\nforeach branch. For example, considering the following code:\n```\n@step\ndef root(self):\n    self.split_1 = ['a', 'b', 'c']\n    self.next(self.nest_1, foreach='split_1')\n\n@step\ndef nest_1(self):\n    self.split_2 = ['d', 'e', 'f', 'g']\n    self.next(self.nest_2, foreach='split_2'):\n\n@step\ndef nest_2(self):\n    foo = self.foreach_stack()\n```\n\n`foo` will take the following values in the various tasks for nest_2:\n```\n    [(0, 3, 'a'), (0, 4, 'd')]\n    [(0, 3, 'a'), (1, 4, 'e')]\n    ...\n    [(0, 3, 'a'), (3, 4, 'g')]\n    [(1, 3, 'b'), (0, 4, 'd')]\n    ...\n```\nwhere each tuple corresponds to:\n\n- The index of the task for that level of the loop.\n- The number of splits for that level of the loop.\n- The value for that level of the loop.\n\nNote that the last tuple returned in a task corresponds to:\n\n- 1st element: value returned by `self.index`.\n- 3rd element: value returned by `self.input`."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""List[Tuple[int, int, object]]"" desc=""An array describing the current stack of foreach steps."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""FlowSpec.merge_artifacts"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/flowspec.py#L360"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""inputs"" type=""Inputs"" /><SigArg name=""exclude"" type=""Optional"" default=""None"" /><SigArg name=""include"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""Helper function for merging artifacts in a join step."" extended_summary=""This function takes all the artifacts coming from the branches of a\njoin point and assigns them to self in the calling step. Only artifacts\nnot set in the current step are considered. If, for a given artifact, different\nvalues are present on the incoming edges, an error will be thrown and the artifacts\nthat conflict will be reported.\n\nAs a few examples, in the simple graph: A splitting into B and C and joining in D:\n```\nA:\n  self.x = 5\n  self.y = 6\nB:\n  self.b_var = 1\n  self.x = from_b\nC:\n  self.x = from_c\n\nD:\n  merge_artifacts(inputs)\n```\nIn D, the following artifacts are set:\n  - `y` (value: 6), `b_var` (value: 1)\n  - if `from_b` and `from_c` are the same, `x` will be accessible and have value `from_b`\n  - if `from_b` and `from_c` are different, an error will be thrown. To prevent this error,\n    you need to manually set `self.x` in D to a merged value (for example the max) prior to\n    calling `merge_artifacts`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""inputs"" type=""Inputs"" desc=""Incoming steps to the join point."" />
 	<Parameter name=""exclude"" type=""List[str], optional"" desc=""If specified, do not consider merging artifacts with a name in `exclude`.\nCannot specify if `include` is also specified."" />
 	<Parameter name=""include"" type=""List[str], optional"" desc=""If specified, only merge artifacts specified. Cannot specify if `exclude` is\nalso specified."" />
 </ParamSection>
 <ParamSection name=""Raises"">
 	<Parameter type=""MetaflowException"" desc=""This exception is thrown if this is not called in a join step."" />
 	<Parameter type=""UnhandledInMergeArtifactsException"" desc=""This exception is thrown in case of unresolved conflicts."" />
 	<Parameter type=""MissingInMergeArtifactsException"" desc=""This exception is thrown in case an artifact specified in `include` cannot\nbe found."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/flowspec#working-with-foreaches,False,5667,724,https://docs.metaflow.org
429,Parameters,"The `Parameter` class is used to define parameters for a flow.
 
 The `Parameter` objects must be defined as class variables inside a flow. The parameter values are available as read-only artifacts in all steps of the flow. For instructions, see [How to define parameters for flows](/metaflow/basics#how-to-define-parameters-for-flows).
 
 
 <DocSection type=""class"" name=""Parameter"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/parameters.py#L217"">
 <SigArgSection>
 <SigArg name=""name"" type=""str"" /><SigArg name=""default"" type=""Union"" default=""None"" /><SigArg name=""type"" type=""Union"" default=""None"" /><SigArg name=""help"" type=""Optional"" default=""None"" /><SigArg name=""required"" type=""bool"" default=""False"" /><SigArg name=""show_default"" type=""bool"" default=""True"" /><SigArg name=""**kwargs: Dict[str, Any]"" type=""Dict"" />
 </SigArgSection>
 <Description summary=""Defines a parameter for a flow."" extended_summary=""Parameters must be instantiated as class variables in flow classes, e.g.\n```\nclass MyFlow(FlowSpec):\n    param = Parameter('myparam')\n```\nin this case, the parameter is specified on the command line as\n```\npython myflow.py run --myparam=5\n```\nand its value is accessible through a read-only artifact like this:\n```\nprint(self.param == 5)\n```\nNote that the user-visible parameter name, `myparam` above, can be\ndifferent from the artifact name, `param` above.\n\nThe parameter value is converted to a Python type based on the `type`\nargument or to match the type of `default`, if it is set."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""name"" type=""str"" desc=""User-visible parameter name."" />
 	<Parameter name=""default"" type=""str or float or int or bool or `JSONType` or a function."" desc=""Default value for the parameter. Use a special `JSONType` class to\nindicate that the value must be a valid JSON object. A function\nimplies that the parameter corresponds to a *deploy-time parameter*.\nThe type of the default value is used as the parameter `type`."" />
 	<Parameter name=""type"" type=""Type, default: None"" desc=""If `default` is not specified, define the parameter type. Specify\none of `str`, `float`, `int`, `bool`, or `JSONType`. If None, defaults\nto the type of `default` or `str` if none specified."" />
 	<Parameter name=""help"" type=""str, optional"" desc=""Help text to show in `run --help`."" />
 	<Parameter name=""required"" type=""bool, default: False"" desc=""Require that the user specified a value for the parameter.\n`required=True` implies that the `default` is not used."" />
 	<Parameter name=""show_default"" type=""bool, default: True"" desc=""If True, show the default value in the help text."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/flowspec#parameters,False,2753,330,https://docs.metaflow.org
430,Deploy-time parameters,"It is possible to define the `default` value programmatically before a run or a deployment is executed through a user-defined function. For more information, see [documentation for Deploy Time Parameters](/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#deploy-time-parameters).
 
 For instance, the following deploy-time parameter, `time`, uses the current time as its default value:
 ```python
 def time_now(context):
     return int(time.time())
 
 class MyFlow(FlowSpec):
     myparam = Parameter(""time"", type=int, default=time_now)
 ```
 Note that if the function returns a non-string value, you must specify the parameter `type` when using deploy-time parameters, as the type of `default` can't be inferred automatically.
 
 The function called gets a parameter `context` that contains attributes about the current parameter which you can use to customize the value returned:
 
 
 <DocSection type=""class"" name=""ParameterContext"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Information about the parameter being evaluated."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""flow_name"" type=""str"" desc=""Flow name"" />
 	<Parameter name=""user_name"" type=""str"" desc=""User name"" />
 	<Parameter name=""parameter_name"" type=""str"" desc=""Parameter name"" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/flowspec#deploy-time-parameters,False,1444,162,https://docs.metaflow.org
431,IncludeFile,"The `IncludeFile` object is a special `Parameter` that reads its value from a local file. For an example, see [Data in Local Files](/scaling/data#data-in-local-files).
 
 
 <DocSection type=""class"" name=""IncludeFile"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/includefile.py#L237"">
 <SigArgSection>
 <SigArg name=""name, **kwargs"" />
 </SigArgSection>
 <Description summary=""Includes a local file as a parameter for the flow."" extended_summary=""`IncludeFile` behaves like `Parameter` except that it reads its value from a file instead of\nthe command line. The user provides a path to a file on the command line. The file contents\nare saved as a read-only artifact which is available in all steps of the flow."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""name"" type=""str"" desc=""User-visible parameter name."" />
 	<Parameter name=""default"" type=""str or a function"" desc=""Default path to a local file. A function\nimplies that the parameter corresponds to a *deploy-time parameter*."" />
 	<Parameter name=""is_text"" type=""bool, default: True"" desc=""Convert the file contents to a string using the provided `encoding`.\nIf False, the artifact is stored in `bytes`."" />
 	<Parameter name=""encoding"" type=""str, optional, default: 'utf-8'"" desc=""Use this encoding to decode the file contexts if `is_text=True`."" />
 	<Parameter name=""required"" type=""bool, default: False"" desc=""Require that the user specified a value for the parameter.\n`required=True` implies that the `default` is not used."" />
 	<Parameter name=""help"" type=""str, optional"" desc=""Help text to show in `run --help`."" />
 	<Parameter name=""show_default"" type=""bool, default: True"" desc=""If True, show the default value in the help text."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/flowspec#includefile,False,1821,222,https://docs.metaflow.org
432,S3 - Accessing data in S3 quickly,"The `S3` client is a wrapper over the standard AWS Python library, `boto`. It contains enhancements that are relevant for data-intensive applications:
 
  - Supports accessing large amounts of data quickly through parallel operations (functions with the `_many` suffix). You can download up to 20Gbps on a large EC2 instance.
  - Improved error handling.
  - Supports versioned data through `S3(run=self)` and `S3(run=Run)`.
  - User-friendly API with minimal boilerplate.
  - Convenient API for advanced featured such as range requests (downloading partial files) and object headers.
  
 For instructions how to use the class, see [Loading and Storing Data](/scaling/data).",H1,https://docs.metaflow.org/api/S3#s3-accessing-data-in-s3-quickly,False,674,103,https://docs.metaflow.org
433,The `S3` client,"<DocSection type=""class"" name=""S3"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L423"">
 <SigArgSection>
 <SigArg name=""tmproot='.', bucket=None, prefix=None, run=None, s3root=None"" />
 </SigArgSection>
 <Description summary=""The Metaflow S3 client."" extended_summary=""This object manages the connection to S3 and a temporary diretory that is used\nto download objects. Note that in most cases when the data fits in memory, no local\ndisk IO is needed as operations are cached by the operating system, which makes\noperations fast as long as there is enough memory available.\n\nThe easiest way is to use this object as a context manager:\n```\nwith S3() as s3:\n    data = [obj.blob for obj in s3.get_many(urls)]\nprint(data)\n```\nThe context manager takes care of creating and deleting a temporary directory\nautomatically. Without a context manager, you must call `.close()` to delete\nthe directory explicitly:\n```\ns3 = S3()\ndata = [obj.blob for obj in s3.get_many(urls)]\ns3.close()\n```\nYou can customize the location of the temporary directory with `tmproot`. It\ndefaults to the current working directory.\n\nTo make it easier to deal with object locations, the client can be initialized\nwith an S3 path prefix. There are three ways to handle locations:\n\n1. Use a `metaflow.Run` object or `self`, e.g. `S3(run=self)` which\n   initializes the prefix with the global `DATATOOLS_S3ROOT` path, combined\n   with the current run ID. This mode makes it easy to version data based\n   on the run ID consistently. You can use the `bucket` and `prefix` to\n   override parts of `DATATOOLS_S3ROOT`.\n\n2. Specify an S3 prefix explicitly with `s3root`,\n   e.g. `S3(s3root='s3://mybucket/some/path')`.\n\n3. Specify nothing, i.e. `S3()`, in which case all operations require\n   a full S3 url prefixed with `s3://`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tmproot"" type=""str, default: '.'"" desc=""Where to store the temporary directory."" />
 	<Parameter name=""bucket"" type=""str, optional"" desc=""Override the bucket from `DATATOOLS_S3ROOT` when `run` is specified."" />
 	<Parameter name=""prefix"" type=""str, optional"" desc=""Override the path from `DATATOOLS_S3ROOT` when `run` is specified."" />
 	<Parameter name=""run"" type=""FlowSpec or Run, optional"" desc=""Derive path prefix from the current or a past run ID, e.g. S3(run=self)."" />
 	<Parameter name=""s3root"" type=""str, optional"" desc=""If `run` is not specified, use this as the S3 prefix."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.close"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L549"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Delete all temporary files downloaded in this context."" />
 
 </DocSection>",H2,https://docs.metaflow.org/api/S3#the-s3-client,False,2957,362,https://docs.metaflow.org
434,Downloading data,"<DocSection type=""method"" name=""S3.get"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L822"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key"" type=""Union"" default=""None"" /><SigArg name=""return_missing"" type=""bool"" default=""False"" /><SigArg name=""return_info"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Get a single object from S3."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key"" type=""str or `S3GetObject`, optional"" desc=""Object to download. It can be an S3 url, a path suffix, or\nan `S3GetObject` that defines a range of data to download. If None, or\nnot provided, gets the S3 root."" />
 	<Parameter name=""return_missing"" type=""bool, default: False"" desc=""If set to True, do not raise an exception for a missing key but\nreturn it as an `S3Object` with `.exists == False`."" />
 	<Parameter name=""return_info"" type=""bool, default: True"" desc=""If set to True, fetch the content-type and user metadata associated\nwith the object at no extra cost, included for symmetry with `get_many`"" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""`S3Object`"" desc=""An S3Object corresponding to the object requested."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.get_many"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L915"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""keys"" type=""Iterable"" /><SigArg name=""return_missing"" type=""bool"" default=""False"" /><SigArg name=""return_info"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Get many objects from S3 in parallel."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""keys"" type=""Iterable[str or `S3GetObject`]"" desc=""Objects to download. Each object can be an S3 url, a path suffix, or\nan `S3GetObject` that defines a range of data to download."" />
 	<Parameter name=""return_missing"" type=""bool, default: False"" desc=""If set to True, do not raise an exception for a missing key but\nreturn it as an `S3Object` with `.exists == False`."" />
 	<Parameter name=""return_info"" type=""bool, default: True"" desc=""If set to True, fetch the content-type and user metadata associated\nwith the object at no extra cost, included for symmetry with `get_many`."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[`S3Object`]"" desc=""S3Objects corresponding to the objects requested."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.get_recursive"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L988"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""keys"" type=""Iterable"" /><SigArg name=""return_info"" type=""bool"" default=""False"" />
 </SigArgSection>
 <Description summary=""Get many objects from S3 recursively in parallel."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""keys"" type=""Iterable[str]"" desc=""Prefixes to download recursively. Each prefix can be an S3 url or a path suffix\nwhich define the root prefix under which all objects are downloaded."" />
 	<Parameter name=""return_info"" type=""bool, default: False"" desc=""If set to True, fetch the content-type and user metadata associated\nwith the object."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[`S3Object`]"" desc=""S3Objects stored under the given prefixes."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.get_all"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L1042"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""return_info"" type=""bool"" default=""False"" />
 </SigArgSection>
 <Description summary=""Get all objects under the prefix set in the `S3` constructor."" extended_summary=""This method requires that the `S3` object is initialized either with `run` or\n`s3root`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""return_info"" type=""bool, default: False"" desc=""If set to True, fetch the content-type and user metadata associated\nwith the object."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""Iterable[`S3Object`]"" desc=""S3Objects stored under the main prefix."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#downloading-data,False,4497,454,https://docs.metaflow.org
435,Listing objects,"<DocSection type=""method"" name=""S3.list_paths"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L614"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""keys"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""List the next level of paths in S3."" extended_summary=""If multiple keys are specified, listings are done in parallel. The returned\nS3Objects have `.exists == False` if the path refers to a prefix, not an\nexisting S3 object.\n\nFor instance, if the directory hierarchy is\n```\na/0.txt\na/b/1.txt\na/c/2.txt\na/d/e/3.txt\nf/4.txt\n```\nThe `list_paths(['a', 'f'])` call returns\n```\na/0.txt (exists == True)\na/b/ (exists == False)\na/c/ (exists == False)\na/d/ (exists == False)\nf/4.txt (exists == True)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""keys"" type=""Iterable[str], optional"" desc=""List of paths."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[`S3Object`]"" desc=""S3Objects under the given paths, including prefixes (directories) that\ndo not correspond to leaf objects."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.list_recursive"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L664"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""keys"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""List all objects recursively under the given prefixes."" extended_summary=""If multiple keys are specified, listings are done in parallel. All objects\nreturned have `.exists == True` as this call always returns leaf objects.\n\nFor instance, if the directory hierarchy is\n```\na/0.txt\na/b/1.txt\na/c/2.txt\na/d/e/3.txt\nf/4.txt\n```\nThe `list_paths(['a', 'f'])` call returns\n```\na/0.txt (exists == True)\na/b/1.txt (exists == True)\na/c/2.txt (exists == True)\na/d/e/3.txt (exists == True)\nf/4.txt (exists == True)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""keys"" type=""Iterable[str], optional"" desc=""List of paths."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[`S3Object`]"" desc=""S3Objects under the given paths."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#listing-objects,False,2350,210,https://docs.metaflow.org
436,Uploading data,"<DocSection type=""method"" name=""S3.put"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L1068"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key"" type=""Union"" /><SigArg name=""obj"" type=""Union"" /><SigArg name=""overwrite"" type=""bool"" default=""True"" /><SigArg name=""content_type"" type=""Optional"" default=""None"" /><SigArg name=""metadata"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""Upload a single object to S3."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key"" type=""str or `S3PutObject`"" desc=""Object path. It can be an S3 url or a path suffix."" />
 	<Parameter name=""obj"" type=""bytes or str"" desc=""An object to store in S3. Strings are converted to UTF-8 encoding."" />
 	<Parameter name=""overwrite"" type=""bool, default: True"" desc=""Overwrite the object if it exists. If set to False, the operation\nsucceeds without uploading anything if the key already exists."" />
 	<Parameter name=""content_type"" type=""str, optional"" desc=""Optional MIME type for the object."" />
 	<Parameter name=""metadata"" type=""Dict, optional"" desc=""A JSON-encodable dictionary of additional headers to be stored\nas metadata with the object."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""URL of the object stored."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.put_many"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L1156"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key_objs"" type=""List"" /><SigArg name=""overwrite"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Upload many objects to S3."" extended_summary=""Each object to be uploaded can be specified in two ways:\n\n1. As a `(key, obj)` tuple where `key` is a string specifying\n   the path and `obj` is a string or a bytes object.\n\n2. As a `S3PutObject` which contains additional metadata to be\n   stored with the object."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key_objs"" type=""List[(str, str) or `S3PutObject`]"" desc=""List of key-object pairs to upload."" />
 	<Parameter name=""overwrite"" type=""bool, default : True"" desc=""Overwrite the object if it exists. If set to False, the operation\nsucceeds without uploading anything if the key already exists."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[(str, str)]"" desc=""List of `(key, url)` pairs corresponding to the objects uploaded."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.put_files"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L1228"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key_paths"" type=""List"" /><SigArg name=""overwrite"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Upload many local files to S3."" extended_summary=""Each file to be uploaded can be specified in two ways:\n\n1. As a `(key, path)` tuple where `key` is a string specifying\n   the S3 path and `path` is the path to a local file.\n\n2. As a `S3PutObject` which contains additional metadata to be\n   stored with the file."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key_paths"" type=""List[(str, str) or `S3PutObject`]"" desc=""List of files to upload."" />
 	<Parameter name=""overwrite"" type=""bool, default: True"" desc=""Overwrite the object if it exists. If set to False, the operation\nsucceeds without uploading anything if the key already exists."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[(str, str)]"" desc=""List of `(key, url)` pairs corresponding to the files uploaded."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#uploading-data,False,3881,424,https://docs.metaflow.org
437,Querying metadata,"<DocSection type=""method"" name=""S3.info"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L710"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key"" type=""Optional"" default=""None"" /><SigArg name=""return_missing"" type=""bool"" default=""False"" />
 </SigArgSection>
 <Description summary=""Get metadata about a single object in S3."" extended_summary=""This call makes a single `HEAD` request to S3 which can be\nmuch faster than downloading all data with `get`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key"" type=""str, optional"" desc=""Object to query. It can be an S3 url or a path suffix."" />
 	<Parameter name=""return_missing"" type=""bool, default: False"" desc=""If set to True, do not raise an exception for a missing key but\nreturn it as an `S3Object` with `.exists == False`."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""`S3Object`"" desc=""An S3Object corresponding to the object requested. The object\nwill have `.downloaded == False`."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""S3.info_many"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L764"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""keys"" type=""Iterable"" /><SigArg name=""return_missing"" type=""bool"" default=""False"" />
 </SigArgSection>
 <Description summary=""Get metadata about many objects in S3 in parallel."" extended_summary=""This call makes a single `HEAD` request to S3 which can be\nmuch faster than downloading all data with `get`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""keys"" type=""Iterable[str]"" desc=""Objects to query. Each key can be an S3 url or a path suffix."" />
 	<Parameter name=""return_missing"" type=""bool, default: False"" desc=""If set to True, do not raise an exception for a missing key but\nreturn it as an `S3Object` with `.exists == False`."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""List[`S3Object`]"" desc=""A list of `S3Object`s corresponding to the paths requested. The\nobjects will have `.downloaded == False`."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#querying-metadata,False,2260,241,https://docs.metaflow.org
438,Handling results with `S3Object`,"Most operations above return `S3Object`s that encapsulate information about S3 paths and objects.
 
 Note that the data itself is not kept in these objects but it is stored in a temporary directory which is accessible through the properties of this object.
 
 
 <DocSection type=""class"" name=""S3Object"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/datatools/s3/s3.py#L126"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""This object represents a path or an object in S3,\nwith an optional local copy."" extended_summary=""`S3Object`s are not instantiated directly, but they are returned\nby many methods of the `S3` client."" />
 
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.exists"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Does this key correspond to an object in S3?\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if this object points at an existing object (file) in S3."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.downloaded"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Has this object been downloaded?\n\nIf True, the contents can be accessed through `path`, `blob`,\nand `text` properties.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if the contents of this object have been downloaded."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.url"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""S3 location of the object\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""The S3 location of this object."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.prefix"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Prefix requested that matches this object.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Requested prefix"" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.key"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Key corresponds to the key given to the get call that produced\nthis object.\n\nThis may be a full S3 URL or a suffix based on what\nwas requested.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Key requested."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.path"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Path to a local temporary file corresponding to the object downloaded.\n\nThis file gets deleted automatically when a S3 scope exits.\nReturns None if this S3Object has not been downloaded.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Local path, if the object has been downloaded."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.blob"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Contents of the object as a byte string or None if the\nobject hasn't been downloaded.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bytes"" desc=""Contents of the object as bytes."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.text"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Contents of the object as a string or None if the\nobject hasn't been downloaded.\n\nThe object is assumed to contain UTF-8 encoded data.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Contents of the object as text."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.size"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Size of the object in bytes.\n\nReturns None if the key does not correspond to an object in S3.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""int"" desc=""Size of the object in bytes, if the object exists."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.has_info"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Returns true if this `S3Object` contains the content-type MIME header or\nuser-defined metadata.\n\nIf False, this means that `content_type`, `metadata`, `range_info` and\n`last_modified` will return None.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if additional metadata is available."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.metadata"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Returns a dictionary of user-defined metadata, or None if no metadata\nis defined.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""Dict"" desc=""User-defined metadata."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.content_type"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Returns the content-type of the S3 object or None if it is not defined.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Content type or None if the content type is undefined."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.range_info"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""If the object corresponds to a partially downloaded object, returns\ninformation of what was downloaded.\n\nThe returned object has the following fields:\n- `total_size`: Size of the object in S3.\n- `request_offset`: The starting offset.\n- `request_length`: The number of bytes downloaded.\n"" />
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""S3Object.last_modified"" module=""metaflow.plugins.datatools.s3.s3"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 
 <Description summary=""Returns the last modified unix timestamp of the object.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""int"" desc=""Unix timestamp corresponding to the last modified time."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#handling-results-with-s3object,False,7327,691,https://docs.metaflow.org
439,Helper Objects,"These objects are simple containers that are used to pass information to `get_many`, `put_many`, and `put_files`. You may use your own objects instead of them, as long as they provide the same set of attributes.
 
 
 <DocSection type=""class"" name=""S3GetObject"" module=""metaflow.datatools.s3"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name=""key"" default=""None"" /><SigArg name=""offset"" default=""None"" /><SigArg name=""length"" default=""None"" />
 </SigArgSection>
 <Description summary=""Represents a chunk of an S3 object. A range query is performed to download only a subset of data,\n`object[key][offset:offset + length]`, from S3."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""key"" type=""str"" desc=""Key identifying the object. Works the same way as any `key` passed to `get` or `get_many`."" />
 	<Parameter name=""offset"" type=""int"" desc=""A byte offset in the file."" />
 	<Parameter name=""length"" type=""int"" desc=""The number of bytes to download."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""class"" name=""S3PutObject"" module=""metaflow.datatools.s3"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name=""key"" default=""None"" /><SigArg name=""value"" default=""None"" /><SigArg name=""path"" default=""None"" /><SigArg name=""content_type"" default=""None"" /><SigArg name=""metadata"" default=""None"" />
 </SigArgSection>
 <Description summary=""Defines an object with metadata to be uplaoded with `put_many` or `put_files`."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""key"" type=""str"" desc=""Key identifying the object. Works the same way as `key` passed to `put` or `put_many`."" />
 	<Parameter name=""value"" type=""str or bytes"" desc=""Object to upload. Works the same way as `obj` passed `to `put` or `put_many`."" />
 	<Parameter name=""path"" type=""str"" desc=""Path to a local file. Works the same way as `path` passed to `put_files`."" />
 	<Parameter name=""content_type"" type=""str"" desc=""Optional MIME type for the file."" />
 	<Parameter name=""metadata"" type=""Dict"" desc=""A JSON-encodable dictionary of additional headers to be stored\nas metadata with the file."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/S3#helper-objects,False,2265,255,https://docs.metaflow.org
440,ArgoEvent - Create events to trigger flows,"This class is mainly used **outside** Metaflow flows to create events that trigger Metaflow flows. For instance,
 you can use this class inside a non-Metaflow ETL pipeline or a microservice to trigger a Metaflow execution.
 
 Note that this class assumes that you have an appropriate Metaflow configuration available. Make sure to copy the config file in any environment where this class is being used.
 
 Read more in [Triggering Flows Based on External Events](/production/event-triggering/external-events).
 
 
 
 <DocSection type=""class"" name=""ArgoEvent"" module=""metaflow.integrations"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_events.py#L17"">
 <SigArgSection>
 <SigArg name=""name, url=None, payload={}"" />
 </SigArgSection>
 <Description summary=""ArgoEvent is a small event, a message, that can be published to Argo Workflows. The\nevent will eventually start all flows which have been previously deployed with `@trigger`\nto wait for this particular named event."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""name"" type=""str,"" desc=""Name of the event"" />
 	<Parameter name=""url"" type=""str, optional"" desc=""Override the event endpoint from `ARGO_EVENTS_WEBHOOK_URL`."" />
 	<Parameter name=""payload"" type=""Dict, optional"" desc=""A set of key-value pairs delivered in this event. Used to set parameters of triggered flows."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""ArgoEvent.add_to_payload"" module=""metaflow.integrations"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_events.py#L42"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""key"" /><SigArg name=""value"" />
 </SigArgSection>
 <Description summary=""Add a key-value pair in the payload. This is typically used to set parameters\nof triggered flows. Often, `key` is the parameter name you want to set to\n`value`. Overrides any existing value of `key`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key"" type=""str"" desc=""Key"" />
 	<Parameter name=""value"" type=""str"" desc=""Value"" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""ArgoEvent.publish"" module=""metaflow.integrations"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_events.py#L78"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""payload"" default=""None"" /><SigArg name=""force"" default=""True"" /><SigArg name=""ignore_errors"" default=""True"" />
 </SigArgSection>
 <Description summary=""Publishes an event."" extended_summary=""Note that the function returns immediately after the event has been sent. It\ndoes not wait for flows to start, nor it guarantees that any flows will start."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""payload"" type=""dict"" desc=""Additional key-value pairs to add to the payload."" />
 	<Parameter name=""ignore_errors"" type=""bool, default: True"" desc=""If True, events are created on a best effort basis - errors are silently ignored."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""ArgoEvent.safe_publish"" module=""metaflow.integrations"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_events.py#L59"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""payload"" default=""None"" /><SigArg name=""ignore_errors"" default=""True"" />
 </SigArgSection>
 <Description summary=""Publishes an event when called inside a deployed workflow. Outside a deployed workflow\nthis function does nothing."" extended_summary=""Use this function inside flows to create events safely. As this function is a no-op\nfor local runs, you can safely call it during local development without causing unintended\nside-effects. It takes effect only when deployed on Argo Workflows."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""payload"" type=""dict"" desc=""Additional key-value pairs to add to the payload."" />
 	<Parameter name=""ignore_errors"" type=""bool, default: True"" desc=""If True, events are created on a best effort basis - errors are silently ignored."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/argoevent#argoevent-create-events-to-trigger-flows,False,4227,445,https://docs.metaflow.org
441,Current - Operating a run,"The `current` object is used to inspect and manipulate the currently executing run. It is only available during flow execution, i.e. inside a `FlowSpec` class and functions called from its steps. You can access the object simply by importing it: `from metaflow import current`.
 
 The attributes available in `current` depend on the decorators assigned to the flow and the step where `current` is used. Attributes that are always available are listed under *Common Attributes* below. Decorator-specific attributes are listed under the decorator name.",H1,https://docs.metaflow.org/api/current#current-operating-a-run,False,550,84,https://docs.metaflow.org
442,Common Attributes,"These attributes are always available in the `current` object.
 
 
 <DocSection type=""property"" name=""current.is_running_flow"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""Returns True if called inside a running Flow, False otherwise.\n\nYou can use this property e.g. inside a library to choose the desired\nbehavior depending on the execution context.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if called inside a run, False otherwise."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.flow_name"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The name of the currently executing flow.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Flow name."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.run_id"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The run ID of the currently executing run.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Run ID."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.step_name"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The name of the currently executing step.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Step name."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.task_id"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The task ID of the currently executing task.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Task ID."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.retry_count"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The index of the task execution attempt.\n\nThis property returns 0 for the first attempt to execute the task.\nIf the @retry decorator is used and the first attempt fails, this\nproperty returns the number of times the task was attempted prior\nto the current attempt.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""int"" desc=""The retry count."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.origin_run_id"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The run ID of the original run this run was resumed from.\n\nThis property returns None for ordinary runs. If the run\nwas started by the resume command, the property returns\nthe ID of the original run.\n\nYou can use this property to detect if the run is resumed\nor not.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Run ID of the original run."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.pathspec"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""Pathspec of the current task, i.e. a unique\nidentifier of the current task. The returned\nstring follows this format:\n```\n{flow_name}/{run_id}/{step_name}/{task_id}\n```\n\nThis is a shorthand to `current.task.pathspec`.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Pathspec."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.namespace"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The current namespace.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Namespace."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.username"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The name of the user who started the run, if available.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""User name."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.tempdir"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""Currently configured temporary directory.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str, optional"" desc=""Temporary director."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/current#common-attributes,False,4253,441,https://docs.metaflow.org
444,@project,"[The @project decorator](/production/coordinating-larger-metaflow-projects) exposes attributes related to the current deployment.
 
 
 <DocSection type=""property"" name=""current.project_name"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The name of the project assigned to this flow,\ni.e. `X` in `@project(name=X)`.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Project name."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.project_flow_name"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The flow name prefixed with the current project\nand branch. This name identifies the deployment\non a production scheduler.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Flow name prefixed with project information."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.branch_name"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""The current branch, i.e. `X` in\n`--branch=X` set during deployment.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""str"" desc=""Branch name."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.is_user_branch"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""True if the flow is deployed without a\nspecific `--branch` or a `--production` flag.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if the deployment does not correspond to a specific branch."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""current.is_production"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""True if the flow is deployed with the `--production`\nflag.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""bool"" desc=""True if the flow is deployed in `--production`."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/current#project,False,1976,193,https://docs.metaflow.org
445,@card,"[The @card decorator](/metaflow/visualizing-results) exposes functions in `current` that allow you to customize
 the contents of cards using [card components](/api/cards#Card-components). For an overview of card-related APIs, see [the API reference for cards](/api/cards).
 
 
 <DocSection type=""method"" name=""current.card.__getitem__"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/__main__.py#L28"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Choose a specific card for manipulation."" extended_summary=""When multiple @card decorators are present, you can add an\n`ID` to distinguish between them, `@card(id=ID)`. This allows you\nto add components to a specific card like this:\n```\ncurrent.card[ID].append(component)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key"" type=""str"" desc=""Card ID."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""CardComponentCollector"" desc=""An object with `append` and `extend` calls which allow you to\nadd components to the chosen card."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""current.card.__setitem__"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/__main__.py#L30"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Specify components of the chosen card."" extended_summary=""Instead of adding components to a card individually with `current.card[ID].append(component)`,\nuse this method to assign a list of components to a card, replacing the existing components:\n```\ncurrent.card[ID] = [FirstComponent, SecondComponent]\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""key: str"" desc=""Card ID."" />
 	<Parameter name=""value: List[CardComponent]"" desc=""List of card components to assign to this card."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""current.card.append"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/__main__.py#L32"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Appends a component to the current card."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""component"" type=""CardComponent"" desc=""Card component to add to this card."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""current.card.extend"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/__main__.py#L34"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Appends many components to the current card."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""component"" type=""Iterator[CardComponent]"" desc=""Card components to add to this card."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/current#card,False,2929,263,https://docs.metaflow.org
446,@trigger and @trigger_on_finish,"You can inspect event(s) that triggered [an event-triggered](/production/event-triggering) run through `current.trigger` which returns a [`MetaflowTrigger`](/api/client#metaflowtrigger) object, if the run was
 triggered by an event.
 
 
 <DocSection type=""property"" name=""current.trigger"" module=""__main__"" show_import=""False"" heading_level=""4"">
 
 <Description summary=""Returns `MetaflowTrigger` if the current run is triggered by an event.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""MetaflowTrigger"" desc=""`MetaflowTrigger` if triggered by a run."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/current#trigger-and-trigger-on-finish,False,596,59,https://docs.metaflow.org
447,Cards - Visualizing results,"Metaflow Cards allows you to produce [human readable reports in workflows](/metaflow/visualizing-results). Use the following APIs to enable, customize, and access cards:
 
  - **Enable cards** by adding [the `@card` decorator](/api/step-decorators/card) in any step.
  - **Specify card contents** with [card components](#card-components).
  - **Populate card components** with [the `current` object](/api/current#card).
  - **Retrive cards** with [the `get_cards` method](#retrieving-cards) or on the command line with the `card` commands.
  - **Create fully custom, shareable cards** with custom [`MetaflowCard` classes](#defining-a-custom-card).",H1,https://docs.metaflow.org/api/cards#cards-visualizing-results,False,647,79,https://docs.metaflow.org
448,Retrieving cards,"To retrieve a card after a run has finished, use the `get_cards` function e.g. in a notebook or the `card get` command on the CLI.
 
 Since a task can contain multiple cards `get_cards` returns a container object, `CardContainer`, which holds `Card` objects corresponding to individual cards. Notably both `CardContainer` and `Card` objects contain a function that allow them to visualize cards in the notebook output cell automatically, so a single `get_cards` call can be used to show all cards of a step in a notebook.
 
 
 <DocSection type=""function"" name=""get_cards"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_client.py#L207"">
 <SigArgSection>
 <SigArg name=""task"" type=""Union"" /><SigArg name=""id"" type=""Optional"" default=""None"" /><SigArg name=""type"" type=""Optional"" default=""None"" /><SigArg name=""follow_resumed"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Get cards related to a `Task`."" extended_summary=""Note that `get_cards` resolves the cards contained by the task, but it doesn't actually\nretrieve them from the datastore. Actual card contents are retrieved lazily either when\nthe card is rendered in a notebook to when you call `Card.get`. This means that\n`get_cards` is a fast call even when individual cards contain a lot of data."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""task"" type=""str or `Task`"" desc=""A `Task` object or pathspec `{flow_name}/{run_id}/{step_name}/{task_id}` that\nuniquely identifies a task."" />
 	<Parameter name=""id"" type=""str, optional"" desc=""The ID of card to retrieve if multiple cards are present."" />
 	<Parameter name=""type"" type=""str, optional"" desc=""The type of card to retrieve if multiple cards are present."" />
 	<Parameter name=""follow_resumed"" type=""bool, default: True"" desc=""If the task has been resumed, then setting this flag will resolve the card for\nthe origin task."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""CardContainer"" desc=""A list-like object that holds `Card` objects."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""class"" name=""CardContainer"" module=""metaflow.cards"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_client.py#L128"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""`CardContainer` is an immutable list-like object, returned by `get_cards`,\nwhich contains individual `Card`s."" extended_summary=""Notably, `CardContainer` contains a special\n`_repr_html_` function which renders cards automatically in an output\ncell of a notebook.\n\nThe following operations are supported:\n```\ncards = get_cards(MyTask)\n\n# retrieve by index\nfirst_card = cards[0]\n\n# check length\nif len(cards) > 1:\n    print('many cards present!')\n\n# iteration\nlist_of_cards = list(cards)\n```"" />
 
 </DocSection>
 
 
 
 <DocSection type=""class"" name=""Card"" module=""metaflow.cards"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_client.py#L22"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""`Card` represents an individual Metaflow Card, a single HTML file, produced by\nthe card `@card` decorator. `Card`s are contained by `CardContainer`, returned by\n`get_cards`."" extended_summary=""Note that the contents of the card, an HTML file, is retrieved lazily when you call\n`Card.get` for the first time or when the card is rendered in a notebook."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""id"" desc=""The ID of the card, if specified with `@card(id=ID)`."" />
 	<Parameter name=""path"" desc=""The path of the card in the datastore which uniquely\nidentifies the card.\n\nReturns\n-------\nstr\n    Path to the card"" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Card.get"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_client.py#L60"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Retrieves the HTML contents of the card from the\nMetaflow datastore."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""HTML contents of the card."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Card.view"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_client.py#L98"">
 <SigArgSection>
 <SigArg name=""self"" />
 </SigArgSection>
 <Description summary=""Opens the card in a local web browser."" extended_summary=""This call uses Python's built-in [`webbrowser`](https://docs.python.org/3/library/webbrowser.html)\nmodule to open the card."" />
 
 </DocSection>",H2,https://docs.metaflow.org/api/cards#retrieving-cards,False,4899,516,https://docs.metaflow.org
449,Card components,"You can customize the contents of a card easily using *card components*, a set of visual elements included in Metaflow which are documented below. See [Easy Custom Reports with Card Components](/metaflow/visualizing-results/easy-custom-reports-with-card-components) for instructions.
 
 The components are added to cards in `@step` methods (or functions called from steps), using [the `current.card` object](/api/current#card).",H2,https://docs.metaflow.org/api/cards#card-components,False,427,52,https://docs.metaflow.org
450,Markdown,"<DocSection type=""class"" name=""Markdown"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L420"">
 <SigArgSection>
 <SigArg name=""text"" default=""None"" />
 </SigArgSection>
 <Description summary=""A block of text formatted in Markdown."" extended_summary=""Example:\n```\ncurrent.card.append(\n    Markdown(&#34;# This is a header appended from `@step` code&#34;)\n)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""text"" type=""str"" desc=""Text formatted in Markdown."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/cards#markdown,False,626,47,https://docs.metaflow.org
451,Image,"<DocSection type=""class"" name=""Image"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L165"">
 <SigArgSection>
 <SigArg name=""src"" default=""None"" /><SigArg name=""label"" default=""None"" />
 </SigArgSection>
 <Description summary=""An image."" extended_summary=""`Images can be created directly from PNG/JPG/GIF `bytes`, `PIL.Image`s,\nor Matplotlib figures. Note that the image data is embedded in the card,\nso no external files are required to show the image.\n\nExample: Create an `Image` from bytes:\n```\ncurrent.card.append(\n    Image(\n        requests.get(&#34;https://www.gif-vif.com/hacker-cat.gif&#34;).content,\n        &#34;Image From Bytes&#34;\n    )\n)\n```\n\nExample: Create an `Image` from a Matplotlib figure\n```\nimport pandas as pd\nimport numpy as np\ncurrent.card.append(\n    Image.from_matplotlib(\n        pandas.DataFrame(\n            np.random.randint(0, 100, size=(15, 4)),\n            columns=list(&#34;ABCD&#34;),\n        ).plot()\n    )\n)\n```\n\nExample: Create an `Image` from a [PIL](https://pillow.readthedocs.io/) Image\n```\nfrom PIL import Image as PILImage\ncurrent.card.append(\n    Image.from_pil_image(\n        PILImage.fromarray(np.random.randn(1024, 768), &#34;RGB&#34;),\n        &#34;From PIL Image&#34;\n    )\n)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""src"" type=""bytes"" desc=""The image data in `bytes`."" />
 	<Parameter name=""label"" type=""str"" desc=""Optional label for the image."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Image.from_matplotlib"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L314"">
 <SigArgSection>
 <SigArg name=""plot"" /><SigArg name=""label"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""Create an `Image` from a Matplotlib plot."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""plot"" type=""matplotlib.figure.Figure or matplotlib.axes.Axes or matplotlib.axes._subplots.AxesSubplot"" desc=""a PIL axes (plot) object."" />
 	<Parameter name=""label"" type=""str, optional"" desc=""Optional label for the image."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Image.from_pil_image"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L266"">
 <SigArgSection>
 <SigArg name=""pilimage"" /><SigArg name=""label"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""Create an `Image` from a PIL image."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""pilimage"" type=""PIL.Image"" desc=""a PIL image object."" />
 	<Parameter name=""label"" type=""str, optional"" desc=""Optional label for the image."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/cards#image,False,2976,312,https://docs.metaflow.org
452,Artifact,"<DocSection type=""class"" name=""Artifact"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L20"">
 <SigArgSection>
 <SigArg name=""artifact"" type=""Any"" /><SigArg name=""name"" type=""Optional"" default=""None"" /><SigArg name=""compressed"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""A pretty-printed version of any Python object."" extended_summary=""Large objects are truncated using Python's built-in [`reprlib`](https://docs.python.org/3/library/reprlib.html).\n\nExample:\n```\nfrom datetime import datetime\ncurrent.card.append(Artifact({'now': datetime.utcnow()}))\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""artifact"" type=""object"" desc=""Any Python object."" />
 	<Parameter name=""name"" type=""str, optional"" desc=""Optional label for the object."" />
 	<Parameter name=""compressed"" type=""bool, default: True"" desc=""Use a truncated representation."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/cards#artifact,False,1036,73,https://docs.metaflow.org
453,Table,"<DocSection type=""class"" name=""Table"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L58"">
 <SigArgSection>
 <SigArg name=""data"" type=""Optional"" default=""None"" /><SigArg name=""headers"" type=""Optional"" default=""None"" />
 </SigArgSection>
 <Description summary=""A table."" extended_summary=""The contents of the table can be text or numerical data, a Pandas dataframe,\nor other card components: `Artifact`, `Image`, `Markdown` objects.\n\nExample: Text and artifacts\n```\nfrom metaflow.cards import Table, Artifact\ncurrent.card.append(\n    Table([\n        ['first row', Artifact({'a': 2})],\n        ['second row', Artifact(3)]\n    ])\n)\n```\n\nExample: Table from a Pandas dataframe\n```\nfrom metaflow.cards import Table\nimport pandas as pd\nimport numpy as np\ncurrent.card.append(\n    Table.from_dataframe(\n        pd.DataFrame(\n            np.random.randint(0, 100, size=(15, 4)),\n            columns=list(&#34;ABCD&#34;)\n        )\n    )\n)\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""data"" type=""List[List[str or MetaflowCardComponent]], optional"" desc=""List (rows) of lists (columns). Each item can be a string or a `MetaflowCardComponent`."" />
 	<Parameter name=""headers"" type=""List[str], optional"" desc=""Optional header row for the table."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Table.from_dataframe"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/components.py#L114"">
 <SigArgSection>
 <SigArg name=""dataframe"" default=""None"" /><SigArg name=""truncate"" type=""bool"" default=""True"" />
 </SigArgSection>
 <Description summary=""Create a `Table` based on a Pandas dataframe."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""dataframe"" type=""Optional[pandas.DataFrame]"" desc=""Pandas dataframe."" />
 	<Parameter name=""truncate"" type=""bool, default: True"" desc=""Truncate large dataframe instead of showing all rows (default: True)."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/cards#table,False,2162,236,https://docs.metaflow.org
454,Defining a custom card,"You can define custom cards types (`T` in `@card(type=T)`) by creating a Python package that includes a class that derives from `MetaflowCard`, documented below.
 
 Find detailed instructions, a starter template, and an example of a simple custom card at [https://github.com/outerbounds/metaflow-card-html]( https://github.com/outerbounds/metaflow-card-html).
 
 
 <DocSection type=""class"" name=""MetaflowCard"" module=""metaflow.cards"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/card.py#L7"">
 <SigArgSection>
 <SigArg name=""options"" />
 </SigArgSection>
 <Description summary=""Metaflow cards derive from this base class."" extended_summary=""Subclasses of this class are called *card types*. The desired card\ntype `T` is defined in the `@card` decorator as `@card(type=T)`.\n\nAfter a task with `@card(type=T, options=S)` finishes executing, Metaflow instantiates\na subclass `C` of `MetaflowCard` that has its `type` attribute set to `T`, i.e. `C.type=T`.\nThe constructor is given the options dictionary `S` that contains arbitrary\nJSON-encodable data that is passed to the instance, parametrizing the card. The subclass\nmay override the constructor to capture and process the options.\n\nThe subclass needs to implement a `render(task)` method that produces the card\ncontents in HTML, given the finished task that is represented by a `Task` object."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""options"" type=""Dict"" desc=""JSON-encodable dictionary containing user-definable options for the class."" />
 </ParamSection>
 <ParamSection name=""Attributes"">
 	<Parameter name=""type"" type=""str"" desc=""Card type string. Note that this should be a globally unique name, similar to a\nPython package name, to avoid name clashes between different custom cards."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""MetaflowCard.render"" module=""metaflow.cards"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_modules/card.py#L52"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""task"" />
 </SigArgSection>
 <Description summary=""Produce custom card contents in HTML."" extended_summary=""Subclasses override this method to customize the card contents."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""task"" type=""Task"" desc=""A `Task` object that allows you to access data from the finished task and tasks\npreceding it."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""Card contents as an HTML string."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/cards#defining-a-custom-card,False,2661,281,https://docs.metaflow.org
455,Client API - Accessing past results,"Use these objects to [access data from past runs and to manipulate tags](/metaflow/client). Objects in this module are organized as a hierarchy:
 
 ![Object hierarchy](/assets/hierarchy.png)",H1,https://docs.metaflow.org/api/client#client-api-accessing-past-results,False,190,25,https://docs.metaflow.org
456,Instantiating Objects,"You can instantiate a specific object at any level of the hierarchy by providing a corresponding `pathspec`, e.g. from Metaflow logs.
 
  - `Metaflow()`
  - `Flow('HelloFlow')`
  - `Run('HelloFlow/2')`
  - `Step('HelloFlow/2/start')`
  - `Task('HelloFlow/2/start/1')`
  - `DataArtifact('HelloFlow/2/start/1/name')`",H3,https://docs.metaflow.org/api/client#instantiating-objects,False,314,40,https://docs.metaflow.org
457,Listing objects,"Each object is a container (*an iterable*) that can be used to iterate over objects that are below it in the hierarchy. For instance, iterating over a `list(Flow(...))` yields a list of `Run`s, and `list(Run(...))` yields a list of `Step`s.",H3,https://docs.metaflow.org/api/client#listing-objects,False,240,40,https://docs.metaflow.org
458,Accessing children,"Since each object is a container, you can access its children through the square-bracket notation, as if each object was a dictionary. For instance, you can access the object `Task('HelloFlow/2/start/1')` as follows:
 ```python
 Flow('HelloFlow')['2']['start']['1']
 ```
 You can also test if the object has a certain child:
 ```python
 if '2' in Flow('HelloFlow'):
     print('Run found')
 ```",H3,https://docs.metaflow.org/api/client#accessing-children,False,394,58,https://docs.metaflow.org
459,Common attributes,"All objects at the `Run` level and below have the following attributes:
 
  - `tags` (set) - tags associated with the run this object belongs to (user and system tags).
  - `user_tags` (set) - user tags associated with the run this object belongs to.
  - `system_tags` (set) - system tags associated with the run this object belongs to.
  - `created_at` (datetime) - Date and time this object was created.
  - `parent` (Metaflow object) - Parent of this object (e.g. `Run(...).parent` is a `Flow`).
  - `pathspec` (string) - Pathspec of this object (e.g. `HelloFlow/2` for a `Run`).
  - `path_components` (list) - Components of the pathspec.
  - `origin_pathspec` (string) - If the object was produced via [resume](/metaflow/debugging#how-to-use-the-resume-command), pathspec of the original object this object was cloned from.",H3,https://docs.metaflow.org/api/client#common-attributes,False,827,133,https://docs.metaflow.org
460,Object visibility,"Note that only objects in [the current namespace](/scaling/tagging) can be instantiated. See [Namespace functions](#namespace) to see how to switch between namespaces. 
 
 This module accesses all objects through the current metadata provider - either Metaflow Service or local metadata. See [Metadata functions](#metadata) for utilities related to metadata provider.",H3,https://docs.metaflow.org/api/client#object-visibility,False,367,49,https://docs.metaflow.org
462,Metaflow,"<DocSection type=""class"" name=""Metaflow"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L2081"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Entry point to all objects in the Metaflow universe."" extended_summary=""This object can be used to list all the flows present either through the explicit property\nor by iterating over this object."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""flows"" type=""List[Flow]"" desc=""Returns the list of all `Flow` objects known to this metadata provider. Note that only\nflows present in the current namespace will be returned. A `Flow` is present in a namespace\nif it has at least one run in the namespace."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#metaflow,False,790,89,https://docs.metaflow.org
463,Flow,"<DocSection type=""class"" name=""Flow"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L2004"">
 <SigArgSection>
 <SigArg name=""pathspec"" />
 </SigArgSection>
 <Description summary=""A Flow represents all existing flows with a certain name, in other words,\nclasses derived from `FlowSpec`. A container of `Run` objects."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""latest_run"" type=""Run"" desc=""Latest `Run` (in progress or completed, successfully or not) of this flow."" />
 	<Parameter name=""latest_successful_run"" type=""Run"" desc=""Latest successfully completed `Run` of this flow."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Flow.runs"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L2054"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""*tags: str"" type=""str"" />
 </SigArgSection>
 <Description summary=""Returns an iterator over all `Run`s of this flow."" extended_summary=""An optional filter is available that allows you to filter on tags.\nIf multiple tags are specified, only runs that have all the\nspecified tags are returned."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tags"" type=""str"" desc=""Tags to match."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""Iterable[Run]"" desc=""Iterator over `Run` objects in this flow."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#flow,False,1517,145,https://docs.metaflow.org
464,Run,"<DocSection type=""class"" name=""Run"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1696"">
 <SigArgSection>
 <SigArg name=""pathspec"" />
 </SigArgSection>
 <Description summary=""A `Run` represents an execution of a `Flow`. It is a container of `Step`s."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""data"" type=""MetaflowData"" desc=""a shortcut to run['end'].task.data, i.e. data produced by this run."" />
 	<Parameter name=""successful"" type=""bool"" desc=""True if the run completed successfully."" />
 	<Parameter name=""finished"" type=""bool"" desc=""True if the run completed."" />
 	<Parameter name=""finished_at"" type=""datetime"" desc=""Time this run finished."" />
 	<Parameter name=""code"" type=""MetaflowCode"" desc=""Code package for this run (if present). See `MetaflowCode`."" />
 	<Parameter name=""trigger"" type=""MetaflowTrigger"" desc=""Information about event(s) that triggered this run (if present). See `MetaflowTrigger`."" />
 	<Parameter name=""end_task"" type=""Task"" desc=""`Task` for the end step (if it is present already)."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.add_tag"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1863"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tag"" type=""str"" />
 </SigArgSection>
 <Description summary=""Add a tag to this `Run`."" extended_summary=""Note that if the tag is already a system tag, it is not added as a user tag,\nand no error is thrown."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tag"" type=""str"" desc=""Tag to add."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.add_tags"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1885"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tags"" type=""Iterable"" />
 </SigArgSection>
 <Description summary=""Add one or more tags to this `Run`."" extended_summary=""Note that if any tag is already a system tag, it is not added as a user tag\nand no error is thrown."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tags"" type=""Iterable[str]"" desc=""Tags to add."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.remove_tag"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1899"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tag"" type=""str"" />
 </SigArgSection>
 <Description summary=""Remove one tag from this `Run`."" extended_summary=""Removing a system tag is an error. Removing a non-existent\nuser tag is a no-op."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tag"" type=""str"" desc=""Tag to remove."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.remove_tags"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1921"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tags"" type=""Iterable"" />
 </SigArgSection>
 <Description summary=""Remove one or more tags to this `Run`."" extended_summary=""Removing a system tag will result in an error. Removing a non-existent\nuser tag is a no-op."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tags"" type=""Iterable[str]"" desc=""Tags to remove."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.replace_tag"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1935"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tag_to_remove"" type=""str"" /><SigArg name=""tag_to_add"" type=""str"" />
 </SigArgSection>
 <Description summary=""Remove a tag and add a tag atomically. Removal is done first.\nThe rules for `Run.add_tag` and `Run.remove_tag` also apply here."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tag_to_remove"" type=""str"" desc=""Tag to remove."" />
 	<Parameter name=""tag_to_add"" type=""str"" desc=""Tag to add."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Run.replace_tags"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1959"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""tags_to_remove"" type=""Iterable"" /><SigArg name=""tags_to_add"" type=""Iterable"" />
 </SigArgSection>
 <Description summary=""Remove and add tags atomically; the removal is done first.\nThe rules for `Run.add_tag` and `Run.remove_tag` also apply here."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""tags_to_remove"" type=""Iterable[str]"" desc=""Tags to remove."" />
 	<Parameter name=""tags_to_add"" type=""Iterable[str]"" desc=""Tags to add."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#run,False,4948,461,https://docs.metaflow.org
465,Step,"<DocSection type=""class"" name=""Step"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1535"">
 <SigArgSection>
 <SigArg name=""pathspec"" />
 </SigArgSection>
 <Description summary=""A `Step` represents a user-defined step, that is, a method annotated with the `@step` decorator."" extended_summary=""It contains `Task` objects associated with the step, that is, all executions of the\n`Step`. The step may contain multiple `Task`s in the case of a foreach step."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""task"" type=""Task"" desc=""The first `Task` object in this step. This is a shortcut for retrieving the only\ntask contained in a non-foreach step."" />
 	<Parameter name=""finished_at"" type=""datetime"" desc=""Time when the latest `Task` of this step finished. Note that in the case of foreaches,\nthis time may change during execution of the step."" />
 	<Parameter name=""environment_info"" type=""Dict[str, Any]"" desc=""Information about the execution environment."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#step,False,1090,122,https://docs.metaflow.org
466,Task,"<DocSection type=""class"" name=""Task"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L984"">
 <SigArgSection>
 <SigArg name=""pathspec, attempt=None"" />
 </SigArgSection>
 <Description summary=""A `Task` represents an execution of a `Step`."" extended_summary=""It contains all `DataArtifact` objects produced by the task as\nwell as metadata related to execution.\n\nNote that the `@retry` decorator may cause multiple attempts of\nthe task to be present. Usually you want the latest attempt, which\nis what instantiating a `Task` object returns by default. If\nyou need to e.g. retrieve logs from a failed attempt, you can\nexplicitly get information about a specific attempt by using the\nfollowing syntax when creating a task:\n\n`Task('flow/run/step/task', attempt=<attempt>)`\n\nwhere `attempt=0` corresponds to the first attempt etc."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""metadata"" type=""List[Metadata]"" desc=""List of all metadata events associated with the task."" />
 	<Parameter name=""metadata_dict"" type=""Dict[str, str]"" desc=""A condensed version of `metadata`: A dictionary where keys\nare names of metadata events and values the latest corresponding event."" />
 	<Parameter name=""data"" type=""MetaflowData"" desc=""Container of all data artifacts produced by this task. Note that this\ncall downloads all data locally, so it can be slower than accessing\nartifacts individually. See `MetaflowData` for more information."" />
 	<Parameter name=""artifacts"" type=""MetaflowArtifacts"" desc=""Container of `DataArtifact` objects produced by this task."" />
 	<Parameter name=""successful"" type=""bool"" desc=""True if the task completed successfully."" />
 	<Parameter name=""finished"" type=""bool"" desc=""True if the task completed."" />
 	<Parameter name=""exception"" type=""object"" desc=""Exception raised by this task if there was one."" />
 	<Parameter name=""finished_at"" type=""datetime"" desc=""Time this task finished."" />
 	<Parameter name=""runtime_name"" type=""str"" desc=""Runtime this task was executed on."" />
 	<Parameter name=""stdout"" type=""str"" desc=""Standard output for the task execution."" />
 	<Parameter name=""stderr"" type=""str"" desc=""Standard error output for the task execution."" />
 	<Parameter name=""code"" type=""MetaflowCode"" desc=""Code package for this task (if present). See `MetaflowCode`."" />
 	<Parameter name=""environment_info"" type=""Dict[str, str]"" desc=""Information about the execution environment."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Task.loglines"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L1440"">
 <SigArgSection>
 <SigArg name=""self"" /><SigArg name=""stream"" type=""str"" /><SigArg name=""as_unicode"" type=""bool"" default=""True"" /><SigArg name=""meta_dict"" type=""Dict"" default=""None"" />
 </SigArgSection>
 <Description summary=""Return an iterator over (utc_timestamp, logline) tuples."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""stream"" type=""str"" desc=""Either 'stdout' or 'stderr'."" />
 	<Parameter name=""as_unicode"" type=""bool, default: True"" desc=""If as_unicode=False, each logline is returned as a byte object. Otherwise,\nit is returned as a (unicode) string."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""Iterable[(datetime, str)]"" desc=""Iterator over timestamp, logline pairs."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#task,False,3499,362,https://docs.metaflow.org
467,DataArtifact,"<DocSection type=""class"" name=""DataArtifact"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L851"">
 <SigArgSection>
 <SigArg name=""pathspec"" />
 </SigArgSection>
 <Description summary=""A single data artifact and associated metadata. Note that this object does\nnot contain other objects as it is the leaf object in the hierarchy."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""data"" type=""object"" desc=""The data contained in this artifact, that is, the object produced during\nexecution of this run."" />
 	<Parameter name=""sha"" type=""string"" desc=""A unique ID of this artifact."" />
 	<Parameter name=""finished_at"" type=""datetime"" desc=""Corresponds roughly to the `Task.finished_at` time of the parent `Task`.\nAn alias for `DataArtifact.created_at`."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#dataartifact,False,882,88,https://docs.metaflow.org
469,MetaflowData,"<DocSection type=""class"" name=""MetaflowData"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L706"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""Container of data artifacts produced by a `Task`. This object is\ninstantiated through `Task.data`."" extended_summary=""`MetaflowData` allows results to be retrieved by their name\nthrough a convenient dot notation:\n\n```python\nTask(...).data.my_object\n```\n\nYou can also test the existence of an object\n\n```python\nif 'my_object' in Task(...).data:\n    print('my_object found')\n```\n\nNote that this container relies on the local cache to load all data\nartifacts. If your `Task` contains a lot of data, a more efficient\napproach is to load artifacts individually like so\n\n```\nTask(...)['my_object'].data\n```"" />
 
 </DocSection>",H3,https://docs.metaflow.org/api/client#metaflowdata,False,906,88,https://docs.metaflow.org
470,MetaflowCode,"<DocSection type=""class"" name=""MetaflowCode"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L750"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""Snapshot of the code used to execute this `Run`. Instantiate the object through\n`Run(...).code` (if any step is executed remotely) or `Task(...).code` for an\nindividual task. The code package is the same for all steps of a `Run`."" extended_summary=""`MetaflowCode` includes a package of the user-defined `FlowSpec` class and supporting\nfiles, as well as a snapshot of the Metaflow library itself.\n\nCurrently, `MetaflowCode` objects are stored only for `Run`s that have at least one `Step`\nexecuting outside the user's local environment.\n\nThe `TarFile` for the `Run` is given by `Run(...).code.tarball`"" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""path"" type=""str"" desc=""Location (in the datastore provider) of the code package."" />
 	<Parameter name=""info"" type=""Dict[str, str]"" desc=""Dictionary of information related to this code-package."" />
 	<Parameter name=""flowspec"" type=""str"" desc=""Source code of the file containing the `FlowSpec` in this code package."" />
 	<Parameter name=""tarball"" type=""TarFile"" desc=""Python standard library `tarfile.TarFile` archive containing all the code."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#metaflowcode,False,1409,155,https://docs.metaflow.org
471,MetaflowTrigger,"`MetaflowTrigger` is returned by `Run.trigger` if the `Run` was [triggered by an event](/production/event-triggering). It is also returned by [`current.trigger`](/api/current) when called from an event-triggered flow.
 
 
 <DocSection type=""property"" name=""Trigger.event"" module=""metaflow.events"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""The `MetaflowEvent` object corresponding to the triggering event.\n\nIf multiple events triggered the run, this property is the latest event.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""MetaflowEvent, optional"" desc=""The latest event that triggered the run, if applicable."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""Trigger.events"" module=""metaflow.events"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""The list of `MetaflowEvent` objects correspondings to all the triggering events.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""List[MetaflowEvent], optional"" desc=""List of all events that triggered the run"" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""Trigger.run"" module=""metaflow.events"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""The corresponding `Run` object if the triggering event is a Metaflow run.\n\nIn case multiple runs triggered the run, this property is the latest run.\nReturns `None` if none of the triggering events are a `Run`.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""Run, optional"" desc=""Latest Run that triggered this run, if applicable."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""property"" name=""Trigger.runs"" module=""metaflow.events"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""The list of `Run` objects in the triggering events.\nReturns `None` if none of the triggering events are `Run` objects.\n"" />
 <ParamSection name=""Returns"">
 <Parameter type=""List[Run], optional"" desc=""List of runs that triggered this run, if applicable."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""method"" name=""Trigger.__getitem__"" module=""metaflow"" show_import=""False"" heading_level=""4"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/events.py#L139"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""If triggering events are runs, `key` corresponds to the flow name of the triggering run.\nOtherwise, `key` corresponds to the event name and a `MetaflowEvent` object is returned."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""Run or MetaflowEvent"" desc=""`Run` object if triggered by a run. Otherwise returns a `MetaflowEvent`."" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#metaflowtrigger,False,3111,305,https://docs.metaflow.org
472,MetaflowEvent,"`MetaflowEvent` is returned by `MetaflowTrigger` (see above) for [event-triggered](/production/event-triggering) runs.
 
 
 <DocSection type=""class"" name=""MetaflowEvent"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""Container of metadata that identifies the event that triggered\nthe `Run` under consideration."" />
 <ParamSection name=""Attributes"">
 	<Parameter name=""name"" type=""str"" desc=""name of the event."" />
 	<Parameter name=""id"" type=""str"" desc=""unique identifier for the event."" />
 	<Parameter name=""timestamp"" type=""datetime"" desc=""timestamp recording creation time for the event."" />
 	<Parameter name=""type"" type=""str"" desc=""type for the event - one of `event` or `run`"" />
 </ParamSection>
 </DocSection>",H3,https://docs.metaflow.org/api/client#metaflowevent,False,863,84,https://docs.metaflow.org
473,Namespace functions,"<DocSection type=""function"" name=""namespace"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L150"">
 <SigArgSection>
 <SigArg name=""ns"" type=""Optional"" />
 </SigArgSection>
 <Description summary=""Switch namespace to the one provided."" extended_summary=""This call has a global effect. No objects outside this namespace\nwill be accessible. To access all objects regardless of namespaces,\npass None to this call."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""ns"" type=""str, optional"" desc=""Namespace to switch to or None to ignore namespaces."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""str, optional"" desc=""Namespace set (result of get_namespace())."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""function"" name=""get_namespace"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L173"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Return the current namespace that is currently being used to filter objects."" extended_summary=""The namespace is a tag associated with all objects in Metaflow."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""str, optional"" desc=""The current namespace used to filter objects."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""function"" name=""default_namespace"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L191"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Resets the namespace used to filter objects to the default one, i.e. the one that was\nused prior to any `namespace` calls."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""The result of get_namespace() after the namespace has been reset."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/client#namespace-functions,False,1934,181,https://docs.metaflow.org
474,Metadata functions,"<DocSection type=""function"" name=""metadata"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L48"">
 <SigArgSection>
 <SigArg name=""ms"" type=""str"" />
 </SigArgSection>
 <Description summary=""Switch Metadata provider."" extended_summary=""This call has a global effect. Selecting the local metadata will,\nfor example, not allow access to information stored in remote\nmetadata providers.\n\nNote that you don't typically have to call this function directly. Usually\nthe metadata provider is set through the Metaflow configuration file. If you\nneed to switch between multiple providers, you can use the `METAFLOW_PROFILE`\nenvironment variable to switch between configurations."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""ms"" type=""str"" desc=""Can be a path (selects local metadata), a URL starting with http (selects\nthe service metadata) or an explicit specification <metadata_type>@<info>; as an\nexample, you can specify local@<path> or service@<url>."" />
 </ParamSection>
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""The description of the metadata selected (equivalent to the result of\nget_metadata())."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""function"" name=""get_metadata"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L100"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Returns the current Metadata provider."" extended_summary=""If this is not set explicitly using `metadata`, the default value is\ndetermined through the Metaflow configuration. You can use this call to\ncheck that your configuration is set up properly.\n\nIf multiple configuration profiles are present, this call returns the one\nselected through the `METAFLOW_PROFILE` environment variable."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""Information about the Metadata provider currently selected. This information typically\nreturns provider specific information (like URL for remote providers or local paths for\nlocal providers)."" />
 </ParamSection>
 </DocSection>
 
 
 
 <DocSection type=""function"" name=""default_metadata"" module=""metaflow"" show_import=""False"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/client/core.py#L123"">
 <SigArgSection>
 
 </SigArgSection>
 <Description summary=""Resets the Metadata provider to the default value, that is, to the value\nthat was used prior to any `metadata` calls."" />
 <ParamSection name=""Returns"">
 	<Parameter type=""str"" desc=""The result of get_metadata() after resetting the provider."" />
 </ParamSection>
 </DocSection>",H2,https://docs.metaflow.org/api/client#metadata-functions,False,2739,273,https://docs.metaflow.org
475,@kubernetes,"The `@kubernetes` decorator sends a step for execution on a [Kubernetes](https://kubernetes.io) cluster. For more information, see [Executing Tasks Remotely](/scaling/remote-tasks/introduction).
 
 For options related to `tmpfs`, see [Using `metaflow.S3` for in-memory processing](/scaling/data#using-metaflows3-for-in-memory-processing).
 
 
 
 <DocSection type=""decorator"" name=""kubernetes"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/kubernetes/kubernetes_decorator.py#L38"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies that this step should execute on Kubernetes."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""cpu"" type=""int, default: 1"" desc=""Number of CPUs required for this step. If `@resources` is\nalso present, the maximum value from all decorators is used."" />
 	<Parameter name=""memory"" type=""int, default: 4096"" desc=""Memory size (in MB) required for this step. If\n`@resources` is also present, the maximum value from all decorators is\nused."" />
 	<Parameter name=""disk"" type=""int, default: 10240"" desc=""Disk size (in MB) required for this step. If\n`@resources` is also present, the maximum value from all decorators is\nused."" />
 	<Parameter name=""image"" type=""str, optional"" desc=""Docker image to use when launching on Kubernetes. If not specified, and\nMETAFLOW_KUBERNETES_CONTAINER_IMAGE is specified, that image is used. If\nnot, a default Docker image mapping to the current version of Python is used."" />
 	<Parameter name=""service_account"" type=""str, default: METAFLOW_KUBERNETES_SERVICE_ACCOUNT"" desc=""Kubernetes service account to use when launching pod in Kubernetes."" />
 	<Parameter name=""namespace"" type=""str, default: METAFLOW_KUBERNETES_NAMESPACE"" desc=""Kubernetes namespace to use when launching pod in Kubernetes."" />
 	<Parameter name=""secrets"" type=""List[str], optional"" desc=""Kubernetes secrets to use when launching pod in Kubernetes. These\nsecrets are in addition to the ones defined in `METAFLOW_KUBERNETES_SECRETS`\nin Metaflow configuration."" />
 	<Parameter name=""tolerations"" type=""List[str], default: METAFLOW_KUBERNETES_TOLERATIONS"" desc=""Kubernetes tolerations to use when launching pod in Kubernetes."" />
 	<Parameter name=""use_tmpfs: bool, default: False"" desc=""This enables an explicit tmpfs mount for this step."" />
 	<Parameter name=""tmpfs_tempdir: bool, default: True"" desc=""sets METAFLOW_TEMPDIR to tmpfs_path if set for this step."" />
 	<Parameter name=""tmpfs_size: int, optional"" desc=""The value for the size (in MiB) of the tmpfs mount for this step.\nThis parameter maps to the `--tmpfs` option in Docker. Defaults to 50% of the\nmemory allocated for this step."" />
 	<Parameter name=""tmpfs_path: string, optional"" desc=""Path to tmpfs mount for this step. Defaults to /metaflow_temp."" />
 	<Parameter name=""persistent_volume_claims: Dict[str, str], optional"" desc=""A map (dictionary) of persistent volumes to be mounted to the pod for this step. The map is from persistent\nvolumes to the path to which the volume is to be mounted, e.g., `{'pvc-name': '/path/to/mount/on'}`."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/kubernetes#kubernetes,False,3209,365,https://docs.metaflow.org
476,@resources,"The `@resources` decorator specifies resource requirements for a step.
 
 Note that `@resources` takes effect only when combined with another decorator like `@batch` or `@kubernetes` which specifies the compute layer. For more information, see [Executing Tasks Remotely](/scaling/remote-tasks/introduction).
 
 
 
 <DocSection type=""decorator"" name=""resources"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/resources_decorator.py#L4"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the resources needed when executing this step."" extended_summary=""Use `@resources` to specify the resource requirements\nindependently of the specific compute layer (`@batch`, `@kubernetes`).\n\nYou can choose the compute layer on the command line by executing e.g.\n```\npython myflow.py run --with batch\n```\nor\n```\npython myflow.py run --with kubernetes\n```\nwhich executes the flow on the desired system using the\nrequirements specified in `@resources`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""cpu"" type=""int, default: 1"" desc=""Number of CPUs required for this step."" />
 	<Parameter name=""gpu"" type=""int, default: 0"" desc=""Number of GPUs required for this step."" />
 	<Parameter name=""memory"" type=""int, default: 4096"" desc=""Memory size (in MB) required for this step."" />
 	<Parameter name=""shared_memory"" type=""int, optional"" desc=""The value for the size (in MiB) of the /dev/shm volume for this step.\nThis parameter maps to the `--shm-size` option in Docker."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/resources#resources,False,1631,179,https://docs.metaflow.org
477,@environment,"The `@environment` decorator specifies environment variables for a step.
 
 Note that `@environment` is mainly useful for setting special environment variables that need to be present when a container launched by `@batch` or `@kubernetes` starts, which happens before any user code is executed. Variables that are needed after the user code has started can be set as usual in Python:
 ```
 import os
 os.environ['SOME_VAL'] = ""some value""
 ```
 
 To set credentials and other secret as environment variables, [see the `@secrets` decorator](/api/step-decorators/secrets).
 
 
 
 <DocSection type=""decorator"" name=""environment"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/environment_decorator.py#L4"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies environment variables to be set prior to the execution of a step."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""vars"" type=""Dict[str, str], default: {}"" desc=""Dictionary of environment variables to set."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/environment#environment,False,1122,129,https://docs.metaflow.org
478,@step,"The `@step` decorator converts a method to a step of a flow.
 
 Use `@step` to construct Metaflow workflows. For more information, see [Basics of Metaflow](/metaflow/basics).
 
 
 
 <DocSection type=""function"" name=""step"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/decorators.py#L552"">
 <SigArgSection>
 <SigArg name="""" />
 </SigArgSection>
 <Description summary=""The step decorator. Makes a method a step in the workflow."" />
 
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/step#step,False,518,56,https://docs.metaflow.org
479,@card,"Creates a report card after the step completes. For more information, see [Visualizing Results](/metaflow/visualizing-results) and [the main API docs for cards](/api/cards).
 
 
 
 <DocSection type=""decorator"" name=""card"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/cards/card_decorator.py#L27"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Creates a human-readable report, a Metaflow Card, after this step completes."" extended_summary=""Note that you may add multiple `@card` decorators in a step with different parameters."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""type"" type=""str, default: 'default'"" desc=""Card type."" />
 	<Parameter name=""id"" type=""str, optional, default: None"" desc=""If multiple cards are present, use this id to identify this card."" />
 	<Parameter name=""options"" type=""Dict[str, Any], default: {}"" desc=""Options passed to the card. The contents depend on the card type."" />
 	<Parameter name=""timeout"" type=""int, default: 45"" desc=""Interrupt reporting if it takes more than this many seconds."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/card#card,False,1185,129,https://docs.metaflow.org
480,@retry,"The `@retry` decorator specifies how many times the task(s) corresponding to a step should be retried before failing the flow.
 
 For more information, see [Dealing with Failures](/scaling/failures).
 
 
 
 <DocSection type=""decorator"" name=""retry"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/retry_decorator.py#L6"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the number of times the task corresponding\nto a step needs to be retried."" extended_summary=""This decorator is useful for handling transient errors, such as networking issues.\nIf your task contains operations that can't be retried safely, e.g. database updates,\nit is advisable to annotate it with `@retry(times=0)`.\n\nThis can be used in conjunction with the `@catch` decorator. The `@catch`\ndecorator will execute a no-op task after all retries have been exhausted,\nensuring that the flow execution can continue."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""times"" type=""int, default: 3"" desc=""Number of times to retry this task."" />
 	<Parameter name=""minutes_between_retries"" type=""int, default: 2"" desc=""Number of minutes between retries."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/retry#retry,False,1287,146,https://docs.metaflow.org
481,@secrets,"The `@secrets` decorator allows you to access secrets, such as database credentials, securely from a secrets manager. For more details, see [Accessing Secrets](/scaling/secrets).
 
 
 
 <DocSection type=""decorator"" name=""secrets"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/secrets/secrets_decorator.py#L182"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies secrets to be retrieved and injected as environment variables prior to\nthe execution of a step."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""sources"" type=""List[Union[str, Dict[str, Any]]], default: []"" desc=""List of secret specs, defining how the secrets are to be retrieved"" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/secrets#secrets,False,807,80,https://docs.metaflow.org
482,@catch,"The `@catch` decorator ensures that a step will succeed, despite any errors in the user code or transient platform issues.
 
 It is best used in conjunction with the `@retry` decorator: After all retries have been exhausted, `@catch` executes a no-op task that allows the run to continue. For more information, see [Dealing with Failures](/scaling/failures).
 
 
 
 <DocSection type=""decorator"" name=""catch"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/catch_decorator.py#L22"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies that the step will success under all circumstances."" extended_summary=""The decorator will create an optional artifact, specified by `var`, which\ncontains the exception raised. You can use it to detect the presence\nof errors, indicating that all happy-path artifacts produced by the step\nare missing."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""var"" type=""str, optional"" desc=""Name of the artifact in which to store the caught exception.\nIf not specified, the exception is not stored."" />
 	<Parameter name=""print_exception"" type=""bool, default: True"" desc=""Determines whether or not the exception is printed to\nstdout when caught."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/catch#catch,False,1334,158,https://docs.metaflow.org
483,@timeout,"The `@timeout` decorator specifies for how long a step should execute before it is interrupted.
 
 You can use it to handle tasks that may get stuck, or to set a time-budget for a step. For more information, see [Dealing with Failures](/scaling/failures).
 
 
 
 <DocSection type=""decorator"" name=""timeout"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/timeout_decorator.py#L13"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies a timeout for your step."" extended_summary=""This decorator is useful if this step may hang indefinitely.\n\nThis can be used in conjunction with the `@retry` decorator as well as the `@catch` decorator.\nA timeout is considered to be an exception thrown by the step. It will cause the step to be\nretried if needed and the exception will be caught by the `@catch` decorator, if present.\n\nNote that all the values specified in parameters are added together so if you specify\n60 seconds and 1 hour, the decorator will have an effective timeout of 1 hour and 1 minute."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""seconds"" type=""int, default: 0"" desc=""Number of seconds to wait prior to timing out."" />
 	<Parameter name=""minutes"" type=""int, default: 0"" desc=""Number of minutes to wait prior to timing out."" />
 	<Parameter name=""hours"" type=""int, default: 0"" desc=""Number of hours to wait prior to timing out."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/timeout#timeout,False,1509,202,https://docs.metaflow.org
484,@conda,"The `@conda` decorator specifies what libraries should be made available for a step.
 
 The libraries are installed from [Conda repositories](https://anaconda.org/). For more information, see [Managing External Libraries](/scaling/dependencies).
 
 
 
 <DocSection type=""decorator"" name=""conda"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/conda/conda_step_decorator.py#L40"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the Conda environment for the step."" extended_summary=""Information in this decorator will augment any\nattributes set in the `@conda_base` flow-level decorator. Hence,\nyou can use `@conda_base` to set common libraries required by all\nsteps and use `@conda` to specify step-specific additions."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""libraries"" type=""Dict[str, str], default: {}"" desc=""Libraries to use for this step. The key is the name of the package\nand the value is the version to use."" />
 	<Parameter name=""python"" type=""str, optional"" desc=""Version of Python to use, e.g. '3.7.4'. A default value of None means to\nuse the current Python version."" />
 	<Parameter name=""disabled"" type=""bool, default: False"" desc=""If set to True, disables Conda."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/conda#conda,False,1355,150,https://docs.metaflow.org
485,@batch,"The `@batch` decorator sends a step for execution on the [AWS Batch](https://aws.amazon.com/batch/) compute layer. For more information, see [Executing Tasks Remotely](/scaling/remote-tasks/introduction).
 
 Note that while `@batch` doesn't allow mounting arbitrary disk volumes on the fly, you can create in-memory filesystems easily with `tmpfs` options. For more details, see [using `metaflow.S3` for in-memory processing](/scaling/data#using-metaflows3-for-in-memory-processing).
 
 
 <DocSection type=""decorator"" name=""batch"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/batch/batch_decorator.py#L34"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies that this step should execute on [AWS Batch](https://aws.amazon.com/batch/)."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""cpu"" type=""int, default: 1"" desc=""Number of CPUs required for this step. If `@resources` is\nalso present, the maximum value from all decorators is used."" />
 	<Parameter name=""gpu"" type=""int, default: 0"" desc=""Number of GPUs required for this step. If `@resources` is\nalso present, the maximum value from all decorators is used."" />
 	<Parameter name=""memory"" type=""int, default: 4096"" desc=""Memory size (in MB) required for this step. If\n`@resources` is also present, the maximum value from all decorators is\nused."" />
 	<Parameter name=""image"" type=""str, optional"" desc=""Docker image to use when launching on AWS Batch. If not specified, and\nMETAFLOW_BATCH_CONTAINER_IMAGE is specified, that image is used. If\nnot, a default Docker image mapping to the current version of Python is used."" />
 	<Parameter name=""queue"" type=""str, default: METAFLOW_BATCH_JOB_QUEUE"" desc=""AWS Batch Job Queue to submit the job to."" />
 	<Parameter name=""iam_role"" type=""str, default: METAFLOW_ECS_S3_ACCESS_IAM_ROLE"" desc=""AWS IAM role that AWS Batch container uses to access AWS cloud resources."" />
 	<Parameter name=""execution_role"" type=""str, default: METAFLOW_ECS_FARGATE_EXECUTION_ROLE"" desc=""AWS IAM role that AWS Batch can use [to trigger AWS Fargate tasks]\n(https://docs.aws.amazon.com/batch/latest/userguide/execution-IAM-role.html)."" />
 	<Parameter name=""shared_memory"" type=""int, optional"" desc=""The value for the size (in MiB) of the /dev/shm volume for this step.\nThis parameter maps to the `--shm-size` option in Docker."" />
 	<Parameter name=""max_swap"" type=""int, optional"" desc=""The total amount of swap memory (in MiB) a container can use for this\nstep. This parameter is translated to the `--memory-swap` option in\nDocker where the value is the sum of the container memory plus the\n`max_swap` value."" />
 	<Parameter name=""swappiness"" type=""int, optional"" desc=""This allows you to tune memory swappiness behavior for this step.\nA swappiness value of 0 causes swapping not to happen unless absolutely\nnecessary. A swappiness value of 100 causes pages to be swapped very\naggressively. Accepted values are whole numbers between 0 and 100."" />
 	<Parameter name=""use_tmpfs: bool, default: False"" desc=""This enables an explicit tmpfs mount for this step."" />
 	<Parameter name=""tmpfs_tempdir: bool, default: True"" desc=""sets METAFLOW_TEMPDIR to tmpfs_path if set for this step."" />
 	<Parameter name=""tmpfs_size: int, optional"" desc=""The value for the size (in MiB) of the tmpfs mount for this step.\nThis parameter maps to the `--tmpfs` option in Docker. Defaults to 50% of the\nmemory allocated for this step."" />
 	<Parameter name=""tmpfs_path: string, optional"" desc=""Path to tmpfs mount for this step. Defaults to /metaflow_temp."" />
 	<Parameter name=""inferentia"" type=""int, default: 0"" desc=""Number of Inferentia chips required for this step."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/step-decorators/batch#batch,False,3813,458,https://docs.metaflow.org
486,@trigger_on_finish,"Use the `@trigger_on_finish` decorator to trigger a flow [deployed on Argo Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows) when another flow finishes.
 
 Read more in [Triggering Flows Based on Other Flows](/production/event-triggering/flow-events).
 
 
 
 <DocSection type=""decorator"" name=""trigger_on_finish"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/events_decorator.py#L142"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the flow(s) that this flow depends on."" extended_summary=""```\n@trigger_on_finish(flow='FooFlow')\n```\nor\n```\n@trigger_on_finish(flows=['FooFlow', 'BarFlow'])\n```\nThis decorator respects the @project decorator and triggers the flow\nwhen upstream runs within the same namespace complete successfully\n\nAdditionally, you can specify project aware upstream flow dependencies\nby specifying the fully qualified project_flow_name.\n```\n@trigger_on_finish(flow='my_project.branch.my_branch.FooFlow')\n```\nor\n```\n@trigger_on_finish(flows=['my_project.branch.my_branch.FooFlow', 'BarFlow'])\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""flow"" type=""str, optional"" desc=""Upstream flow dependency for this flow."" />
 	<Parameter name=""flows"" type=""List[str], optional"" desc=""Upstream flow dependencies for this flow."" />
 	<Parameter name=""options"" type=""dict, optional"" desc=""Backend-specific configuration for tuning eventing behavior."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/flow-decorators/trigger_on_finish#trigger-on-finish,False,1578,121,https://docs.metaflow.org
487,@trigger,"Use the `@trigger` decorator to trigger a flow [deployed on Argo Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows) based on an external event.
 
 Read more in [Triggering Flows Based on External Events](/production/event-triggering/external-events).
 
 
 
 <DocSection type=""decorator"" name=""trigger"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/events_decorator.py#L14"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the event(s) that this flow depends on."" extended_summary=""```\n@trigger(event='foo')\n```\nor\n```\n@trigger(events=['foo', 'bar'])\n```\n\nAdditionally, you can specify the parameter mappings\nto map event payload to Metaflow parameters for the flow.\n```\n@trigger(event={'name':'foo', 'parameters':{'my_param': 'event_field'})\n```\nor\n```\n@trigger(events=[{'name':'foo', 'parameters':{'my_param_1': 'event_field_1'},\n                 {'name':'bar', 'parameters':{'my_param_2': 'event_field_2'}])\n```"" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""event"" type=""Union[str, dict], optional"" desc=""Event dependency for this flow."" />
 	<Parameter name=""events"" type=""List[Union[str, dict]], optional"" desc=""Events dependency for this flow."" />
 	<Parameter name=""options"" type=""dict, optional"" desc=""Backend-specific configuration for tuning eventing behavior."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/flow-decorators/trigger#trigger,False,1486,129,https://docs.metaflow.org
488,@project,"The `@project` decorator makes it convenient to create isolated [Metaflow namespaces](/scaling/tagging) and
 corresponding [proudction deployments](/production/scheduling-metaflow-flows/introduction). When
 multiple flows use the same project name, they can fetch data across them safely using [the Client API](/metaflow/client), without interference from other users running the same flows.
 
 By itself, `@project` doesn't change the behavior besides [exposing new attributes in the `current` object](/api/current#project). It alters the flow names when they are deployed in production, allowing multiple parallel deployments.
 
 For more information, see [Coordinating Larger Metaflow Projects](/production/coordinating-larger-metaflow-projects).
 
 
 
 <DocSection type=""decorator"" name=""project"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/project_decorator.py#L15"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies what flows belong to the same project."" extended_summary=""A project-specific namespace is created for all flows that\nuse the same `@project(name)`."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""name"" type=""str"" desc=""Project name. Make sure that the name is unique amongst all\nprojects that use the same production scheduler. The name may\ncontain only lowercase alphanumeric characters and underscores."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/flow-decorators/project#project,False,1497,154,https://docs.metaflow.org
489,@schedule,"The `@schedule` decorator specifies the times when the flow should be run when deployed to an external orchestrator like AWS Step Functions or Argo Workflows.
 
 For more information, see [Scheduling Metaflow Flows](/production/scheduling-metaflow-flows/introduction).
 
 
 
 <DocSection type=""decorator"" name=""schedule"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/schedule_decorator.py#L5"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the times when the flow should be run when running on a\nproduction scheduler."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""hourly"" type=""bool, default: False"" desc=""Run the workflow hourly."" />
 	<Parameter name=""daily"" type=""bool, default: True"" desc=""Run the workflow daily."" />
 	<Parameter name=""weekly"" type=""bool, default: False"" desc=""Run the workflow weekly."" />
 	<Parameter name=""cron"" type=""str, optional"" desc=""Run the workflow at [a custom Cron schedule](https://docs.aws.amazon.com/eventbridge/latest/userguide/scheduled-events.html#cron-expressions)\nspecified by this expression."" />
 	<Parameter name=""timezone"" type=""str, optional"" desc=""Timezone on which the schedule runs (default: None). Currently supported only for Argo workflows,\nwhich accepts timezones in [IANA format](https://nodatime.org/TimeZones)."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/flow-decorators/schedule#schedule,False,1461,138,https://docs.metaflow.org
490,@conda_base,"The `@conda_base` decorator specifies what libraries should be made available for all steps of a flow.
 
 The libraries are installed from [Conda repositories](https://anaconda.org/). For more information, see [Managing External Libraries](/scaling/dependencies).
 
 
 
 <DocSection type=""decorator"" name=""conda_base"" module=""metaflow"" show_import=""True"" heading_level=""3"" link=""https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/conda/conda_flow_decorator.py#L7"">
 <SigArgSection>
 <SigArg name=""..."" />
 </SigArgSection>
 <Description summary=""Specifies the Conda environment for all steps of the flow."" extended_summary=""Use `@conda_base` to set common libraries required by all\nsteps and use `@conda` to specify step-specific additions."" />
 <ParamSection name=""Parameters"">
 	<Parameter name=""libraries"" type=""Dict[str, str], default: {}"" desc=""Libraries to use for this flow. The key is the name of the package\nand the value is the version to use."" />
 	<Parameter name=""python"" type=""str, optional"" desc=""Version of Python to use, e.g. '3.7.4'. A default value of None means\nto use the current Python version."" />
 	<Parameter name=""disabled"" type=""bool, default: False"" desc=""If set to True, disables Conda."" />
 </ParamSection>
 </DocSection>",H1,https://docs.metaflow.org/api/flow-decorators/conda_base#conda-base,False,1268,141,https://docs.metaflow.org
491,Creating Flows,"This document introduces the basic concepts of Metaflow. If you are eager to try out
 Metaflow in practice, you can start with the [tutorial](../getting-started/tutorials/).
 After the tutorial, you can return to this document to learn more about how Metaflow
 works.",H1,https://docs.metaflow.org/metaflow/basics#creating-flows,False,267,40,https://docs.metaflow.org
492,The Structure of Metaflow Code,"Metaflow follows [the dataflow
 paradigm](https://en.wikipedia.org/wiki/Dataflow_programming) which models a program as
 a directed graph of operations. This is a natural paradigm for expressing data
 processing pipelines, machine learning in particular.
 
 We call the graph of operations **a flow**. You define the operations, called **steps**,
 which are nodes of the graph and contain transitions to the next steps, which serve as
 edges.
 
 Metaflow sets some constraints on the structure of the graph. For starters, every flow
 needs a step called `start` and a step called `end`. An execution of the flow, which we
 call **a run**, starts at `start`. The run is successful if the final `end` step
 finishes successfully.
 
 What happens between `start` and `end` is up to you. You can construct the graph in
 between using an arbitrary combination of the following three types of transitions
 supported by Metaflow:",H2,https://docs.metaflow.org/metaflow/basics#the-structure-of-metaflow-code,False,922,142,https://docs.metaflow.org
493,Linear,"The most basic type of transition is **a linear** transition. It moves from one step to
 another one.
 
 Here is a graph with two linear transitions:
 
 ![](/assets/graph_linear.png)
 
 The corresponding Metaflow script looks like this:
 
 ```python
 from metaflow import FlowSpec, step
 
 class LinearFlow(FlowSpec):
 
     @step
     def start(self):
         self.my_var = 'hello world'
         self.next(self.a)
 
     @step
     def a(self):
         print('the data artifact is: %s' % self.my_var)
         self.next(self.end)
 
     @step
     def end(self):
         print('the data artifact is still: %s' % self.my_var)
 
 if __name__ == '__main__':
     LinearFlow()
 ```
 
 Save this snippet to a file, `linear.py`. You can execute Metaflow flows on the command
 line like any other Python scripts. Try this:
 
 ```bash
 python linear.py run
 ```
 
 Whenever you see a flow like this in the documentation, just save it in a file and
 execute it like above.",H3,https://docs.metaflow.org/metaflow/basics#linear,False,968,207,https://docs.metaflow.org
494,Artifacts,"Besides executing the steps `start`, `a`, and `end` in order, this flow creates **a data
 artifact** called `my_var`. In Metaflow, data artifacts are created simply by assigning
 values to instance variables like `my_var`.
 
 Artifacts are a core concept of Metaflow. They have a number of uses:
 
  - They allow you to manage the data flow through the flow without having to load and
    store data manually.
 
  - All artifacts are persisted so that they can be analyzed later using the [Client
    API](/metaflow/client), visualized with [Cards](/metaflow/visualizing-results), and
    even used across flows.
 
  - Artifacts works consistently across environments, so you can run some steps locally
    and [some steps in the cloud](/scaling/introduction) without having to worry about
    transferring data explicitly.
 
  - Having access to past artifacts greatly helps [debugging](/metaflow/debugging), since
  you can eyeball data before failures and even [resume past
  executions](/metaflow/debugging#how-to-use-the-resume-command) after fixing bugs.
 
 Data artifacts are available in all steps after they have been created, so they behave
 as any normal instance variables. An exception to this rule are branches, as explained
 below.",H3,https://docs.metaflow.org/metaflow/basics#artifacts,False,1246,198,https://docs.metaflow.org
495,Branch,"You can express parallel steps with **a branch**. In the figure below, `start`
 transitions to two parallel steps, `a` and `b`. Any number of parallel steps are
 allowed. A benefit of a branch like this is performance: Metaflow can execute `a` and
 `b` over multiple CPU cores or over multiple instances in the cloud.
 
 ![](/assets/graph_branch.png)
 
 ```python
 from metaflow import FlowSpec, step
 
 class BranchFlow(FlowSpec):
 
     @step
     def start(self):
         self.next(self.a, self.b)
 
     @step
     def a(self):
         self.x = 1
         self.next(self.join)
 
     @step
     def b(self):
         self.x = 2
         self.next(self.join)
 
     @step
     def join(self, inputs):
         print('a is %s' % inputs.a.x)
         print('b is %s' % inputs.b.x)
         print('total is %d' % sum(input.x for input in inputs))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     BranchFlow()
 ```
 
 Every branch must be joined. The join step does not need to be called `join` as above
 but it must take an extra argument, like `inputs` above.
 
 In the example above, the value of `x` above is ambiguous: `a` sets it to `1` and `b` to
 `2`. To disambiguate the branches, the join step can refer to a specific step in the
 branch, like `inputs.a.x` above. For convenience, you can also iterate over all steps in
 the branch using `inputs`, as done in the last print statement in the above `join` step.
 For more details, see the section about [data flow through the
 graph](basics#data-flow-through-the-graph).
 
 Note that you can nest branches arbitrarily, that is, you can branch inside a branch.
 Just remember to join all the branches that you create.",H3,https://docs.metaflow.org/metaflow/basics#branch,False,1737,381,https://docs.metaflow.org
496,Foreach,"Static branches like above are useful when you know the branches at the development
 time. Alternatively, you may want to branch based on data dynamically. This is the use
 case for **a foreach** branch.
 
 Foreach works similarly like the branch above but instead of creating named step
 methods, many parallel copies of steps inside a foreach loop are executed.
 
 A foreach loop can iterate over any list like `titles` below.
 
 ![](/assets/graph_foreach.png)
 
 ```python
 from metaflow import FlowSpec, step
 
 class ForeachFlow(FlowSpec):
 
     @step
     def start(self):
         self.titles = ['Stranger Things',
                        'House of Cards',
                        'Narcos']
         self.next(self.a, foreach='titles')
 
     @step
     def a(self):
         self.title = '%s processed' % self.input
         self.next(self.join)
 
     @step
     def join(self, inputs):
         self.results = [input.title for input in inputs]
         self.next(self.end)
 
     @step
     def end(self):
         print('\n'.join(self.results))
 
 if __name__ == '__main__':
     ForeachFlow()
 ```
 
 The foreach loop is initialized by specifying a keyword argument `foreach` in
 `self.next()`. The `foreach` argument takes a string that is the name of a list stored
 in an instance variable, like `titles` above.
 
 Steps inside a foreach loop create separate **tasks** to process each item of the list.
 Here, Metaflow creates three parallel tasks for the step `a` to process the three items
 of the `titles` list in parallel. You can access the specific item assigned to a task
 with an instance variable called `input`.
 
 Foreach loops must be joined like static branches. Note that tasks inside a foreach loop
 are not named, so you can only iterate over them with `inputs`. If you want, you can
 assign a value to an instance variable in a foreach step which helps you to identify the
 task.
 
 You can nest foreaches and combine them with branches and linear steps arbitrarily.",H3,https://docs.metaflow.org/metaflow/basics#foreach,False,1998,425,https://docs.metaflow.org
497,What should be a step?,"There is not a single right way of structuring code as a graph of steps but here are
 some best practices that you can follow.
 
 Metaflow treats steps as indivisible units of execution. That is, a step either succeeds
 or fails as a whole. After the step has finished successfully, Metaflow persists all
 instance variables that were created in the step code, so the step does not have to be
 executed again even if a subsequent step fails. In other words, you can inspect data
 artifacts that were present when the step finished, but you can not inspect data that
 were manipulated within a step.
 
 This makes a step [a
 checkpoint](https://en.wikipedia.org/wiki/Application_checkpointing). The more granular
 your steps are, the more control you have over inspecting results and resuming failed
 runs.
 
 A downside of making steps too granular is that checkpointing adds some overhead. It
 would not make sense to execute each line of code as a separate step. Keep your steps
 small but not too small. A good rule of thumb is that a single step should not take more
 than an hour to run, preferably much less than that.
 
 Another important consideration is the readability of your code. Try running
 
 ```bash
 python myflow.py show
 ```
 
 which prints out the steps of your flow. Does the overview give you a good idea of your
 code? If the steps are too broad, it might make sense to split them up just to make the
 overall flow more descriptive.",H2,https://docs.metaflow.org/metaflow/basics#what-should-be-a-step,False,1455,252,https://docs.metaflow.org
498,How to define parameters for flows?,"Here is an example of a flow that defines a parameter, `alpha`:
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 
 class ParameterFlow(FlowSpec):
     alpha = Parameter('alpha',
                       help='Learning rate',
                       default=0.01)
 
     @step
     def start(self):
         print('alpha is %f' % self.alpha)
         self.next(self.end)
 
     @step
     def end(self):
         print('alpha is still %f' % self.alpha)
 
 if __name__ == '__main__':
     ParameterFlow()
 ```
 
 Parameters are defined by assigning a `Parameter` object to a class variable. Parameter
 variables are automatically available in all steps, like `alpha` above.
 
 You can set the parameter values on the command line as follows:
 
 ```bash
 python parameter_flow.py run --alpha 0.6
 ```
 
 You can see available parameters with:
 
 ```bash
 python parameter_flow.py run --help
 ```
 
 Parameters are typed based on the type of their default value. If there is no meaningful
 default for a parameter, you can define it as follows:
 
 ```python
 num_components = Parameter('num_components',
                            help='Number of components',
                            required=True,
                            type=int)
 ```
 
 Now the flow can not be run without setting `--num_components` to an integer value.
 
 See the API reference for [the `Parameter` class](/api/flowspec#parameters) for more
 information.",H2,https://docs.metaflow.org/metaflow/basics#how-to-define-parameters-for-flows,False,1441,353,https://docs.metaflow.org
499,Advanced parameters,"In the example above, `Parameters` took simple scalar values, such as integers or
 floating point values. To support more complex values for `Parameter`, Metaflow allows
 you to specify the value as JSON. This feature comes in handy if your `Parameter` is a
 list of values, a mapping, or a more complex data structure.
 
 This example allows the user to define a GDP by country mapping as a `Parameter`:
 
 ```python
 from metaflow import FlowSpec, Parameter, step, JSONType
 
 class JSONParameterFlow(FlowSpec):
     gdp = Parameter('gdp',
                     help='Country-GDP Mapping',
                     type=JSONType,
                     default='{""US"": 1939}')
 
     country = Parameter('country',
                         help='Choose a country',
                         default='US')
 
     @step
     def start(self):
         print('The GDP of %s is $%dB' % (self.country, self.gdp[self.country]))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     JSONParameterFlow()
 ```
 
 Execute the code as follows:
 
 ```bash
 python parameter_flow.py run --gdp '{""US"": 1}'
 ```
 
 Parameters can also be used to include local files. See the section on
 [IncludeFile](/scaling/data#data-in-local-files) for more information.",H3,https://docs.metaflow.org/metaflow/basics#advanced-parameters,False,1292,316,https://docs.metaflow.org
500,Data flow through the graph,"As previously mentioned, for [linear](basics#linear) steps, data artifacts are
 propagated and any linear step can access data artifacts created by previous steps using
 instance variables. In this case, Metaflow can easily determine the value of each
 artifact by simply taking the value of that artifact at the end of the previous step.
 
 In a join step, however, the value of artifacts can potentially be set to different
 values on the incoming branches; the value of the artifact is said to be ambiguous.
 
 To make it easier to implement a join step after foreach or branch, Metaflow provides a
 utility function, `merge_artifacts`, to aid in propagating unambiguous values.
 
 ```python
 from metaflow import FlowSpec, step
 
 class MergeArtifactsFlow(FlowSpec):
 
     @step
     def start(self):
         self.pass_down = 'a'
         self.next(self.a, self.b)
 
     @step
     def a(self):
         self.common = 5
         self.x = 1
         self.y = 3
         self.from_a = 6
         self.next(self.join)
 
     @step
     def b(self):
         self.common = 5
         self.x = 2
         self.y = 4
         self.next(self.join)
 
     @step
     def join(self, inputs):
         self.x = inputs.a.x
         self.merge_artifacts(inputs, exclude=['y'])
         print('x is %s' % self.x)
         print('pass_down is %s' % self.pass_down)
         print('common is %d' % self.common)
         print('from_a is %d' % self.from_a)
         self.next(self.c)
 
     @step
     def c(self):
         self.next(self.d, self.e)
 
     @step
     def d(self):
         self.conflicting = 7
         self.next(self.join2)
 
     @step
     def e(self):
         self.conflicting = 8
         self.next(self.join2)
 
     @step
     def join2(self, inputs):
         self.merge_artifacts(inputs, include=['pass_down', 'common'])
         print('Only pass_down and common exist here')
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     MergeArtifactsFlow()
 ```
 
 In the example above, the `merge_artifacts` function behaves as follows:",H2,https://docs.metaflow.org/metaflow/basics#data-flow-through-the-graph,False,2106,542,https://docs.metaflow.org
501,Developing with Metaflow,"Every project is a journey. Each stage of the journey presents different challenges and
 requirements. Luckily Metaflow allows you to start experimenting easily without having
 to worry about all details upfront. Rest assured that when your project grows in scale
 and impact, Metaflow helps your code grow accordingly.
 
 A typical project goes through three major stages that are illustrated below. This
 section focuses on the first stage - local development. If you are curious about the
 next two stages, you can take a peek at [Scalable Flows](/scaling/introduction) and
 [Production Deployments](/production/introduction).
 
 ![](/assets/intro-cartoon-1.svg)",H1,https://docs.metaflow.org/metaflow/introduction#developing-with-metaflow,False,665,93,https://docs.metaflow.org
502,Developing on a Personal Workstation,"As a data scientist or engineer, your main productivity tool is your personal
 workstation, such as a laptop or a cloud workstation. A great thing about a personal
 computer is that they allow you to iterate quickly and experiment freely knowing that
 you are not accidentally interfering with a colleague's work.
 
 Metaflow treats local development as the first class concern. You can develop and test
 Metaflow code locally like any other Python project or a notebook. Here's what often
 happens in the early phases of a project:
 
 1. Many data scientists are familiar with notebooks that shine at open-ended exploration
    and quick sketching of solutions. When developing with Metaflow, it is totally ok
    (although not required) to use notebooks for analysis. Use the [Metaflow Client
    API](/metaflow/client) to access and organize results of Metaflow runs in a notebook.
 
 2. Once you have a rough idea for the first version of your project, it is useful to
 structure it as a workflow, or *flows* in Metaflow parlance. Metaflow makes this easy:
 You can copy-paste the best parts of a notebook as steps of a Metaflow flow. For details
 why this is a good idea and how to create flows in practice, see [Creating
 Flows](/metaflow/basics).
 
 3. Don't consider flows just as static configuration. They are living and dynamic
 entities that you should be able to execute locally and improve gradually (this is where
 [`resume` comes in handy!](/metaflow/debugging#how-to-use-the-resume-command)). The
 workflow becomes the backbone of your application - in particular helping with [data
 flow through artifacts](/metaflow/basics#artifacts) - which enables much of the
 functionality in the next phases of the project.",H2,https://docs.metaflow.org/metaflow/introduction#developing-on-a-personal-workstation,False,1730,278,https://docs.metaflow.org
503,What You Will Learn,"Let's go ahead and learn how to create and test Metaflow flows. This stage covers four
 core topics:
 
  1. [Creating flows](/metaflow/basics)
  2. [Inspecting results of flows](/metaflow/client)
  3. [Visualizing results](/metaflow/visualizing-results)
  4. [Debugging flows](/metaflow/debugging)
 
 These topics work locally on your workstation without any additional infrastructure, so
 it is easy to get started.",H2,https://docs.metaflow.org/metaflow/introduction#what-you-will-learn,False,416,56,https://docs.metaflow.org
504,Debugging Flows,"Metaflow wants to make debugging failed flows as painless as possible.
 
 Debugging issues during development is a normal part of the development process. You
 should be able to develop and debug your Metaflow scripts similar to how you develop any
 Python scripts locally.
 
 Debugging a failure can either happen **after** a failed execution or **during**
 execution. In the first case, Metaflow provides two mechanisms:",H1,https://docs.metaflow.org/metaflow/debugging#debugging-flows,False,422,66,https://docs.metaflow.org
505,How to debug failed flows,"The process of debugging failed flows is similar both for development-time and
 production-time issues:
 
 1. Identify the step that failed. The failed step is reported as the last line of the
    error report where it is easy to spot.
 2. Identify the run id of the failed run. On the console output, each line is prefixed
    with an identifier like `2/start/21426`. Here, `2` is the run id, `start` is the step
    name, and `21426` is the task id.
 3. Reproduce the failed run with `resume` as [described
    below](debugging#how-to-use-the-resume-command). Confirm that the error message you
    get locally matches to the original error message.
 4. Identify the failed logic inside the failed step. You can do this by adding `print`
    statements in the step until `resume` reveals enough information. Alternatively, you
    can reproduce the faulty logic in a notebook using input data artifacts for the step,
    as described below in the section about
    [notebooks](debugging#inspecting-data-with-a-notebook).
 5. Confirm that the fix works with `resume`. Return to 4 if the error has not been
    fixed.
 6. When the step works locally, rerun the whole flow from `start` to `end` and confirm
    that the fix works as intended.",H2,https://docs.metaflow.org/metaflow/debugging#how-to-debug-failed-flows,False,1241,226,https://docs.metaflow.org
506,How to use the `resume` command,"The `resume` command allows you to resume execution of a past run at a failed step.
 Resuming makes it easy to quickly reproduce the failure and iterate on the step code
 until a fix has been found.
 
 Here is how it works. First, save the snippet below :
 
 ```python
 from metaflow import FlowSpec, step
 
 class DebugFlow(FlowSpec):
 
     @step
     def start(self):
         self.next(self.a, self.b)
 
     @step
     def a(self):
         self.x = 1
         self.next(self.join)
 
     @step
     def b(self):
         self.x = int('2fail')
         self.next(self.join)
 
     @step
     def join(self, inputs):
         print('a is %s' % inputs.a.x)
         print('b is %s' % inputs.b.x)
         print('total is %d' % sum(input.x for input in inputs))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     DebugFlow()
 ```
 
 Run the script with:
 
 ```bash
 python debug.py run
 ```
 
 The run should fail. The output should look like:
 
 ```python
 ...
 2018-01-27 22:59:40.313 [3/b/21638 (pid 13720)] File ""debug.py"", line 17, in b
 2018-01-27 22:59:40.313 [3/b/21638 (pid 13720)] self.x = int('2fail')
 2018-01-27 22:59:40.314 [3/b/21638 (pid 13720)] ValueError: invalid literal for int() with base 10: '2fail'
 2018-01-27 22:59:40.314 [3/b/21638 (pid 13720)]
 2018-01-27 22:59:40.361 [3/a/21637 (pid 13719)] Task finished successfully.
 2018-01-27 22:59:40.362 [3/b/21638 (pid 13720)] Task failed.
 2018-01-27 22:59:40.362 Workflow failed.
     Step failure:
     Step b (task-id 21638) failed.
 ```
 
 This shows that the step `b` of the run `3` failed. In your case, the run id could be
 different.
 
 The `resume` command runs the flow similar to `run`. However, in contrast to `run`
 resuming reuses results of every successful step instead of actually running them.
 
 Try it with
 
 ```bash
 python debug.py resume
 ```
 
 Metaflow remembers the run number of the last local run, which in this case is `3`, so
 you should see `resume` reusing results of the run above. Since we have not changed
 anything yet, you should see the above error again but with an incremented run number.
 
 You can also resume a specific run using the CLI option `--origin-run-id` if you don't
 like the default value selected by Metaflow. To get the same behavior as above, you can
 also do:
 
 ```bash
 python debug.py resume --origin-run-id 3
 ```
 
 If you'd like programmatic access to the `--origin-run-id` selected for the `resume`
 (either implicitly selected by Metaflow as last `run` invocation, or explicitly declared
 by the user via the CLI), you can use the `current` singleton. Read more
 [here](/scaling/tagging#accessing-current-ids-in-a-flow).
 
 Next, fix the error by replacing `int('2fail')` in `debug.py` with `int('2')`. Try again
 after the fix. This time, you should see the flow completing successfully.
 
 Resuming uses the flow and step names to decide what results can be reused. This means
 that the results of previously successful steps will get reused even if you change their
 step code. You can add new steps and alter code of failed steps safely with `resume`",H3,https://docs.metaflow.org/metaflow/debugging#how-to-use-the-resume-command,False,3154,601,https://docs.metaflow.org
507,Resuming from an arbitrary step,"By default, `resume` resumes from the step that failed, like `b` above. Sometimes fixing
 the failed step requires re-execution of some steps that precede it.
 
 You can choose the step to resume from by specifying the step name on the command line:
 
 ```bash
 python debug.py resume start
 ```
 
 This would resume execution from the step `start`. If you specify a step that comes
 after the step that failed, execution resumes from the failed step - you can't skip over
 steps.",H4,https://docs.metaflow.org/metaflow/debugging#resuming-from-an-arbitrary-step,False,480,83,https://docs.metaflow.org
508,Resume and parameters,"If your flow has [`Parameters`](basics#how-to-define-parameters-for-flows), you can't
 change their values when resuming. Changing parameter values could change the results of
 any steps, including those that `resume` skips over, which could result to unexpected
 behavior in subsequent steps.
 
 The `resume` command reuses the parameter values that you set with `run` originally.",H4,https://docs.metaflow.org/metaflow/debugging#resume-and-parameters,False,381,51,https://docs.metaflow.org
509,Reproducing production issues locally,"The `resume` command can come in handy when debugging failed production runs too. This
 works exactly the same way as described above: Just specify a production run ID as the
 `--origin-run-id`. Crucially, the resumed producation run executes in your own
 namespace, so it doesn't affect other production runs directly, making it safe to debug,
 test, and iterate on issues locally.
 
 Here's a high-level recipe:
 
  1. You deploy a flow to [a production workflow orchestrator](/production/introduction)
     supported by Metaflow.
  2. A production run fails. Note its run ID, `R`.
  3. To debug the issue, you resume the failed run locally with `resume --origin-run-id
     R`.
  4. You can repeat (3) until the issue has been fixed.
  5. Once the issue has been fixed, you deploy the fixed version to production and
     restart the production run.
 
 To apply the above recipe on your orchestrator of choice, see the following sections:
 
  - [Resuming with Argo
    Workflows](/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#reproducing-failed-production-runs)
  - [Resuming with AWS Step
    Functions](/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#reproducing-failed-production-runs)
  - [Resuming with Apache
    Airflow](/production/scheduling-metaflow-flows/scheduling-with-airflow#reproducing-failed-production-runs)",H3,https://docs.metaflow.org/metaflow/debugging#reproducing-production-issues-locally,False,1376,195,https://docs.metaflow.org
510,Inspecting data with a notebook,"The above example demonstrates a trivial error. In the real life, errors can be much
 trickier to debug. In the case of machine learning, a flow may fail because of an
 unexpected distribution of input data, although nothing is wrong with the code per se.
 
 Being able to inspect data produced by every step is a powerful feature of Metaflow
 which can help in situations like this.
 
 This clip (no audio) demonstrates inspecting values in a flow:
 
 <div style={{position: ""relative"", width: ""100%"", height: 500}}>
 <iframe src=""https://cdn.iframe.ly/3Ffh7OX"" style={{top: 0, left: 0, width: ""100%"", 
 height: ""100%"", position: ""absolute"", border: 0}} allowfullscreen="""" scrolling=""no""
 allow=""accelerometer *; clipboard-write *; encrypted-media *; gyroscope *; picture-in-picture *;""></iframe>
 </div>
 
 In the above clip, you will see:
 
 1. In the flow from the [tutorials](../getting-started/tutorials/) ([Episode
    1](../getting-started/tutorials/season-1-the-local-experience/episode01)), the
    `genre_movies` step calculates an artifact `movies`. We are going to demonstrate how
    this artifact can be inspected after the flow has executed;
 2. In a Jupyter notebook, you can list all the flows and select the latest run of the
    Episode 1 flow;
 3. Further, you can select the `genre_movies` step from this flow and inspect its value.
    As you can see, the value computed at that step is fully available via the [Client
    API](client) and this works for any completed step even steps that completed
    successfully in a failed run.
 
 For more details about the notebook API, see the [Client API](client).",H2,https://docs.metaflow.org/metaflow/debugging#inspecting-data-with-a-notebook,False,1630,258,https://docs.metaflow.org
511,Debugging your Flow code using an IDE,"If anything fails in your code, Metaflow prints out the normal Python stack trace
 showing the line of code that caused the error. Typically, this error message provides
 enough information so that you can fix the code using your favorite editor.
 
 Alternatively, you can use a built-in debugger available in many modern IDEs. Since
 Metaflow uses subprocesses to launch steps, the IDE may need some additional
 configuration to handle this properly. We detail the configuration for two popular IDEs
 here. Other IDEs may also work similarly - let us know and we can add information about
 your favorite tool.",H2,https://docs.metaflow.org/metaflow/debugging#debugging-your-flow-code-using-an-ide,False,610,100,https://docs.metaflow.org
512,Debugging with PyCharm,"The following steps will allow you to debug your Flow within PyCharm:
 
 1. In the ""Run"" menu, select ""Edit Configurations...""
 2. Create a new configuration with the following items:
    1. Set the ""Script path"" field to point to the absolute path of your Flow script
    2. Set the ""Parameters"" field to ""run""
    3. Set the ""Working directory"" field to the directory containing your Flow script
 3. You can now set your breakpoints as usual in your Flow code and select ""Debug"" from
    the ""Run"" menu.
 
 Note that since Metaflow may launch multiple steps in parallel, you may actually hit
 multiple breakpoints at the same time; you will be able to switch between those
 breakpoints using the dropdown menu (it will say ""MainThread""). You can also restrict
 Metaflow to only execute one step at a time by adding ""--max-workers 1"" to the
 ""Parameters"" field.",H3,https://docs.metaflow.org/metaflow/debugging#debugging-with-pycharm,False,862,157,https://docs.metaflow.org
513,Debugging with VSCode,"You can enable debugging of a Flow in VSCode by adjusting your project's configuration
 in `.vscode/launch.json`.
 
 Here is a recording of the end-to-end setup process:
 
 <ReactPlayer controls url=""https://www.youtube.com/watch?v=xWGxDeojqeM"" />
 
 The configuration file as illustrated in the recording is provided below. Make sure you
 are extra careful to update the json structure appropriately if you already have
 existing settings.
 
 ```javascript
 {
     ""version"": ""0.2.0"",
     ""configurations"": [
         {
             ""name"": ""Metaflow Debug"",
             ""type"": ""python"",
             ""request"": ""launch"",
             ""program"": ""${file}"",
             ""args"": [
                 ""run""
             ],
             ""env"": {
                 ""USERNAME"": ""hamel""
             },
             ""subProcess"": true,
             ""console"": ""integratedTerminal""
         }
     ]
 }
 ```
 
 You can now set breakpoints and then select ""Start Debugging"" from the ""Debug"" menu or
 command pallete as illustrated in the recording. Note that since Metaflow may launch
 multiple steps in parallel, you may actually hit multiple breakpoints at the same time;
 you will be able to switch between those breakpoints by selecting the proper function
 stack in the ""Call Stack"" window. You can also restrict Metaflow to only execute one
 step at a time by adding the values ""--max-workers"" and ""1"" to the ""args"" array in the
 configuration.",H3,https://docs.metaflow.org/metaflow/debugging#debugging-with-vscode,False,1443,365,https://docs.metaflow.org
514,Combining debugging with resume,"You can naturally combine the techniques described in this section with the ""resume""
 command described previously. Instead of passing ""run"" as the program argument, simply
 pass ""resume"".",H3,https://docs.metaflow.org/metaflow/debugging#combining-debugging-with-resume,False,188,27,https://docs.metaflow.org
515,Compatibility with Conda decorator,"The above instructions work even if you use [`@conda`
 decorators](/scaling/dependencies#managing-dependencies-with-conda-decorator) in your
 code; you need, however, to ensure that the `conda` binary is available in your `PATH`.
 The easiest way to do this is to set the `PATH` environment variable to properly include
 the path to the `conda` binary if it is in a non-standard location. In VSCode, you can
 simply add this value in the env section of launch.json and in PyCharm, the UI allows
 you to set environment variables.",H3,https://docs.metaflow.org/metaflow/debugging#compatibility-with-conda-decorator,False,529,81,https://docs.metaflow.org
516,Inspecting Flows and Results,"Metaflow provides a client API that is used to inspect results of past runs. It is
 particularly well suited to being used in notebooks.
 
 This document provides an overview of the client API. See the complete API in [the
 Client API reference page](/api/client).",H1,https://docs.metaflow.org/metaflow/client#inspecting-flows-and-results,False,264,44,https://docs.metaflow.org
517,Object hierarchy,"Note that all operations in the Client API are filtered by the current namespace, as
 explained in [Organizing Results](/scaling/tagging.md). If you do not get the results
 you expect, make sure you are in the correct namespace. The Client API consults the
 metadata service to gather results, so make sure that the client is properly configured
 to use the correct [metadata provider](/metaflow/client.md#metadata-provider).
 
 ![Object hierarchy](/assets/hierarchy.png)
 
 You can import any of the objects shown above directly from the metaflow package as
 follows (for example):
 
 ```python
 from metaflow import Run
 ```
 
 The root object, `Metaflow`, can be instantiated simply with
 
 ```python
 from metaflow import Metaflow
 mf = Metaflow()
 ```
 
 This is the entry point to all other objects. For instance, you can list all flows that
 have been run in the past with:
 
 ```python
 from metaflow import Metaflow
 print(Metaflow().flows)
 ```",H2,https://docs.metaflow.org/metaflow/client#object-hierarchy,False,954,143,https://docs.metaflow.org
518,Navigating the object hierarchy,"Every object listed above follows a consistent interface. All the operations below are
 available in all objects, not just the ones demonstrated.",H2,https://docs.metaflow.org/metaflow/client#navigating-the-object-hierarchy,False,145,22,https://docs.metaflow.org
519,Listing children,"You can list child objects of any parent object simply by iterating over the parent:
 
 ```python
 from metaflow import Flow
 flow = Flow('HelloFlow')
 runs = list(flow)
 ```
 
 Expectedly, this works too:
 
 ```python
 from metaflow import Flow
 flow = Flow('HelloFlow')
 for run in flow:
     print(run)
 ```",H3,https://docs.metaflow.org/metaflow/client#listing-children,False,310,52,https://docs.metaflow.org
520,Accessing a specific child,"You can access a specific child with square brackets, similar to a key lookup in a
 dictionary. Note that keys are always strings (even if they are numerical IDs):
 
 ```python
 from metaflow import Flow
 flow = Flow('HelloFlow')
 run = flow['2']
 ```",H3,https://docs.metaflow.org/metaflow/client#accessing-a-specific-child,False,251,42,https://docs.metaflow.org
521,Accessing a specific object by its address,"Besides navigating from the root downwards, you can instantiate every object directly
 with its fully qualified name, called `pathspec`. Note that also this operation is
 subject to the current namespace, as explained in [Organizing
 Results](/scaling/tagging.md); in short, you will not be able to access a Flow that is
 not the current namespace; the error message returned will make it clear whether an
 object exists and is not in the namespace or does not exist at all.
 
 You can instantiate, for example, a particular flow by its name:
 
 ```python
 from metaflow import Flow
 flow = Flow('HelloFlow')
 ```
 
 You can instantiate a particular run of a flow by its run id:
 
 ```python
 from metaflow import Run
 run = Run('HelloFlow/2')
 ```
 
 And every step in a run by its name:
 
 ```python
 from metaflow import Step
 step = Step('HelloFlow/2/start')
 ```",H3,https://docs.metaflow.org/metaflow/client#accessing-a-specific-object-by-its-address,False,867,142,https://docs.metaflow.org
522,Accessing data,"One of the most typical use cases of the client API is to access data artifacts produced
 by runs. Each data artifact is represented by a `DataArtifact` object whose parent is a
 `Task`.
 
 `DataArtifact` is a container object for the actual value. Besides the value,
 `DataArtifact` includes metadata about the artifact, such as its time of creation.
 
 Often you are only interested in the value of an artifact. For this typical use case we
 provide a convenience property `.data` in the `Task` object. The `.data` property
 returns a container which has all artifacts produced by the task as attributes.
 
 For instance, this the shortest way to access a value produced by a step in a run:
 
 ```python
 from metaflow import Step
 print(Step('DebugFlow/2/a').task.data.x)
 ```
 
 Here, we print the value of `self.x` in the step `a` of the run `2` of the flow
 `DebugFlow`.",H3,https://docs.metaflow.org/metaflow/client#accessing-data,False,876,147,https://docs.metaflow.org
523,"Adding, removing, and replacing tags","*New in Metaflow 2.7.1: You need to upgrade your Metaflow library and the metadata
 service to benefit from this feature.*
 
 Every run has [a set of tags](/scaling/tagging.md#tagging) attached, that is,
 user-defined annotations. You can add and remove tags as follows:
 
 ```python
 from metaflow import Run
 run = Run('HelloFlow/2')
 run.add_tag('one_tag') # add one tag
 run.add_tags(['another_tag', 'yet_another', 'one_tag']) # add many tags
 print(run.user_tags)
 ```
 
 This will print `one_tag`, `another_tag`, `yet_another`. Note that `one_tag` is added
 twice but since tags are a set, duplicates are ignored.
 
 Removing works symmetrically:
 ```python
 from metaflow import Run
 run = Run('HelloFlow/2')
 run.remove_tag('one_tag') # remove one tag
 run.remove_tags(['another_tag', 'yet_another']) # remove many tags
 ```
 
 You can also replace tags with other tags:
 
 ```python
 from metaflow import Run
 run = Run('HelloFlow/2')
 run.replace_tag('one_tag', 'better_tag')
 run.replace_tags(['yet_another', 'another_tag'], ['better_tag'])
 ```
 
 The replace calls first removes the tags specified as the first argument and then adds
 the tag(s) in the second argument. Crucially, this is guaranteed to be an *atomic
 operation*: If another party lists the tags while replace is running, they won't see a
 partial state between remove and adds.
 
 Note you can perform these operations also on the command line using the `tag` command,
 for instance:
 ```
 python helloflow.py tag add --run-id 2 one_tag
 ```",H3,https://docs.metaflow.org/metaflow/client#adding-removing-and-replacing-tags,False,1521,212,https://docs.metaflow.org
524,System tags,"In addition to user-defined tags, Metaflow assigns a handful of *system tags* to runs
 automatically. These tags can be used for filtering and organizing runs, but they can
 not be removed or replaced with other tags.
 
 You can see the set of system tags assigned to a run like this:
 ```python
 from metaflow import Run
 print(Run('HelloFlow/2').system_tags)
 ```
 
 Or the union of system tags and user-defined tags like this:
 ```python
 from metaflow import Run
 print(Run('HelloFlow/2').tags)
 ```",H4,https://docs.metaflow.org/metaflow/client#system-tags,False,503,77,https://docs.metaflow.org
526,Properties related to flows,"To access an iterator over runs and filter by tags, use the `runs()` method. See
 [Tagging](/scaling/tagging.md#tagging) for more detail.
 
 `Flow` has two additional properties related to determining the latest run for the flow.
 Note that any `Run` returned will be in the current namespace.",H3,https://docs.metaflow.org/metaflow/client#properties-related-to-flows,False,293,45,https://docs.metaflow.org
527,Properties related to runs,"To access an iterator over the steps of a run and filter by tags, use the `steps()`
 method. See [Tagging](/scaling/tagging.md#tagging) for more detail.
 
 `Run` also has a few additional properties to make it easy to access commonly used
 information:",H3,https://docs.metaflow.org/metaflow/client#properties-related-to-runs,False,252,40,https://docs.metaflow.org
528,Properties related to steps,"A `Step` typically has a single `Task`. A Step will have multiple `Task` objects as its
 children if it is a `foreach` step; each `Task` will correspond to a single execution of
 the `Step`.
 
 To access an iterator over the tasks of a step and filter by tags, use the `tasks()`
 method. See [Tagging](/scaling/tagging.md#tagging) for more detail.
 
 `Step` has a few additional properties as well:",H3,https://docs.metaflow.org/metaflow/client#properties-related-to-steps,False,398,67,https://docs.metaflow.org
529,Properties related to tasks,"Since a `Task` is the actual unit of execution in Metaflow, these objects contain the
 richest set of properties:",H3,https://docs.metaflow.org/metaflow/client#properties-related-to-tasks,False,113,19,https://docs.metaflow.org
530,Metadata provider,"The Client API relies on a metadata service to gather results appropriately. Metaflow
 supports a local mode (`.metaflow` directory on your filesystem) and a [remote
 mode](https://github.com/Netflix/metaflow-service).
 
 ```python
 from metaflow import get_metadata, metadata",H2,https://docs.metaflow.org/metaflow/client#metadata-provider,False,276,33,https://docs.metaflow.org
531,Effortless Task Inspection with Default Cards,"Metaflow comes with a built-in _Default Card_ that shows all artifacts produced by a
 task. Let’s create a simple flow to test it.
 
 ```python
 from metaflow import FlowSpec, Parameter, step, card
 from datetime import datetime
 
 class DefaultCardFlow(FlowSpec):
 
     alpha = Parameter('alpha', default=0.5)
 
     @card
     @step
     def start(self):
         self.example_dict = {'first_key': list(range(10)),
                              'second_key': {'one', 'two'}}
         self.timestamp = datetime.utcnow()
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == ""__main__"":
     DefaultCardFlow()
 ```
 
 The only new feature introduced in this flow is the `@card` decorator which attaches a
 card to the `start` step. Since no arguments are given to the decorator, the _Default
 Card_ is used. Save the example in `defaultcard.py` and execute the flow as usual:
 
 `python defaultcard.py run`
 
 After the run has finished, you can open a generated card on the command line:
 
 `python defaultcard.py card view start`
 
 The command will open the card in your local web browser. It will look like this:
 
 ![](/assets/card-docs-defaultcard.png)
 
 The _Default Card_ shows basic metadata about the task, parameters given for the flow,
 artifacts accessible in the task, as well as a visualization of the flow DAG. You can
 use this information to quickly observe and verify results of a task without making any
 changes in the code.",H1,https://docs.metaflow.org/metaflow/visualizing-results/effortless-task-inspection-with-default-cards#effortless-task-inspection-with-default-cards,False,1487,301,https://docs.metaflow.org
532,**Visualizing Artifacts with the Default Card**,"As shown in the screenshot above, the artifacts table shows all Metaflow artifacts
 related to the task. Large artifacts are truncated for display - you can access the
 originals using [the Client API](../client).
 
 If an artifact contains an image or a dataframe, the artifact is visualized in a
 separate section in addition to its string representation. Take a look at the following
 example which contains an artifact, `self.image` storing an animated GIF and another
 artifact, a Pandas `dataframe`:
 
 ```python
 from metaflow import FlowSpec, Parameter, step
 import requests, pandas, string
 
 URL = ""https://upload.wikimedia.org/wikipedia/commons/4/45/Blue_Marble_rotating.gif""
 
 class FancyDefaultCardFlow(FlowSpec):
 
     image_url = Parameter('image_url', default=URL)
 
     @step
     def start(self):
         self.image = requests.get(self.image_url,
                                   headers={'user-agent': 'metaflow-example'}).content
         self.dataframe = pandas.DataFrame({'lowercase': list(string.ascii_lowercase),
                                            'uppercase': list(string.ascii_uppercase)})
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == ""__main__"":
     FancyDefaultCardFlow()
 ```
 
 To demonstrate how cards can be attached to runs on the fly, this example doesn’t
 include the `@card` decorator in the code. Save the code to `fancydefaultcard.py` and
 run it as follows:
 
 `python fancydefaultcard.py run --with card`
 
 Note that the example expects that you have the `requests` and `pandas` libraries
 installed. The `--with card` option attaches a `@card` decorator to every step without
 changes in the code. You can execute any existing flow `--with card` to inspect its
 results visually.
 
 You can open the card as before:
 
 `python fancydefaultcard.py card view start`
 
 You will see additional sections in the card which visualize `dataframe` as a table and
 show the image stored in the `image` artifact.
 
 ![](/assets/card-docs-fancydefaultcard.png)
 
 Thanks to this feature, you can use any plotting library such as
 [Matplotlib](https://matplotlib.org) to create arbitrary visualizations in a Metaflow
 task, which are then shown in the _Default Card_ automatically without you having to
 write a line of additional code. You can use this feature during development to quickly
 debug flows.",H2,https://docs.metaflow.org/metaflow/visualizing-results/effortless-task-inspection-with-default-cards#visualizing-artifacts-with-the-default-card,False,2401,439,https://docs.metaflow.org
533,Cards Are Stored And Versioned Automatically,"A major benefit of `@card` is that reports produced by it are versioned and stored in
 the Metaflow datastore automatically, alongside their parent task. This way, you or your
 colleagues can easily access any historical card, e.g. a model scorecard associated with
 a particular version of the model.
 
 You can access any historical card on the command line by using a run ID of a past run.
 For instance
 
 `python fancydefaultcard.py card view 1638257165470922/start`
 
 In the case of [foreach](../basics#foreach), a single step can produce multiple tasks
 and cards. You can view an individual card by giving a full task ID (aka _pathspec_)
 corresponding to a task:
 
 `python fancydefaultcard.py card view 1638257165470922/start/1`
 
 You can see all available cards in the latest run with the “`card list`” command:
 
 `python fancydefaultcard.py card list`
 
 It is possible to produce multiple separate cards from a single task by adding multiple
 `@card` decorators in a step, which are all shown by “`card list`”. To make it easier to
 identify specific cards, you can also assign them a unique ID, as described in [Multiple
 Cards In a Step](easy-custom-reports-with-card-components#multiple-cards-in-a-step).",H2,https://docs.metaflow.org/metaflow/visualizing-results/effortless-task-inspection-with-default-cards#cards-are-stored-and-versioned-automatically,False,1223,188,https://docs.metaflow.org
534,Accessing Cards via an API,"Besides the command line interface, you can access and view cards programmatically
 through an API. This is particularly convenient, if you want to access cards in a
 Jupyter notebook.
 
 Given a Task ID (a _pathspec_), or [a Task object from the Client API](../client), the
 `get_cards` function lists all cards of the task. You can try this in a notebook cell.
 Replace the Task ID with an actual ID from a previous run:
 
 ```python
 from metaflow.cards import get_cards
 get_cards('CountryModelFlow/1641937201798104/train_country_model/2')
 ```
 
 This will show the card in the output cell:
 
 ![](/assets/card-docs-notebook.png)
 
 The `get_cards` function works well in conjunction with [the Client API](../client). For
 instance, you can use the Client API to search for a task with a specific artifact and
 view its card:
 
 ```python
 run = Run('CountryModelFlow/1641937201798104')
 [brazil] = [task for task in run['train_country_model']
             if task['country'].data == 'Brazil']
 get_cards(brazil)
 ```
 
 ![](/assets/card-docs-clientapi.png)",H2,https://docs.metaflow.org/metaflow/visualizing-results/effortless-task-inspection-with-default-cards#accessing-cards-via-an-api,False,1062,158,https://docs.metaflow.org
535,Sharing Cards,"Since cards are self-contained HTML files, they can be easily shared and viewed by
 anyone without having to install additional software. To share a card, first save the
 desired card to a file:
 
 `python fancydefaultcard.py card get start mycard.html`
 
 Use the “`card get`” command to save the HTML without opening it in a browser. You can
 attach the resulting card file, here `mycard.html`, say, in an email or a Slack message.
 If you want to share reports automatically e.g. via email, you can use the `get_cards`
 API discussed above to obtain the HTML programmatically.
 
 Some recipients may prefer a PDF file over HTML. In this case, you can simply choose
 “Print” in your browser followed by “Save as PDF”.",H2,https://docs.metaflow.org/metaflow/visualizing-results/effortless-task-inspection-with-default-cards#sharing-cards,False,719,122,https://docs.metaflow.org
536,Easy Custom Reports with Card Components,"_Default Cards_ are useful during development when you need to quickly inspect artifacts
 produced by a task or visualize the overall structure of the flow. As your project
 progresses, you may want to create a custom card that highlights information specific to
 your project.
 
 The easiest way to create a custom card is to use built-in components: _Images_,
 _Tables_, _Artifacts_, and _Markdown_ text. You can construct a report with these
 components in Python without having to worry about HTML or styling in CSS. Rest assured
 that if components ever show their limits, you have an option to customize reports even
 further using [_Card Templates_](advanced-shareable-cards-with-card-templates).
 
 Let’s start with a simple example:
 
 ```python
 from metaflow import FlowSpec, step, card, Parameter, current
 from metaflow.cards import Markdown
 
 class GuessCardFlow(FlowSpec):
 
     number = Parameter('number', default=3)
 
     @card(type='blank')
     @step
     def start(self):
         current.card.append(Markdown(""# Guess my number""))
         if self.number > 5:
             current.card.append(Markdown(""My number is **smaller** ⬇️""))
         elif self.number < 5:
             current.card.append(Markdown(""My number is **larger** ⬆️""))
         else:
             current.card.append(Markdown(""## Correct! 🎉""))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == ""__main__"":
     GuessCardFlow()
 ```
 
 Notice how in the `@card` decorator we specify `type=’blank’.` Instead of the _Default
 Card_, we want an empty card with no content by default. The `blank` card provides a
 nice empty canvas for custom components.
 
 The `current.card.append` call adds a component in the card. Each component occupies a
 row in the card, so you don’t have to worry about the layout. If you run
 `GuessCardFlow`, you will see a card like below. The exact content depends on the value
 of the number parameter.
 
 ![](/assets/card-docs-guess.png)
 
 Currently, the following components are provided:",H1,https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#easy-custom-reports-with-card-components,False,2055,384,https://docs.metaflow.org
537,Showing Plots,"A data scientist may care more about showing data visualizations rather than photos of
 cats. Technically there isn’t a huge difference: You can use any existing visualization
 library in Python to produce plots, save the resulting image in a file or an in-memory
 object, and provide the contents of the file (bytes) to the `Image` component.
 
 For convenience, the `Image` component provides a utility method,
 `Image.from_matplotlib`, that extracts bytes from a [Matplotlib](https://matplotlib.org)
 figure automatically. Here’s an example that uses the [@conda
 decorator](/scaling/dependencies) to make sure that Matplotlib is available. If you have
 Matplotlib and Numpy already installed in your environment, you can run the example
 without `@conda_base`.
 
 ```python
 from metaflow import FlowSpec, step, current, card, conda_base
 from metaflow.cards import Image
 
 @conda_base(python='3.8.1',
             libraries={'numpy':'1.20.3', 'matplotlib':'3.4.2'})
 class PlotDemoFlow(FlowSpec):
 
     @card(type='blank')
     @step
     def start(self):
         import matplotlib.pyplot as plt
         import numpy
         fig = plt.figure()
         x = numpy.random.normal(0, 0.1, 100000)
         y = numpy.random.normal(0, 0.1, 100000)
         plt.scatter(x, y, s=0.1, color=(0.2, 0.2, 1.0, 0.2))
         current.card.append(Image.from_matplotlib(fig))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     PlotDemoFlow()
 ```
 
 The resulting card will look like this:
 
 ![](/assets/card-docs-plot.png)
 
 Note that you can click the image in the card to see a larger version of it.",H2,https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#showing-plots,False,1659,309,https://docs.metaflow.org
538,Multiple Cards In a Step,"You may want to produce multiple separate cards in a step. Maybe one card shows
 high-level business metrics that are suitable for wide distribution, while another shows
 technical details for debugging purposes.
 
 When multiple cards are present, calling `current.card.append` is ambiguous: As such, it
 doesn’t know which of the many cards the component should be added to. Metaflow will
 show a warning if you try to do this, but it won’t crash the flow - nothing card-related
 should ever cause the flow to crash.
 
 Use the id keyword argument in the `@card` decorator to uniquely identify each card.
 Then, you can refer to a specific card with the `current.card[card_id].append` notation.
 Here’s an example:
 
 ```python
 from metaflow import FlowSpec, step, current, card
 from metaflow.cards import Markdown
 
 class ManyCardsFlow(FlowSpec):
 
     @card(type='blank', id='first')
     @card(type='blank', id='second')
     @step
     def start(self):
         current.card['first'].append(
             Markdown('# I am the first card'))
         current.card['second'].append(
             Markdown('# I am the second card'))
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == '__main__':
     ManyCardsFlow()
 ```
 
 When a task has multiple cards, the “`card view`” command will list all cards that are
 viewable for the task. You must specify which exact card you want to view:",H2,https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#multiple-cards-in-a-step,False,1436,281,https://docs.metaflow.org
539,Comparing Data Across Runs,"In many cases, you may want to produce a single card that characterizes the results of
 the whole flow. A natural way to do this is to assign a card to the `end` step that has
 access to all results produced by a run.
 
 Besides accessing all results of a single run, you may want to access results across
 multiple runs and produce a card that compares the latest data to past results. Thanks
 to the fact that Metaflow persists and versions all results, this can be done easily:
 Just use [the Client API](../client) to access past results.
 
 The following example demonstrates how you can create a card that accesses all data
 produced by a flow at the `end` step, as well as compares results across historical
 runs.
 
 ```python
 from metaflow import FlowSpec, step, current, card, conda_base, Flow, Parameter
 from metaflow.cards import Image, Table, Artifact
 from itertools import islice
 
 @conda_base(python='3.8.1',
             libraries={'numpy':'1.20.3', 'matplotlib':'3.4.2'})
 class CompareRunsFlow(FlowSpec):
 
     alpha = Parameter('alpha', default=0.1)
 
     @step
     def start(self):
         import numpy as np
         self.x = np.linspace(-1, 2, 100)
         self.y = self.alpha * np.exp(self.x)
         self.next(self.end)
 
     @card(type='blank')
     @step
     def end(self):
         self.compare_runs()
 
     def compare_runs(self):
         import matplotlib.pyplot as plt
         rows = []
         fig = plt.figure()
         for run in islice(Flow('CompareRunsFlow'), 3):
             data = run['start'].task.data
             rows.append(list(map(Artifact, (run.id,
                                             run.created_at,
                                             data.alpha))))
             plt.plot(data.x, data.y, label=run.id)
         plt.legend()
         current.card.append(Table(rows,\
             headers=['Run ID', 'Created', 'Alpha']))
         current.card.append(Image.from_matplotlib(fig))
 
 if __name__ == '__main__':
     CompareRunsFlow()
 ```
 
 To see the comparison in action, run the flow at least three times with varying values
 of the `–alpha` parameter. Note the following features of the flow:",H2,https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#comparing-data-across-runs,False,2176,534,https://docs.metaflow.org
540,"Advanced, Shareable Cards with Card Templates","The built-in [_Card Components_](easy-custom-reports-with-card-components) allow you to
 create a visual report with a few lines of Python code. This is by far the easiest way
 to output visualizations using Metaflow’s default visual style and layout.
 
 This section describes a more advanced concept of _Card Templates_ which are more
 flexible than [_Default Cards_](effortless-task-inspection-with-default-cards) and Card
 Components, but they require more upfront effort to create. However, using an existing
 Card Template is very easy, as shown below. They are a good match for use cases such as",H1,https://docs.metaflow.org/metaflow/visualizing-results/advanced-shareable-cards-with-card-templates#advanced-shareable-cards-with-card-templates,False,602,86,https://docs.metaflow.org
541,Using a Card Template,"A _Card Template_ is a normal Python package, hosted in a Git repository of its own,
 optionally published to a private or public package repository. By convention, public
 Card Templates have a `metaflow-card` prefix, so you can easily [find public card
 templates on PyPi](https://pypi.org/search/?q=metaflow-card-&o=).
 
 Let’s test a public template,
 [metaflow-card-html](https://github.com/outerbounds/metaflow-card-html), which simply
 converts HTML stored in an artifact to a card. First, install the template using `pip`:
 
 `pip install metaflow-card-html`
 
 Now we can use the card in any flow by adding a decorator, `@card(type=’html’)`. The
 type attribute refers to the template name. Let’s test it:
 
 ```python
 from metaflow import FlowSpec, step, card
 
 class HtmlCardFlow(FlowSpec):
 
     @card(type='html')
     @step
     def start(self):
         self.html = """"""
         <html>
           <body style='color: blue'>
             Hello World!
           </body>
         </html>
         """"""
         self.next(self.end)
 
     @step
     def end(self):
         pass
 
 if __name__ == ""__main__"":
     HtmlCardFlow()
 ```
 
 Note that this a just a simple example what a custom template can do. Other custom
 templates don't require writing HTML by hand. Save the flow in `htmlcardflow.py`. Then,
 you can run it
 
 `python htmlcardflow.py run`
 
 and view the card
 
 `python htmlcardflow.py card view start`
 
 You should see a blank page with a blue “Hello World!” text.
 
 ![](</assets/card-docs-html_(2).png>)
 
 A particularly useful feature of card templates is that they work in any compute
 environment, even when [executing tasks remotely](/scaling/remote-tasks/introduction).
 For instance, if you have AWS Batch set up, you can run the flow as follows:
 
 `python htmlcardflow.py run --with batch`
 
 The card will get produced without you having to worry about installing anything on the
 remote instances! You can [deploy flows to
 production](../../production/scheduling-metaflow-flows/introduction/) with custom
 templates too:
 
 `python htmlcardflow.py step-functions create`
 
 Now, every time a production run executes, cards will get produced exactly as during
 prototyping. Behind the scenes, Metaflow takes care of packaging any card templates
 whenever you execute code remotely.",H2,https://docs.metaflow.org/metaflow/visualizing-results/advanced-shareable-cards-with-card-templates#using-a-card-template,False,2329,415,https://docs.metaflow.org
542,Developing a Card Template,"If you want to develop a card template of your own, it is useful to have a mental model
 of how cards work under the hood:
 
 ![](</assets/card-docs-template_(1).png>)
 
 The blue box is a Metaflow task executing a step from the user’s flow. It is decorated
 with a `@card` decorator that has a `type` attribute referring to your custom template,
 e.g. `mycard`. The task executes before the card template. After the task has finished,
 a new subprocess is started that executes a card template. This ensures that even if the
 template fails for any reason, it won’t crash the task.
 
 The card template is given the Task ID of the task that the card corresponds to. Using
 this Task ID, the template can use [the Client API](../client) to query any information
 about the task, its parent run, and any past runs. Using this information, the template
 needs to output a single stand-alone HTML file - the actual card. Note that the HTML
 file can’t depend on any other local files. In particular, you must include any images
 as [Data URIs](https://css-tricks.com/data-uris/) in the file itself.
 
 The template itself is a Python class, derived from _MetaflowCard_, which needs to
 implement one method, _render_, which is given [a Task object from the Client
 API](../client) - see [the `MetaflowCard` API
 reference](/api/cards#defining-a-custom-card) for details.
 
 This is the complete implementation of the `@card(type='html')` which we used above:
 
 ```python
 from metaflow.cards import MetaflowCard
 
 class HTMLCard(MetaflowCard):
 
     type = 'html'
 
     def __init__(self, options={""artifact"":""html""}, **kwargs):
         self._attr_nm = options.get(""artifact"", ""html"")
 
     def render(self, task):
         if self._attr_nm in task:
             return str(task[self._attr_nm].data)
 
 CARDS = [HTMLCard]
 ```
 
 The example above used the default `self.html` artifact to pass HTML code to the
 template. You can choose another artifact by specifying an artifact name in the
 _options_ dictionary that is passed to the template: `@card(type='html',
 options={'artifact': 'other_html')`.
 
 The _render_ method needs to return a self-contained HTML as a string. This template has
 it easy, since all it has to do is to return the user-defined artifact. Other templates
 can do much more complex processing to produce a suitable HTML page.
 
 To implement and publish a template of your own, take a look at the
 [metaflow-card-html](https://github.com/outerbounds/metaflow-card-html/) repository
 which shows how to structure the package, as well as step-by-step instructions on how to
 create one of your own. If you create a Card Template that other people might benefit
 from, let our [Slack community](http://slack.outerbounds.co) know about it!",H2,https://docs.metaflow.org/metaflow/visualizing-results/advanced-shareable-cards-with-card-templates#developing-a-card-template,False,2767,450,https://docs.metaflow.org
543,Managing Dependencies in Card Templates.,"Card templates may rely on 3rd party libraries for their functionality, say, to produce
 advanced visualizations. To make sure the card can be rendered in remote environments
 that might not have all dependencies already installed, Metaflow takes care of packaging
 any files included directly in the template itself. However, it can’t handle 3rd party
 dependencies automatically. Hence, to make sure your template works without friction,
 you need to pay attention to its dependencies.
 
 Here are recommended strategies for handling 3rd party library dependencies in card
 templates:
 
 1. You can rely on Javascript libraries to move functionality to the frontend side. For
    instance, instead of producing visualizations in Python, you can produce them in
    Javascript. Take a look at
    [metaflow-card-uplot-timeseries](https://github.com/outerbounds/metaflow-card-uplot-timeseries)
    template to see how to use a Javascript library in your template.
 2. You can include small Python libraries in the template package itself, aka _vendor_
    them.
 
 If these approaches don’t work, you can instruct users to include the dependencies of
 the template in their [@conda libraries](/scaling/dependencies). For templates shared
 privately, you may also rely on dependencies included in a Docker image shared by all
 users and `@batch` executions.",H4,https://docs.metaflow.org/metaflow/visualizing-results/advanced-shareable-cards-with-card-templates#managing-dependencies-in-card-templates,False,1356,206,https://docs.metaflow.org
545,Generating the documentation,"To generate the documentation, you first have to build it. Several packages are necessary to build the doc, 
 you can install them with the following command, at the root of the code repository:
 
 ```bash
 pip install -e "".[docs]""
 ```
 
 Then you need to install our special tool that builds the documentation:
 
 ```bash
 pip install git+https://github.com/huggingface/doc-builder
 ```
 
 **NOTE**
 
 You only need to generate the documentation to inspect it locally (if you're planning changes and want to
 check how they look before committing for instance). You don't have to commit the built documentation.",H1,https://huggingface.co/docs/accelerate/README#generating-the-documentation,False,613,97,https://huggingface.co
546,Building the documentation,"Once you have setup the `doc-builder` and additional packages, you can generate the documentation by 
 typing the following command:
 
 ```bash
 doc-builder build accelerate docs/source/ --build_dir ~/tmp/test-build
 ```
 
 You can adapt the `--build_dir` to set any temporary folder that you prefer. This command will create it and generate
 the MDX files that will be rendered as the documentation on the main website. You can inspect them in your favorite
 Markdown editor.",H2,https://huggingface.co/docs/accelerate/README#building-the-documentation,False,476,73,https://huggingface.co
547,Previewing the documentation,"To preview the docs, first install the `watchdog` module with:
 
 ```bash
 pip install watchdog
 ```
 
 Then run the following command:
 
 ```bash
 doc-builder preview {package_name} {path_to_docs}
 ```
 
 For example:
 
 ```bash
 doc-builder preview accelerate docs/source/
 ```
 
 The docs will be viewable at [http://localhost:3000](http://localhost:3000). You can also preview the docs once you have opened a PR. You will see a bot add a comment to a link where the documentation with your changes lives.
 
 **NOTE**
 
 The `preview` command only works with existing doc files. When you add a completely new file, you need to update `_toctree.yml` & restart `preview` command (`ctrl-c` to stop it & call `doc-builder preview ...` again).",H2,https://huggingface.co/docs/accelerate/README#previewing-the-documentation,False,741,115,https://huggingface.co
548,Adding a new element to the navigation bar,"Accepted files are Markdown (.md).
 
 Create a file with its extension and put it in the source directory. You can then link it to the toc-tree by putting
 the filename without the extension in the [`_toctree.yml`](https://github.com/huggingface/accelerate/blob/main/docs/source/_toctree.yml) file.",H2,https://huggingface.co/docs/accelerate/README#adding-a-new-element-to-the-navigation-bar,False,298,38,https://huggingface.co
549,Renaming section headers and moving sections,"It helps to keep the old links working when renaming the section header and/or moving sections from one document to another. This is because the old links are likely to be used in Issues, Forums, and Social media and it'd make for a much more superior user experience if users reading those months later could still easily navigate to the originally intended information.
 
 Therefore, we simply keep a little map of moved sections at the end of the document where the original section was. The key is to preserve the original anchor.
 
 So if you renamed a section from: ""Section A"" to ""Section B"", then you can add at the end of the file:
 
 ```
 Sections that were moved:
 
 [ <a href=""#section-b"">Section A</a><a id=""section-a""></a> ]
 ```
 and of course, if you moved it to another file, then:
 
 ```
 Sections that were moved:
 
 [ <a href=""../new-file#section-b"">Section A</a><a id=""section-a""></a> ]
 ```
 
 Use the relative style to link to the new file so that the versioned docs continue to work.",H2,https://huggingface.co/docs/accelerate/README#renaming-section-headers-and-moving-sections,False,1007,174,https://huggingface.co
550,Writing Documentation - Specification,"The `huggingface/accelerate` documentation follows the
 [Google documentation](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html) style for docstrings,
 although we can write them directly in Markdown.",H2,https://huggingface.co/docs/accelerate/README#writing-documentation-specification,False,227,18,https://huggingface.co
551,Adding a new tutorial,Adding a new tutorial or section is done in two steps:,H3,https://huggingface.co/docs/accelerate/README#adding-a-new-tutorial,False,54,11,https://huggingface.co
552,Writing source documentation,"Values that should be put in `code` should either be surrounded by backticks: \`like so\`. Note that argument names
 and objects like True, None, or any strings should usually be put in `code`.
 
 When mentioning a class, function, or method, it is recommended to use our syntax for internal links so that our tool
 adds a link to its documentation with this syntax: \[\`XXXClass\`\] or \[\`function\`\]. This requires the class or 
 function to be in the main package.
 
 If you want to create a link to some internal class or function, you need to
 provide its path. For instance: \[\`utils.gather\`\]. This will be converted into a link with
 `utils.gather` in the description. To get rid of the path and only keep the name of the object you are
 linking to in the description, add a ~: \[\`~utils.gather\`\] will generate a link with `gather` in the description.
 
 The same works for methods so you can either use \[\`XXXClass.method\`\] or \[~\`XXXClass.method\`\].",H3,https://huggingface.co/docs/accelerate/README#writing-source-documentation,False,971,163,https://huggingface.co
553,Defining arguments in a method,"Arguments should be defined with the `Args:` (or `Arguments:` or `Parameters:`) prefix, followed by a line return and
 an indentation. The argument should be followed by its type, with its shape if it is a tensor, a colon, and its
 description:
 
 ```
     Args:
         n_layers (`int`): The number of layers of the model.
 ```
 
 If the description is too long to fit in one line (more than 119 characters in total), another indentation is necessary 
 before writing the description after the argument.
 
 Finally, to maintain uniformity if any *one* description is too long to fit on one line, the 
 rest of the parameters should follow suit and have an indention before their description.
 
 Here's an example showcasing everything so far:
 
 ```
     Args:
         gradient_accumulation_steps (`int`, *optional*, default to 1):
             The number of steps that should pass before gradients are accumulated. A number > 1 should be combined with `Accelerator.accumulate`.
         cpu (`bool`, *optional*):
             Whether or not to force the script to execute on CPU. Will ignore GPU available if set to `True` and force the execution on one process only.
 ```
 
 For optional arguments or arguments with defaults we follow the following syntax: imagine we have a function with the
 following signature:
 
 ```
 def my_function(x: str = None, a: float = 1):
 ```
 
 then its documentation should look like this:
 
 ```
     Args:
         x (`str`, *optional*):
             This argument controls ... and has a description longer than 119 chars.
         a (`float`, *optional*, defaults to 1):
             This argument is used to ... and has a description longer than 119 chars.
 ```
 
 Note that we always omit the ""defaults to \`None\`"" when None is the default for any argument. Also note that even
 if the first line describing your argument type and its default gets long, you can't break it on several lines. You can
 however write as many lines as you want in the indented description (see the example above with `input_ids`).",H4,https://huggingface.co/docs/accelerate/README#defining-arguments-in-a-method,False,2053,428,https://huggingface.co
554,Writing a multi-line code block,"Multi-line code blocks can be useful for displaying examples. They are done between two lines of three backticks as usual in Markdown:
 
 
 ````
 ```python",H4,https://huggingface.co/docs/accelerate/README#writing-a-multi-line-code-block,False,155,26,https://huggingface.co
558,Writing a return block,"The return block should be introduced with the `Returns:` prefix, followed by a line return and an indentation.
 The first line should be the type of the return, followed by a line return. No need to indent further for the elements
 building the return.
 
 Here's an example of a single value return:
 
 ```
     Returns:
         `List[int]`: A list of integers in the range [0, 1] --- 1 for a special token, 0 for a sequence token.
 ```
 
 Here's an example of a tuple return, comprising several objects:
 
 ```
     Returns:
         `tuple(torch.FloatTensor)` comprising various elements depending on the configuration ([`BertConfig`]) and inputs:
         - ** loss** (*optional*, returned when `masked_lm_labels` is provided) `torch.FloatTensor` of shape `(1,)` --
           Total loss is the sum of the masked language modeling loss and the next sequence prediction (classification) loss.
         - **prediction_scores** (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) --
           Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).
 ```",H4,https://huggingface.co/docs/accelerate/README#writing-a-return-block,False,1129,219,https://huggingface.co
560,Writing documentation examples,"The syntax for Example docstrings can look as follows:
 
 ```
     Example:
 
     ```python
     >>> import time
     >>> from accelerate import Accelerator
     >>> accelerator = Accelerator()
     >>> if accelerator.is_main_process:
     ...     time.sleep(2)
     >>> else:
     ...     print(""I'm waiting for the main process to finish its sleep..."")
     >>> accelerator.wait_for_everyone()
     >>> # Should print on every process at the same time
     >>> print(""Everyone is here"")
     ```
 ```
 
 The docstring should give a minimal, clear example of how the respective function 
 is to be used in inference and also include the expected (ideally sensible)
 output.
 Often, readers will try out the example before even going through the function 
 or class definitions. Therefore, it is of utmost importance that the example 
 works as expected.",H2,https://huggingface.co/docs/accelerate/README#writing-documentation-examples,False,855,182,https://huggingface.co
562,Quick tour,Let's have a look at the 🤗 Accelerate main features and traps to avoid.,H1,https://huggingface.co/docs/accelerate/source/quicktour#quick-tour,False,71,14,https://huggingface.co
563,Main use,"To use 🤗 Accelerate in your own script, you have to change four things:
 
 1. Import the [`Accelerator`] main class and instantiate one in an `accelerator` object:
 
 ```python
 from accelerate import Accelerator
 
 accelerator = Accelerator()
 ```
 
 This should happen as early as possible in your training script as it will initialize everything necessary for
 distributed training. You don't need to indicate the kind of environment you are in (just one machine with a GPU, one
 machines with several GPUs, several machines with multiple GPUs or a TPU), the library will detect this automatically.
 
 2. Remove the call `.to(device)` or `.cuda()` for your model and input data. The `accelerator` object
 will handle this for you and place all those objects on the right device for you. If you know what you're doing, you
 can leave those `.to(device)` calls but you should use the device provided by the `accelerator` object:
 `accelerator.device`.
 
 To fully deactivate the automatic device placement, pass along `device_placement=False` when initializing your
 [`Accelerator`].
 
 <Tip warning={true}>
 
     If you place your objects manually on the proper device, be careful to create your optimizer after putting your
     model on `accelerator.device` or your training will fail on TPU.
 
 </Tip>
 
 3. Pass all objects relevant to training (optimizer, model, training dataloader, learning rate scheduler) to the
 [`~Accelerator.prepare`] method. This will make sure everything is ready for training.
 
 ```python
 model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
     model, optimizer, train_dataloader, lr_scheduler
 )
 ```
 
 In particular, your training dataloader will be sharded across all GPUs/TPU cores available so that each one sees a
 different portion of the training dataset. Also, the random states of all processes will be synchronized at the
 beginning of each iteration through your dataloader, to make sure the data is shuffled the same way (if you decided to
 use `shuffle=True` or any kind of random sampler).
 
 <Tip>
 
     The actual batch size for your training will be the number of devices used multiplied by the batch size you set in
     your script: for instance training on 4 GPUs with a batch size of 16 set when creating the training dataloader will
     train at an actual batch size of 64.
 
 </Tip>
 
 Alternatively, you can use the option `split_batches=True` when creating and initializing your
 [`Accelerator`], in which case the batch size will always stay the same, whether you run your
 script on 1, 2, 4, or 64 GPUs.
 
 You should execute this instruction as soon as all objects for training are created, before starting your actual
 training loop.
 
 <Tip warning={true}>
 
     You should only pass the learning rate scheduler to [`~Accelerator.prepare`] when the scheduler needs to be stepped
     at each optimizer step.
 
 </Tip>
 
 <Tip warning={true}>
 
     Your training dataloader may change length when going through this method: if you run on X GPUs, it will have its
     length divided by X (since your actual batch size will be multiplied by X), unless you set
     `split_batches=True`.
 
 </Tip>
 
 Any instruction using your training dataloader length (for instance if you want to log the number of total training
 steps) should go after the call to [`~Accelerator.prepare`].
 
 You can perfectly send your dataloader to [`~Accelerator.prepare`] on its own, but it's best to send the
 model and optimizer to [`~Accelerator.prepare`] together.
 
 You may or may not want to send your validation dataloader to [`~Accelerator.prepare`], depending on
 whether you want to run distributed evaluation or not (see below).
 
 4. Replace the line `loss.backward()` by `accelerator.backward(loss)`.
 
 And you're all set! With all these changes, your script will run on your local machine as well as on multiple GPUs or a
 TPU! You can either use your favorite tool to launch the distributed training, or you can use the 🤗 Accelerate
 launcher.",H2,https://huggingface.co/docs/accelerate/source/quicktour#main-use,False,4028,676,https://huggingface.co
564,Distributed evaluation,"You can perform regular evaluation in your training script, if you leave your validation dataloader out of the
 [`~Accelerator.prepare`] method. In this case, you will need to put the input data on the
 `accelerator.device` manually.
 
 To perform distributed evaluation, send along your validation dataloader to the [`~Accelerator.prepare`]
 method:
 
 ```python
 validation_dataloader = accelerator.prepare(validation_dataloader)
 ```
 
 As for your training dataloader, it will mean that (should you run your script on multiple devices) each device will
 only see part of the evaluation data. This means you will need to group your predictions together. This is very easy to
 do with the [`~Accelerator.gather_for_metrics`] method.
 
 ```python
 for inputs, targets in validation_dataloader:
     predictions = model(inputs)
     # Gather all predictions and targets
     all_predictions, all_targets = accelerator.gather_for_metrics((predictions, targets))
     # Example of use with a *Datasets.Metric*
     metric.add_batch(all_predictions, all_targets)
 ```
 
 <Tip warning={true}>
 
     Similar to the training dataloader, passing your validation dataloader through
     [`~Accelerator.prepare`] may change it: if you run on X GPUs, it will have its length divided by X
     (since your actual batch size will be multiplied by X), unless you set `split_batches=True`.
 
 </Tip>
 
 Any instruction using your training dataloader length (for instance if you need the number of total training steps
 to create a learning rate scheduler) should go after the call to [`~Accelerator.prepare`]. 
 
 Some data at the end of the dataset may be duplicated so the batch can be divided equally among all workers. As a result, metrics
 should be calculated through the [`~Accelerator.gather_for_metrics`] method to automatically remove the duplicated data while gathering.
 
 <Tip>
 
     If for some reason you don't wish to have this automatically done, [`~Accelerator.gather`] can be used instead to gather 
     the data across all processes and this can manually be done instead.
 
 </Tip>
 
 
 <Tip warning={true}>
 
     The [`~Accelerator.gather`] and [`~Accelerator.gather_for_metrics`] methods require the tensors to be all the same size on each process. If
     you have tensors of different sizes on each process (for instance when dynamically padding to the maximum length in
     a batch), you should use the [`~Accelerator.pad_across_processes`] method to pad you tensor to the
     biggest size across processes.
 
 </Tip>",H2,https://huggingface.co/docs/accelerate/source/quicktour#distributed-evaluation,False,2534,411,https://huggingface.co
565,Launching your distributed script,"You can use the regular commands to launch your distributed training (like `torch.distributed.run` for
 PyTorch), they are fully compatible with 🤗 Accelerate.
 
 🤗 Accelerate also provides a CLI tool that unifies all launchers, so you only have to remember one command. To use it,
 just run:
 
 ```bash
 accelerate config
 ```
 
 on your machine and reply to the questions asked. This will save a *default_config.yaml* file in your cache folder for
 🤗 Accelerate. That cache folder is (with decreasing order of priority):",H2,https://huggingface.co/docs/accelerate/source/quicktour#launching-your-distributed-script,False,521,84,https://huggingface.co
566,Launching training from a notebook,"In Accelerate 0.3.0, a new [`notebook_launcher`] has been introduced to help you launch your training
 function from a notebook. This launcher supports launching a training with TPUs on Colab or Kaggle, as well as training
 on several GPUs (if the machine on which you are running your notebook has them).
 
 Just define a function responsible for your whole training and/or evaluation in a cell of the notebook, then execute a
 cell with the following code:
 
 ```python
 from accelerate import notebook_launcher
 
 notebook_launcher(training_function)
 ```
 
 <Tip warning={true}>
 
     Your [`Accelerator`] object should only be defined inside the training function. This is because the
     initialization should be done inside the launcher only.
 
 </Tip>
 
 Check out the [Notebook Launcher tutorial](basic_tutorials/notebook) for more information about training on TPUs.",H2,https://huggingface.co/docs/accelerate/source/quicktour#launching-training-from-a-notebook,False,878,136,https://huggingface.co
567,Training on TPU,"If you want to launch your script on TPUs, there are a few caveats you should be aware of. Behind the scenes, the TPUs
 will create a graph of all the operations happening in your training step (forward pass, backward pass and optimizer
 step). This is why your first step of training will always be very long as building and compiling this graph for
 optimizations takes some time.
 
 The good news is that this compilation will be cached so the second step and all the following will be much faster. The
 bad news is that it only applies if all of your steps do exactly the same operations, which implies:",H2,https://huggingface.co/docs/accelerate/source/quicktour#training-on-tpu,False,607,111,https://huggingface.co
568,Other caveats,We list here all smaller issues you could have in your script conversion and how to resolve them.,H2,https://huggingface.co/docs/accelerate/source/quicktour#other-caveats,False,97,18,https://huggingface.co
569,Execute a statement only on one processes,"Some of your instructions only need to run for one process on a given server: for instance a data download or a log
 statement. To do this, wrap the statement in a test like this:
 
 ```python docstyle-ignore
 if accelerator.is_local_main_process:
     # Is executed once per server
 ```
 
 Another example is progress bars: to avoid having multiple progress bars in your output, you should only display one on
 the local main process:
 
 ```python
 from tqdm.auto import tqdm
 
 progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)
 ```
 
 The *local* means per machine: if you are running your training on two servers with several GPUs, the instruction will
 be executed once on each of those servers. If you need to execute something only once for all processes (and not per
 machine) for instance, uploading the final model to the 🤗 model hub, wrap it in a test like this:
 
 ```python docstyle-ignore
 if accelerator.is_main_process:
     # Is executed once only
 ```
 
 For printing statements you only want executed once per machine, you can just replace the `print` function by
 `accelerator.print`.",H3,https://huggingface.co/docs/accelerate/source/quicktour#execute-a-statement-only-on-one-processes,False,1150,186,https://huggingface.co
570,Defer execution,"When you run your usual script, instructions are executed in order. Using 🤗 Accelerate to deploy your script on several
 GPUs at the same time introduces a complication: while each process executes all instructions in order, some may be
 faster than others.
 
 You might need to wait for all processes to have reached a certain point before executing a given instruction. For
 instance, you shouldn't save a model before being sure every process is done with training. To do this, just write the
 following line in your code:
 
 ```
 accelerator.wait_for_everyone()
 ```
 
 This instruction will block all the processes that arrive first until all the other processes have reached that
 point (if you run your script on just one GPU or CPU, this won't do anything).",H3,https://huggingface.co/docs/accelerate/source/quicktour#defer-execution,False,765,128,https://huggingface.co
571,Saving/loading a model,"Saving the model you trained might need a bit of adjustment: first you should wait for all processes to reach that
 point in the script as shown above, and then, you should unwrap your model before saving it. This is because when going
 through the [`~Accelerator.prepare`] method, your model may have been placed inside a bigger model,
 which deals with the distributed training. This in turn means that saving your model state dictionary without taking
 any precaution will take that potential extra layer into account, and you will end up with weights you can't load back
 in your base model. The [`~Accelerator.save_model`] method will help you to achieve that. It will unwrap your model and save
 the model state dictionnary.
 
 Here is an example:
 ```
 accelerator.wait_for_everyone()
 accelerator.save_model(model, save_directory)
 ```
 The [`~Accelerator.save_model`] method can also save a model into sharded checkpoints or with safetensors format.
 Here is an example: 
 
 ```python
 accelerator.wait_for_everyone()
 accelerator.save_model(model, save_directory, max_shard_size=""1GB"", safe_serialization=True)
 ```
 
 If your script contains logic to load a checkpoint, we also recommend you load your weights in the unwrapped model
 (this is only useful if you use the load function after making your model go through
 [`~Accelerator.prepare`]). Here is an example:
 
 ```python
 unwrapped_model = accelerator.unwrap_model(model)
 path_to_checkpoint = os.path.join(save_directory,""pytorch_model.bin"")
 unwrapped_model.load_state_dict(torch.load(path_to_checkpoint))
 ```
 
 Note that since all the model parameters are references to tensors, this will load your weights inside `model`.
 
 If you want to load a sharded checkpoint or a checkpoint with safetensors format into the model with a specific `device`, we recommend you to load it with [`~utils.load_checkpoint_in_model`] function. Here's an example:
 
 ```python
 load_checkpoint_in_model(unwrapped_model, save_directory, device_map={"""":device})
 ```",H3,https://huggingface.co/docs/accelerate/source/quicktour#saving-loading-a-model,False,2021,269,https://huggingface.co
572,Saving/loading entire states,"When training your model, you may want to save the current state of the model, optimizer, random generators, and potentially LR schedulers to be restored in the _same script_.
 You can use [`~Accelerator.save_state`] and [`~Accelerator.load_state`] respectively to do so.
 
 To further customize where and how states saved through [`~Accelerator.save_state`] the [`~utils.ProjectConfiguration`] class can be used. For example 
 if `automatic_checkpoint_naming` is enabled each saved checkpoint will be located then at `Accelerator.project_dir/checkpoints/checkpoint_{checkpoint_number}`.
 
 If you have registered any other stateful items to be stored through [`~Accelerator.register_for_checkpointing`] they will also be saved and/or loaded.
 
 <Tip>
 
     Every object passed to [`~Accelerator.register_for_checkpointing`] must have a `load_state_dict` and `state_dict` function to be stored
 
 </Tip>",H2,https://huggingface.co/docs/accelerate/source/quicktour#saving-loading-entire-states,False,904,117,https://huggingface.co
573,Gradient clipping,"If you are using gradient clipping in your script, you should replace the calls to
 `torch.nn.utils.clip_grad_norm_` or `torch.nn.utils.clip_grad_value_` with [`~Accelerator.clip_grad_norm_`]
 and [`~Accelerator.clip_grad_value_`] respectively.",H3,https://huggingface.co/docs/accelerate/source/quicktour#gradient-clipping,False,244,23,https://huggingface.co
574,Mixed Precision training,"If you are running your training in Mixed Precision with 🤗 Accelerate, you will get the best result with your loss being
 computed inside your model (like in Transformer models for instance). Every computation outside of the model will be
 executed in full precision (which is generally what you want for loss computation, especially if it involves a
 softmax). However you might want to put your loss computation inside the [`~Accelerator.autocast`] context manager:
 
 ```
 with accelerator.autocast():
     loss = complex_loss_function(outputs, target):
 ```
 
 Another caveat with Mixed Precision training is that the gradient will skip a few updates at the beginning and
 sometimes during training: because of the dynamic loss scaling strategy, there are points during training where the
 gradients have overflown, and the loss scaling factor is reduced to avoid this happening again at the next step.
 
 This means that you may update your learning rate scheduler when there was no update, which is fine in general, but may
 have an impact when you have very little training data, or if the first learning rate values of your scheduler are very
 important. In this case, you can skip the learning rate scheduler updates when the optimizer step was not done like
 this:
 
 ```
 if not accelerator.optimizer_step_was_skipped:
     lr_scheduler.step()
 ```",H3,https://huggingface.co/docs/accelerate/source/quicktour#mixed-precision-training,False,1359,219,https://huggingface.co
575,Gradient Accumulation,"To perform gradient accumulation use [`~Accelerator.accumulate`] and specify a `gradient_accumulation_steps`. 
 This will also automatically ensure the gradients are synced or unsynced when on multi-device training, check if the step should
 actually be performed, and auto-scale the loss:
 
 ```python
 accelerator = Accelerator(gradient_accumulation_steps=2)
 model, optimizer, training_dataloader = accelerator.prepare(model, optimizer, training_dataloader)
 
 for input, label in training_dataloader:
     with accelerator.accumulate(model):
         predictions = model(input)
         loss = loss_function(predictions, label)
         accelerator.backward(loss)
         optimizer.step()
         scheduler.step()
         optimizer.zero_grad()
 ```",H3,https://huggingface.co/docs/accelerate/source/quicktour#gradient-accumulation,False,755,122,https://huggingface.co
576,DeepSpeed,"DeepSpeed support is experimental, so the underlying API will evolve in the near future and may have some slight
 breaking changes. In particular, 🤗 Accelerate does not support DeepSpeed config you have written yourself yet, this
 will be added in a next version.
 
 <Tip warning={true}>
 
     The [`notebook_launcher`] does not support the DeepSpeed integration yet.
 
 </Tip>",H3,https://huggingface.co/docs/accelerate/source/quicktour#deepspeed,False,378,62,https://huggingface.co
577,Internal mechanism,"Internally, the library works by first analyzing the environment in which the script is launched to determine which
 kind of distributed setup is used, how many different processes there are and which one the current script is in. All
 that information is stored in the [`~AcceleratorState`].
 
 This class is initialized the first time you instantiate an [`~Accelerator`] as well as performing any
 specific initialization your distributed setup needs. Its state is then uniquely shared through all instances of
 [`~state.AcceleratorState`].
 
 Then, when calling [`~Accelerator.prepare`], the library:",H2,https://huggingface.co/docs/accelerate/source/quicktour#internal-mechanism,False,603,87,https://huggingface.co
579,Accelerate,"🤗 Accelerate is a library that enables the same PyTorch code to be run across any distributed configuration by adding just four lines of code! In short, training and inference at scale made simple, efficient and adaptable.
 
 ```diff
 + from accelerate import Accelerator
 + accelerator = Accelerator()
 
 + model, optimizer, training_dataloader, scheduler = accelerator.prepare(
 +     model, optimizer, training_dataloader, scheduler
 + )
 
   for batch in training_dataloader:
       optimizer.zero_grad()
       inputs, targets = batch
       inputs = inputs.to(device)
       targets = targets.to(device)
       outputs = model(inputs)
       loss = loss_function(outputs, targets)
 +     accelerator.backward(loss)
       optimizer.step()
       scheduler.step()
 ```
 
 Built on `torch_xla` and `torch.distributed`, 🤗 Accelerate takes care of the heavy lifting, so you don't have to write any custom code to adapt to these platforms.
 Convert existing codebases to utilize [DeepSpeed](usage_guides/deepspeed), perform [fully sharded data parallelism](usage_guides/fsdp), and have automatic support for mixed-precision training! 
 
 <Tip> 
 
   To get a better idea of this process, make sure to check out the [Tutorials](basic_tutorials/overview)! 
 
 </Tip>
 
 
 This code can then be launched on any system through Accelerate's CLI interface:
 ```bash
 accelerate launch {my_script.py}
 ```
 
 <div class=""mt-10"">
   <div class=""w-full flex flex-col space-y-4 md:space-y-0 md:grid md:grid-cols-2 md:gap-y-4 md:gap-x-5"">
     <a class=""!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg"" href=""./basic_tutorials/overview""
       ><div class=""w-full text-center bg-gradient-to-br from-blue-400 to-blue-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed"">Tutorials</div>
       <p class=""text-gray-700"">Learn the basics and become familiar with using 🤗 Accelerate. Start here if you are using 🤗 Accelerate for the first time!</p>
     </a>
     <a class=""!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg"" href=""./usage_guides/explore""
       ><div class=""w-full text-center bg-gradient-to-br from-indigo-400 to-indigo-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed"">How-to guides</div>
       <p class=""text-gray-700"">Practical guides to help you achieve a specific goal. Take a look at these guides to learn how to use 🤗 Accelerate to solve real-world problems.</p>
     </a>
     <a class=""!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg"" href=""./concept_guides/gradient_synchronization""
       ><div class=""w-full text-center bg-gradient-to-br from-pink-400 to-pink-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed"">Conceptual guides</div>
       <p class=""text-gray-700"">High-level explanations for building a better understanding of important topics such as avoiding subtle nuances and pitfalls in distributed training and DeepSpeed.</p>
    </a>
     <a class=""!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg"" href=""./package_reference/accelerator""
       ><div class=""w-full text-center bg-gradient-to-br from-purple-400 to-purple-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed"">Reference</div>
       <p class=""text-gray-700"">Technical descriptions of how 🤗 Accelerate classes and methods work.</p>
     </a>
   </div>
 </div>",H1,https://huggingface.co/docs/accelerate/source/index#accelerate,False,3474,516,https://huggingface.co
581,Overview,"Welcome to the 🤗 Accelerate tutorials! These introductory guides will help catch you up to speed on working with 🤗 Accelerate.
 You'll learn how to modify your code to have it work with the API seamlessly, how to launch your script properly,
 and more!
 
 These tutorials assume some basic knowledge of Python and familiarity with the PyTorch framework.
 
 If you have any questions about 🤗 Accelerate, feel free to join and ask the community on our [forum](https://discuss.huggingface.co/c/accelerate/18).",H1,https://huggingface.co/docs/accelerate/source/basic_tutorials/overview#overview,False,506,79,https://huggingface.co
583,Launching your 🤗 Accelerate scripts,"In the previous tutorial, you were introduced to how to modify your current training script to use 🤗 Accelerate.
 The final version of that code is shown below:
 
 ```python
 from accelerate import Accelerator
 
 accelerator = Accelerator()
 
 model, optimizer, training_dataloader, scheduler = accelerator.prepare(
     model, optimizer, training_dataloader, scheduler
 )
 
 for batch in training_dataloader:
     optimizer.zero_grad()
     inputs, targets = batch
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     accelerator.backward(loss)
     optimizer.step()
     scheduler.step()
 ```
 
 But how do you run this code and have it utilize the special hardware available to it?
 
 First, you should rewrite the above code into a function, and make it callable as a script. For example:
 
 ```diff
   from accelerate import Accelerator
   
 + def main():
       accelerator = Accelerator()
 
       model, optimizer, training_dataloader, scheduler = accelerator.prepare(
           model, optimizer, training_dataloader, scheduler
       )
 
       for batch in training_dataloader:
           optimizer.zero_grad()
           inputs, targets = batch
           outputs = model(inputs)
           loss = loss_function(outputs, targets)
           accelerator.backward(loss)
           optimizer.step()
           scheduler.step()
 
 + if __name__ == ""__main__"":
 +     main()
 ```
 
 Next, you need to launch it with `accelerate launch`. 
 
 <Tip warning={true}>
 
   It's recommended you run `accelerate config` before using `accelerate launch` to configure your environment to your liking. 
   Otherwise 🤗 Accelerate will use very basic defaults depending on your system setup.
 
 </Tip>",H1,https://huggingface.co/docs/accelerate/source/basic_tutorials/launch#launching-your-accelerate-scripts,False,1720,359,https://huggingface.co
584,Using accelerate launch,"🤗 Accelerate has a special CLI command to help you launch your code in your system through `accelerate launch`.
 This command wraps around all of the different commands needed to launch your script on various platforms, without you having to remember what each of them is.
 
 <Tip>
 
   If you are familiar with launching scripts in PyTorch yourself such as with `torchrun`, you can still do this. It is not required to use `accelerate launch`.
 
 </Tip>
 
 You can launch your script quickly by using:
 
 ```bash
 accelerate launch {script_name.py} --arg1 --arg2 ...
 ```
 
 Just put `accelerate launch` at the start of your command, and pass in additional arguments and parameters to your script afterward like normal!
 
 Since this runs the various torch spawn methods, all of the expected environment variables can be modified here as well.
 For example, here is how to use `accelerate launch` with a single GPU:
 
 ```bash
 CUDA_VISIBLE_DEVICES=""0"" accelerate launch {script_name.py} --arg1 --arg2 ...
 ```
 
 You can also use `accelerate launch` without performing `accelerate config` first, but you may need to manually pass in the right configuration parameters.
 In this case, 🤗 Accelerate will make some hyperparameter decisions for you, e.g., if GPUs are available, it will use all of them by default without the mixed precision.
 Here is how you would use all GPUs and train with mixed precision disabled:
 
 ```bash
 accelerate launch --multi_gpu {script_name.py} {--arg1} {--arg2} ...
 ```
 
 Or by specifying a number of GPUs to use:
 
 ```bash
 accelerate launch --num_processes=2 {script_name.py} {--arg1} {--arg2} ...
 ```
 
 To get more specific you should pass in the needed parameters yourself. For instance, here is how you 
 would also launch that same script on two GPUs using mixed precision while avoiding all of the warnings: 
 
 ```bash
 accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 {script_name.py} {--arg1} {--arg2} ...
 ```
 
 For a complete list of parameters you can pass in, run:
 
 ```bash
 accelerate launch -h
 ```
 
 <Tip>
 
   Even if you are not using 🤗 Accelerate in your code, you can still use the launcher for starting your scripts!
 
 </Tip>
 
 For a visualization of this difference, that earlier `accelerate launch` on multi-gpu would look something like so with `torchrun`:
 
 ```bash
 MIXED_PRECISION=""fp16"" torchrun --nproc_per_node=2 --num_machines=1 {script_name.py} {--arg1} {--arg2} ...
 ```
 
 You can also launch your script utilizing the launch CLI as a python module itself, enabling the ability to pass in other python-specific
 launching behaviors. To do so, use `accelerate.commands.launch` instead of `accelerate launch`:
 
 ```bash
 python -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}
 ```
 
 If you want to execute the script with any other python flags, you can pass them in as well similar to `-m`, such as 
 the below example enabling unbuffered stdout and stderr:
 
 ```bash
 python -u -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/launch#using-accelerate-launch,False,3105,481,https://huggingface.co
585,Why you should always use `accelerate config`,"Why is it useful to the point you should **always** run `accelerate config`? 
 
 Remember that earlier call to `accelerate launch` as well as `torchrun`?
 Post configuration, to run that script with the needed parts you just need to use `accelerate launch` outright, without passing anything else in:
 
 ```bash
 accelerate launch {script_name.py} {--arg1} {--arg2} ...
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/launch#why-you-should-always-use-accelerate-config,False,374,58,https://huggingface.co
586,Custom Configurations,"As briefly mentioned earlier, `accelerate launch` should be mostly used through combining set configurations 
 made with the `accelerate config` command. These configs are saved to a `default_config.yaml` file in your cache folder for 🤗 Accelerate. 
 This cache folder is located at (with decreasing order of priority):",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/launch#custom-configurations,False,319,48,https://huggingface.co
588,Installation and Configuration,"Before you start, you will need to setup your environment, install the appropriate packages, and configure 🤗 Accelerate. 🤗 Accelerate is tested on **Python 3.8+**.",H1,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#installation-and-configuration,False,163,25,https://huggingface.co
589,Installing 🤗 Accelerate,"🤗 Accelerate is available on pypi and conda, as well as on GitHub. Details to install from each are below:",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#installing-accelerate,False,106,20,https://huggingface.co
590,pip,"To install 🤗 Accelerate from pypi, perform:
 
 ```bash
 pip install accelerate
 ```",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#pip,False,83,13,https://huggingface.co
591,conda,"🤗 Accelerate can also be installed with conda with:
 
 ```bash
 conda install -c conda-forge accelerate
 ```",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#conda,False,108,17,https://huggingface.co
592,Source,"New features are added every day that haven't been released yet. To try them out yourself, install
 from the GitHub repository:
 
 ```bash
 pip install git+https://github.com/huggingface/accelerate
 ```
 
 If you're working on contributing to the library or wish to play with the source code and see live 
 results as you run the code, an editable version can be installed from a locally-cloned version of the 
 repository:
 
 ```bash
 git clone https://github.com/huggingface/accelerate
 cd accelerate
 pip install -e .
 ```",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#source,False,525,80,https://huggingface.co
593,Configuring 🤗 Accelerate,"After installing, you need to configure 🤗 Accelerate for how the current system is setup for training. 
 To do so run the following and answer the questions prompted to you:
 
 ```bash
 accelerate config
 ```
 
 To write a barebones configuration that doesn't include options such as DeepSpeed configuration or running on TPUs, you can quickly run:
 
 ```bash
 python -c ""from accelerate.utils import write_basic_config; write_basic_config(mixed_precision='fp16')""
 ```
 🤗 Accelerate will automatically utilize the maximum number of GPUs available and set the mixed precision mode.
 
 To check that your configuration looks fine, run:
 
 ```bash
 accelerate env
 ```
 
 An example output is shown below, which describes two GPUs on a single machine with no mixed precision being used:",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/install#configuring-accelerate,False,784,120,https://huggingface.co
595,Migrating your code to 🤗 Accelerate,"This tutorial will detail how to easily convert existing PyTorch code to use 🤗 Accelerate!
 You'll see that by just changing a few lines of code, 🤗 Accelerate can perform its magic and get you on 
 your way toward running your code on distributed systems with ease!",H1,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#migrating-your-code-to-accelerate,False,265,48,https://huggingface.co
596,The base training loop,"To begin, write out a very basic PyTorch training loop. 
 
 <Tip>
 
     We are under the presumption that `training_dataloader`, `model`, `optimizer`, `scheduler`, and `loss_function` have been defined beforehand.
 
 </Tip>
 
 ```python
 device = ""cuda""
 model.to(device)
 
 for batch in training_dataloader:
     optimizer.zero_grad()
     inputs, targets = batch
     inputs = inputs.to(device)
     targets = targets.to(device)
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     loss.backward()
     optimizer.step()
     scheduler.step()
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#the-base-training-loop,False,574,105,https://huggingface.co
597,Add in 🤗 Accelerate,"To start using 🤗 Accelerate, first import and create an [`Accelerator`] instance:
 ```python
 from accelerate import Accelerator
 
 accelerator = Accelerator()
 ```
 [`Accelerator`] is the main force behind utilizing all the possible options for distributed training!",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#add-in-accelerate,False,267,36,https://huggingface.co
598,Setting the right device,"The [`Accelerator`] class knows the right device to move any PyTorch object to at any time, so you should
 change the definition of `device` to come from [`Accelerator`]:",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#setting-the-right-device,False,170,28,https://huggingface.co
599,Preparing your objects,"Next, you need to pass all of the important objects related to training into [`~Accelerator.prepare`]. 🤗 Accelerate will
 make sure everything is setup in the current environment for you to start training:
 
 ```
 model, optimizer, training_dataloader, scheduler = accelerator.prepare(
     model, optimizer, training_dataloader, scheduler
 )
 ```
 These objects are returned in the same order they were sent in. By default when using `device_placement=True`, all of the objects that can be sent to the right device will be.
 If you need to work with data that isn't passed to [~Accelerator.prepare] but should be on the active device, you should pass in the `device` you made earlier. 
 
 <Tip warning={true}>
 
     Accelerate will only prepare objects that inherit from their respective PyTorch classes (such as `torch.optim.Optimizer`).
 
 </Tip>",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#preparing-your-objects,False,850,135,https://huggingface.co
600,Modifying the training loop,"Finally, three lines of code need to be changed in the training loop. 🤗 Accelerate's DataLoader classes will automatically handle the device placement by default,
 and [`~Accelerator.backward`] should be used for performing the backward pass:",H3,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#modifying-the-training-loop,False,242,35,https://huggingface.co
601,The finished code,"Below is the final version of the converted code: 
 
 ```python
 from accelerate import Accelerator
 
 accelerator = Accelerator()
 
 model, optimizer, training_dataloader, scheduler = accelerator.prepare(
     model, optimizer, training_dataloader, scheduler
 )
 
 for batch in training_dataloader:
     optimizer.zero_grad()
     inputs, targets = batch
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     accelerator.backward(loss)
     optimizer.step()
     scheduler.step()
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#the-finished-code,False,509,85,https://huggingface.co
602,More Resources,"To check out more ways on how to migrate to 🤗 Accelerate, check out our [interactive migration tutorial](https://huggingface.co/docs/accelerate/usage_guides/explore) which showcases other items that need to be watched for when using Accelerate and how to do so quickly.",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/migration#more-resources,False,269,37,https://huggingface.co
604,Launching Multi-GPU Training from a Jupyter Environment,"This tutorial teaches you how to fine tune a computer vision model with 🤗 Accelerate from a Jupyter Notebook on a distributed system.
 You will also learn how to setup a few requirements needed for ensuring your environment is configured properly, your data has been prepared properly, and finally how to launch training.
 
 <Tip>
 
     This tutorial is also available as a Jupyter Notebook [here](https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb)
 
 </Tip>",H1,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#launching-multi-gpu-training-from-a-jupyter-environment,False,513,72,https://huggingface.co
605,Configuring the Environment,"Before any training can be performed, a 🤗 Accelerate config file must exist in the system. Usually this can be done by running the following in a terminal and answering the prompts:
 
 ```bash
 accelerate config
 ```
 
 However, if general defaults are fine and you are *not* running on a TPU, 🤗Accelerate has a utility to quickly write your GPU configuration into a config file via [`utils.write_basic_config`].
 
 The following code will restart Jupyter after writing the configuration, as CUDA code was called to perform this. 
 
 <Tip warning={true}>
 
     CUDA can't be initialized more than once on a multi-GPU system. It's fine to debug in the notebook and have calls to CUDA, but in order to finally train a full cleanup and restart will need to be performed.
     
 </Tip>
 
 ```python
 import os
 from accelerate.utils import write_basic_config
 
 write_basic_config()  # Write a config file
 os._exit(00)  # Restart the notebook
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#configuring-the-environment,False,945,164,https://huggingface.co
606,Preparing the Dataset and Model,"Next you should prepare your dataset. As mentioned at earlier, great care should be taken when preparing the `DataLoaders` and model to make sure that **nothing** is put on *any* GPU. 
 
 If you do, it is recommended to put that specific code into a function and call that from within the notebook launcher interface, which will be shown later. 
 
 Make sure the dataset is downloaded based on the directions [here](https://github.com/huggingface/accelerate/tree/main/examples#simple-vision-example)
 
 ```python
 import os, re, torch, PIL
 import numpy as np
 
 from torch.optim.lr_scheduler import OneCycleLR
 from torch.utils.data import DataLoader, Dataset
 from torchvision.transforms import Compose, RandomResizedCrop, Resize, ToTensor
 
 from accelerate import Accelerator
 from accelerate.utils import set_seed
 from timm import create_model
 ```
 
 First you need to create a function to extract the class name based on a filename:
 
 ```python
 import os
 
 data_dir = ""../../images""
 fnames = os.listdir(data_dir)
 fname = fnames[0]
 print(fname)
 ```
 
 ```python out
 beagle_32.jpg
 ```
 
 In the case here, the label is `beagle`. Using regex you can extract the label from the filename:
 
 ```python
 import re
 
 
 def extract_label(fname):
     stem = fname.split(os.path.sep)[-1]
     return re.search(r""^(.*)_\d+\.jpg$"", stem).groups()[0]
 ```
 
 ```python
 extract_label(fname)
 ```
 
 And you can see it properly returned the right name for our file:
 
 ```python out
 ""beagle""
 ```
 
 Next a `Dataset` class should be made to handle grabbing the image and the label:
 
 ```python
 class PetsDataset(Dataset):
     def __init__(self, file_names, image_transform=None, label_to_id=None):
         self.file_names = file_names
         self.image_transform = image_transform
         self.label_to_id = label_to_id
 
     def __len__(self):
         return len(self.file_names)
 
     def __getitem__(self, idx):
         fname = self.file_names[idx]
         raw_image = PIL.Image.open(fname)
         image = raw_image.convert(""RGB"")
         if self.image_transform is not None:
             image = self.image_transform(image)
         label = extract_label(fname)
         if self.label_to_id is not None:
             label = self.label_to_id[label]
         return {""image"": image, ""label"": label}
 ```
 
 Now to build the dataset. Outside the training function you can find and declare all the filenames and labels and use them as references inside the 
 launched function:
 
 ```python
 fnames = [os.path.join(""../../images"", fname) for fname in fnames if fname.endswith("".jpg"")]
 ```
 
 Next gather all the labels:
 
 ```python
 all_labels = [extract_label(fname) for fname in fnames]
 id_to_label = list(set(all_labels))
 id_to_label.sort()
 label_to_id = {lbl: i for i, lbl in enumerate(id_to_label)}
 ```
 
 Next, you should make a `get_dataloaders` function that will return your built dataloaders for you. As mentioned earlier, if data is automatically 
 sent to the GPU or a TPU device when building your `DataLoaders`, they must be built using this method. 
 
 ```python
 def get_dataloaders(batch_size: int = 64):
     ""Builds a set of dataloaders with a batch_size""
     random_perm = np.random.permutation(len(fnames))
     cut = int(0.8 * len(fnames))
     train_split = random_perm[:cut]
     eval_split = random_perm[cut:]
 
     # For training a simple RandomResizedCrop will be used
     train_tfm = Compose([RandomResizedCrop((224, 224), scale=(0.5, 1.0)), ToTensor()])
     train_dataset = PetsDataset([fnames[i] for i in train_split], image_transform=train_tfm, label_to_id=label_to_id)
 
     # For evaluation a deterministic Resize will be used
     eval_tfm = Compose([Resize((224, 224)), ToTensor()])
     eval_dataset = PetsDataset([fnames[i] for i in eval_split], image_transform=eval_tfm, label_to_id=label_to_id)
 
     # Instantiate dataloaders
     train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=4)
     eval_dataloader = DataLoader(eval_dataset, shuffle=False, batch_size=batch_size * 2, num_workers=4)
     return train_dataloader, eval_dataloader
 ```
 
 Finally, you should import the scheduler to be used later:
 
 ```python
 from torch.optim.lr_scheduler import CosineAnnealingLR
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#preparing-the-dataset-and-model,False,4293,715,https://huggingface.co
607,Writing the Training Function,"Now you can build the training loop. [`notebook_launcher`] works by passing in a function to call that will be ran across the distributed system.
 
 Here is a basic training loop for the animal classification problem:
 
 <Tip>
 
     The code has been split up to allow for explainations on each section. A full version that can be copy and pasted will be available at the end
 
 </Tip>
 
 
 ```python
 def training_loop(mixed_precision=""fp16"", seed: int = 42, batch_size: int = 64):
     set_seed(seed)
     accelerator = Accelerator(mixed_precision=mixed_precision)
 ```
 
 First you should set the seed and create an [`Accelerator`] object as early in the training loop as possible.
 
 <Tip warning={true}>
 
     If training on the TPU, your training loop should take in the model as a parameter and it should be instantiated 
     outside of the training loop function. See the [TPU best practices](../concept_guides/training_tpu) 
     to learn why
 
 </Tip>
 
 Next you should build your dataloaders and create your model:
 
 ```python
     train_dataloader, eval_dataloader = get_dataloaders(batch_size)
     model = create_model(""resnet50d"", pretrained=True, num_classes=len(label_to_id))
 ```
 
 <Tip>
 
     You build the model here so that the seed also controls the new weight initialization
 
 </Tip>
 
 As you are performing transfer learning in this example, the encoder of the model starts out frozen so the head of the model can be 
 trained only initially:
 
 ```python
     for param in model.parameters():
         param.requires_grad = False
     for param in model.get_classifier().parameters():
         param.requires_grad = True
 ```
 
 Normalizing the batches of images will make training a little faster:
 
 ```python
     mean = torch.tensor(model.default_cfg[""mean""])[None, :, None, None]
     std = torch.tensor(model.default_cfg[""std""])[None, :, None, None]
 ```
 
 To make these constants available on the active device, you should set it to the Accelerator's device:
 
 ```python
     mean = mean.to(accelerator.device)
     std = std.to(accelerator.device)
 ```
 
 Next instantiate the rest of the PyTorch classes used for training:
 
 ```python
     optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-2 / 25)
     lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-2, epochs=5, steps_per_epoch=len(train_dataloader))
 ```
 
 Before passing everything to [`~Accelerator.prepare`].
 
 <Tip>
 
     There is no specific order to remember, you just need to unpack the objects in the same order you gave them to the prepare method.
 
 </Tip>
 
 ```python
     model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
         model, optimizer, train_dataloader, eval_dataloader, lr_scheduler
     )
 ```
 
 Now train the model:
 
 ```python
     for epoch in range(5):
         model.train()
         for batch in train_dataloader:
             inputs = (batch[""image""] - mean) / std
             outputs = model(inputs)
             loss = torch.nn.functional.cross_entropy(outputs, batch[""label""])
             accelerator.backward(loss)
             optimizer.step()
             lr_scheduler.step()
             optimizer.zero_grad()
 ```
 
 The evaluation loop will look slightly different compared to the training loop. The number of elements passed as well as the overall 
 total accuracy of each batch will be added to two constants:
 
 ```python
         model.eval()
         accurate = 0
         num_elems = 0
 ```
 
 Next you have the rest of your standard PyTorch loop:
 
 ```python
         for batch in eval_dataloader:
             inputs = (batch[""image""] - mean) / std
             with torch.no_grad():
                 outputs = model(inputs)
             predictions = outputs.argmax(dim=-1)
 ```
 
 Before finally the last major difference. 
 
 When performing distributed evaluation, the predictions and labels need to be passed through 
 [`~Accelerator.gather`] so that all of the data is available on the current device and a properly calculated metric can be achieved:
 
 ```python
             accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[""label""])
             num_elems += accurate_preds.shape[0]
             accurate += accurate_preds.long().sum()
 ```
 
 Now you just need to calculate the actual metric for this problem, and you can print it on the main process using [`~Accelerator.print`]:
 
 ```python
         eval_metric = accurate.item() / num_elems
         accelerator.print(f""epoch {epoch}: {100 * eval_metric:.2f}"")
 ```
 
 A full version of this training loop is available below:
 
 ```python
 def training_loop(mixed_precision=""fp16"", seed: int = 42, batch_size: int = 64):
     set_seed(seed)
     # Initialize accelerator
     accelerator = Accelerator(mixed_precision=mixed_precision)
     # Build dataloaders
     train_dataloader, eval_dataloader = get_dataloaders(batch_size)
 
     # Instantiate the model (you build the model here so that the seed also controls new weight initaliziations)
     model = create_model(""resnet50d"", pretrained=True, num_classes=len(label_to_id))
 
     # Freeze the base model
     for param in model.parameters():
         param.requires_grad = False
     for param in model.get_classifier().parameters():
         param.requires_grad = True
 
     # You can normalize the batches of images to be a bit faster
     mean = torch.tensor(model.default_cfg[""mean""])[None, :, None, None]
     std = torch.tensor(model.default_cfg[""std""])[None, :, None, None]
 
     # To make these constants available on the active device, set it to the accelerator device
     mean = mean.to(accelerator.device)
     std = std.to(accelerator.device)
 
     # Intantiate the optimizer
     optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-2 / 25)
 
     # Instantiate the learning rate scheduler
     lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-2, epochs=5, steps_per_epoch=len(train_dataloader))
 
     # Prepare everything
     # There is no specific order to remember, you just need to unpack the objects in the same order you gave them to the
     # prepare method.
     model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
         model, optimizer, train_dataloader, eval_dataloader, lr_scheduler
     )
 
     # Now you train the model
     for epoch in range(5):
         model.train()
         for batch in train_dataloader:
             inputs = (batch[""image""] - mean) / std
             outputs = model(inputs)
             loss = torch.nn.functional.cross_entropy(outputs, batch[""label""])
             accelerator.backward(loss)
             optimizer.step()
             lr_scheduler.step()
             optimizer.zero_grad()
 
         model.eval()
         accurate = 0
         num_elems = 0
         for batch in eval_dataloader:
             inputs = (batch[""image""] - mean) / std
             with torch.no_grad():
                 outputs = model(inputs)
             predictions = outputs.argmax(dim=-1)
             accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[""label""])
             num_elems += accurate_preds.shape[0]
             accurate += accurate_preds.long().sum()
 
         eval_metric = accurate.item() / num_elems
         # Use accelerator.print to print only on the main process.
         accelerator.print(f""epoch {epoch}: {100 * eval_metric:.2f}"")
 ```",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#writing-the-training-function,False,7462,1593,https://huggingface.co
608,Using the notebook_launcher,"All that's left is to use the [`notebook_launcher`].
 
 You pass in the function, the arguments (as a tuple), and the number of processes to train on. (See the [documentation](../package_reference/launchers) for more information)
 
 ```python
 from accelerate import notebook_launcher
 ```
 
 ```python
 args = (""fp16"", 42, 64)
 notebook_launcher(training_loop, args, num_processes=2)
 ```
 
 In the case of running on the TPU, it would look like so:
 
 ```python
 model = create_model(""resnet50d"", pretrained=True, num_classes=len(label_to_id))
 
 args = (model, ""fp16"", 42, 64)
 notebook_launcher(training_loop, args, num_processes=8)
 ```
 
 As it's running it will print the progress as well as state how many devices you ran on. This tutorial was ran with two GPUs:
 
 ```python out
 Launching training on 2 GPUs.
 epoch 0: 88.12
 epoch 1: 91.73
 epoch 2: 92.58
 epoch 3: 93.90
 epoch 4: 94.71
 ```
 
 And that's it!",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#using-the-notebook-launcher,False,921,137,https://huggingface.co
609,Debugging,"A common issue when running the `notebook_launcher` is receiving a CUDA has already been initialized issue. This usually stems
 from an import or prior code in the notebook that makes a call to the PyTorch `torch.cuda` sublibrary. To help narrow down what went wrong,
 you can launch the `notebook_launcher` with `ACCELERATE_DEBUG_MODE=yes` in your environment and an additional check
 will be made when spawning that a regular process can be created and utilize CUDA without issue. (Your CUDA code can still be ran afterwards).",H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#debugging,False,528,83,https://huggingface.co
610,Conclusion,This notebook showed how to perform distributed training from inside of a Jupyter Notebook. Some key notes to remember:,H2,https://huggingface.co/docs/accelerate/source/basic_tutorials/notebook#conclusion,False,119,19,https://huggingface.co
612,The Command Line,Below is a list of all the available commands 🤗 Accelerate with their parameters,H1,https://huggingface.co/docs/accelerate/source/package_reference/cli#the-command-line,False,80,14,https://huggingface.co
613,accelerate config,"**Command**:
 
 `accelerate config` or `accelerate-config`
 
 Launches a series of prompts to create and save a `default_config.yml` configuration file for your training system. Should 
 always be ran first on your machine.
 
 **Usage**: 
 
 ```bash
 accelerate config [arguments]
 ```
 
 **Optional Arguments**:
 * `--config_file CONFIG_FILE` (`str`) -- The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
                         of the environment `HF_HOME` suffixed with 'accelerate', or if you don't have such an environment variable, your cache directory
                         (`~/.cache` or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.
 * `-h`, `--help` (`bool`) -- Show a help message and exit",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-config,False,804,161,https://huggingface.co
614,accelerate config default,"**Command**:
 
 `accelerate config default` or `accelerate-config default`
 
 Create a default config file for Accelerate with only a few flags set.
 
 **Usage**: 
 
 ```bash
 accelerate config default [arguments]
 ```
 
 **Optional Arguments**:
 * `--config_file CONFIG_FILE` (`str`) -- The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
                         of the environment `HF_HOME` suffixed with 'accelerate', or if you don't have such an environment variable, your cache directory
                         (`~/.cache` or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.
 
 * `-h`, `--help` (`bool`) -- Show a help message and exit
 * `--mixed_precision {no,fp16,bf16}` (`str`) -- Whether or not to use mixed precision training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only supported on Nvidia Ampere GPUs and PyTorch 1.10 or later.",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-config-default,False,967,186,https://huggingface.co
615,accelerate config update,"**Command**:
 
 `accelerate config update` or `accelerate-config update`
 
 Update an existing config file with the latest defaults while maintaining the old configuration.
 
 **Usage**: 
 
 ```bash
 accelerate config update [arguments]
 ```
 
 **Optional Arguments**:
 * `--config_file CONFIG_FILE` (`str`) -- The path to the config file to update. Will default to a file named default_config.yaml in the cache location, which is the content
                         of the environment `HF_HOME` suffixed with 'accelerate', or if you don't have such an environment variable, your cache directory
                         (`~/.cache` or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.
 
 * `-h`, `--help` (`bool`) -- Show a help message and exit",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-config-update,False,759,152,https://huggingface.co
616,accelerate env,"**Command**:
 
 `accelerate env` or `accelerate-env` or `python -m accelerate.commands.env`
 
 Lists the contents of the passed 🤗 Accelerate configuration file. Should always be used when opening an issue on the [GitHub repository](https://github.com/huggingface/accelerate).
 
 **Usage**:
 
 ```bash
 accelerate env [arguments]
 ```
 
 **Optional Arguments**:
 * `--config_file CONFIG_FILE` (`str`) -- The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
                         of the environment `HF_HOME` suffixed with 'accelerate', or if you don't have such an environment variable, your cache directory
                         (`~/.cache` or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.
 * `-h`, `--help` (`bool`) -- Show a help message and exit",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-env,False,852,160,https://huggingface.co
617,accelerate launch,"**Command**:
 
 `accelerate launch` or `accelerate-launch` or `python -m accelerate.commands.launch`
 
 Launches a specified script on a distributed system with the right parameters.
 
 **Usage**: 
 
 ```bash
 accelerate launch [arguments] {training_script} --{training_script-argument-1} --{training_script-argument-2} ...
 ```
 
 **Positional Arguments**:",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-launch,False,357,39,https://huggingface.co
618,accelerate tpu-config,"`accelerate tpu-config`
 
 **Usage**:
 
 ```bash
 accelerate tpu-config [arguments]
 ```
 
 **Optional Arguments**:
 * `-h`, `--help` (`bool`) -- Show a help message and exit
 
 **Config Arguments**:
 
 Arguments that can be configured through `accelerate config`.
 
 * `--config_file` (`str`) -- Path to the config file to use for accelerate.
 * `--tpu_name` (`str`) -- The name of the TPU to use. If not specified, will use the TPU specified in the config file.
 * `--tpu_zone` (`str`) -- The zone of the TPU to use. If not specified, will use the zone specified in the config file.
 
 **TPU Arguments**:
 
 Arguments for options ran inside the TPU.
 
 * `--command_file` (`str`) -- The path to the file containing the commands to run on the pod on startup.
 * `--command` (`str`) -- A command to run on the pod. Can be passed multiple times.
 * `--install_accelerate` (`bool`) -- Whether to install accelerate on the pod. Defaults to False.
 * `--accelerate_version` (`str`) -- The version of accelerate to install on the pod. If not specified, will use the latest pypi version. Specify 'dev' to install from GitHub.
 * `--debug` (`bool`) -- If set, will print the command that would be run instead of running it.",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-tpu-config,False,1216,203,https://huggingface.co
619,accelerate test,"`accelerate test` or `accelerate-test`
 
 Runs `accelerate/test_utils/test_script.py` to verify that 🤗 Accelerate has been properly configured on your system and runs. 
 
 **Usage**: 
 
 ```bash
 accelerate test [arguments]
 ```
 
 **Optional Arguments**:
 * `--config_file CONFIG_FILE` (`str`) -- The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
                         of the environment `HF_HOME` suffixed with 'accelerate', or if you don't have such an environment variable, your cache directory
                         (`~/.cache` or the content of `XDG_CACHE_HOME`) suffixed with `huggingface`.
 * `-h`, `--help` (`bool`) -- Show a help message and exit",H2,https://huggingface.co/docs/accelerate/source/package_reference/cli#accelerate-test,False,747,150,https://huggingface.co
621,Utilities for Megatron-LM,"[[autodoc]] utils.MegatronLMPlugin
 
 [[autodoc]] utils.MegatronLMDummyScheduler
 
 [[autodoc]] utils.MegatronLMDummyDataLoader
 
 [[autodoc]] utils.AbstractTrainStep
 
 [[autodoc]] utils.GPTTrainStep
 
 [[autodoc]] utils.BertTrainStep
 
 [[autodoc]] utils.T5TrainStep
 
 [[autodoc]] utils.avg_losses_across_data_parallel_group",H1,https://huggingface.co/docs/accelerate/source/package_reference/megatron_lm#utilities-for-megatron-lm,False,327,23,https://huggingface.co
623,Kwargs Handlers,"The following objects can be passed to the main [`Accelerator`] to customize how some PyTorch objects
 related to distributed training or mixed precision are created.",H1,https://huggingface.co/docs/accelerate/source/package_reference/kwargs#kwargs-handlers,False,166,25,https://huggingface.co
630,Stateful Classes,"Below are variations of a [singleton class](https://en.wikipedia.org/wiki/Singleton_pattern) in the sense that all
 instances share the same state, which is initialized on the first instantiation.
 
 These classes are immutable and store information about certain configurations or 
 states.
 
 [[autodoc]] state.PartialState
 
 [[autodoc]] state.AcceleratorState
 
 [[autodoc]] state.GradientState",H1,https://huggingface.co/docs/accelerate/source/package_reference/state#stateful-classes,False,398,47,https://huggingface.co
632,Accelerator,"The [`Accelerator`] is the main class provided by 🤗 Accelerate. 
 It serves at the main entry point for the API.",H1,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#accelerator,False,112,21,https://huggingface.co
633,Quick adaptation of your code,"To quickly adapt your script to work on any kind of setup with 🤗 Accelerate just:
 
 1. Initialize an [`Accelerator`] object (that we will call `accelerator` throughout this page) as early as possible in your script.
 2. Pass your dataloader(s), model(s), optimizer(s), and scheduler(s) to the [`~Accelerator.prepare`] method.
 3. Remove all the `.cuda()` or `.to(device)` from your code and let the `accelerator` handle the device placement for you. 
 
 <Tip>
 
     Step three is optional, but considered a best practice.
 
 </Tip>
 
 4. Replace `loss.backward()` in your code with `accelerator.backward(loss)`
 5. Gather your predictions and labels before storing them or using them for metric computation using [`~Accelerator.gather`]
 
 <Tip warning={true}>
 
     Step five is mandatory when using distributed evaluation
     
 </Tip>
 
 In most cases this is all that is needed. The next section lists a few more advanced use cases and nice features
 you should search for and replace by the corresponding methods of your `accelerator`:",H2,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#quick-adaptation-of-your-code,False,1043,172,https://huggingface.co
635,Printing,`print` statements should be replaced by [`~Accelerator.print`] to be printed once per process:,H3,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#printing,False,95,13,https://huggingface.co
637,Once on a single server,"For statements that should be executed once per server, use [`~Accelerator.is_local_main_process`]:
 
 ```python
 if accelerator.is_local_main_process:
     do_thing_once_per_server()
 ```
 
 A function can be wrapped using the [`~Accelerator.on_local_main_process`] function to achieve the same 
 behavior on a function's execution:
 
 ```python
 @accelerator.on_local_main_process
 def do_my_thing():
     ""Something done once per server""
     do_thing_once_per_server()
 ```",H4,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#once-on-a-single-server,False,477,61,https://huggingface.co
638,Only ever once across all servers,"For statements that should only ever be executed once, use [`~Accelerator.is_main_process`]:
 
 ```python
 if accelerator.is_main_process:
     do_thing_once()
 ```
 
 A function can be wrapped using the [`~Accelerator.on_main_process`] function to achieve the same 
 behavior on a function's execution:
 
 ```python
 @accelerator.on_main_process
 def do_my_thing():
     ""Something done once per server""
     do_thing_once()
 ```",H4,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#only-ever-once-across-all-servers,False,430,61,https://huggingface.co
639,On specific processes,"If a function should be ran on a specific overall or local process index, there are similar decorators 
 to achieve this:
 
 ```python
 @accelerator.on_local_process(local_process_idx=0)
 def do_my_thing():
     ""Something done on process index 0 on each server""
     do_thing_on_index_zero_on_each_server()
 ```
 
 ```python
 @accelerator.on_process(process_index=0)
 def do_my_thing():
     ""Something done on process index 0""
     do_thing_on_index_zero()
 ```",H4,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#on-specific-processes,False,463,67,https://huggingface.co
640,Synchronicity control,Use [`~Accelerator.wait_for_everyone`] to make sure all processes join that point before continuing. (Useful before a model save for instance).,H3,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#synchronicity-control,False,143,19,https://huggingface.co
641,Saving and loading,"```python
 model = MyModel()
 model = accelerator.prepare(model)
 ```
 
 Use [`~Accelerator.save_model`] instead of `torch.save` to save a model. It will remove all model wrappers added during the distributed process, get the state_dict of the model and save it. The state_dict will be in the same precision as the model being trained.",H3,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#saving-and-loading,False,335,51,https://huggingface.co
642,🤗 Transformers models,"If you are using models from the [🤗 Transformers](https://huggingface.co/docs/transformers/) library, you can use the `.save_pretrained()` method.
 
 ```python
 from transformers import AutoModel
 
 model = AutoModel.from_pretrained(""bert-base-cased"")
 model = accelerator.prepare(model)",H4,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#transformers-models,False,287,29,https://huggingface.co
644,Gradient Accumulation,"To perform gradient accumulation use [`~Accelerator.accumulate`] and specify a gradient_accumulation_steps. 
 This will also automatically ensure the gradients are synced or unsynced when on 
 multi-device training, check if the step should actually be performed, and auto-scale the loss:",H3,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#gradient-accumulation,False,288,39,https://huggingface.co
645,GradientAccumulationPlugin,"[[autodoc]] utils.GradientAccumulationPlugin
 
 
 Instead of passing `gradient_accumulation_steps` you can instantiate a GradientAccumulationPlugin and pass it to the [`Accelerator`]'s `__init__`
 as `gradient_accumulation_plugin`. You can only pass either one of `gradient_accumulation_plugin` or `gradient_accumulation_steps` passing both will raise an error.
 ```diff
 from accelerate.utils import GradientAccumulationPlugin",H4,https://huggingface.co/docs/accelerate/source/package_reference/accelerator#gradientaccumulationplugin,False,427,43,https://huggingface.co
650,Integrated Trackers,"[[autodoc]] tracking.TensorBoardTracker
     - __init__
 [[autodoc]] tracking.WandBTracker
     - __init__
 [[autodoc]] tracking.CometMLTracker
     - __init__
 [[autodoc]] tracking.AimTracker
     - __init__
 [[autodoc]] tracking.MLflowTracker
     - __init__",H2,https://huggingface.co/docs/accelerate/source/package_reference/tracking#integrated-trackers,False,260,40,https://huggingface.co
653,Dispatching and Offloading Models,"[[autodoc]] big_modeling.init_empty_weights
 [[autodoc]] big_modeling.cpu_offload
 [[autodoc]] big_modeling.disk_offload
 [[autodoc]] big_modeling.dispatch_model
 [[autodoc]] big_modeling.load_checkpoint_and_dispatch
 [[autodoc]] big_modeling.load_checkpoint_in_model
 [[autodoc]] utils.infer_auto_device_map",H2,https://huggingface.co/docs/accelerate/source/package_reference/big_modeling#dispatching-and-offloading-models,False,308,14,https://huggingface.co
659,Helpful Utilities,"Below are a variety of utility functions that 🤗 Accelerate provides, broken down by use-case.",H1,https://huggingface.co/docs/accelerate/source/package_reference/utilities#helpful-utilities,False,93,15,https://huggingface.co
660,Constants,"Constants used throughout 🤗 Accelerate for reference
 
 The following are constants used when utilizing [`Accelerator.save_state`]
 
 `utils.MODEL_NAME`: `""pytorch_model""`
 `utils.OPTIMIZER_NAME`: `""optimizer""`
 `utils.RNG_STATE_NAME`: `""random_states""`
 `utils.SCALER_NAME`: `""scaler.pt`
 `utils.SCHEDULER_NAME`: `""scheduler`
 
 The following are constants used when utilizing [`Accelerator.save_model`]
 
 `utils.WEIGHTS_NAME`: `""pytorch_model.bin""`
 `utils.SAFE_WEIGHTS_NAME`: `""model.safetensors""`
 `utils.WEIGHTS_INDEX_NAME`: `""pytorch_model.bin.index.json""`
 `utils.SAFE_WEIGHTS_INDEX_NAME`: `""model.safetensors.index.json""`",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#constants,False,630,45,https://huggingface.co
661,Data Classes,"These are basic dataclasses used throughout 🤗 Accelerate and they can be passed in as parameters.
 
 [[autodoc]] utils.DistributedType
 
 [[autodoc]] utils.DynamoBackend
 
 [[autodoc]] utils.LoggerType
 
 [[autodoc]] utils.PrecisionType
 
 [[autodoc]] utils.ProjectConfiguration",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#data-classes,False,278,31,https://huggingface.co
662,Plugins,"These are plugins that can be passed to the [`Accelerator`] object. While they are defined elsewhere in the documentation, 
 for convience all of them are available to see here:
 
 [[autodoc]] utils.DeepSpeedPlugin
 
 [[autodoc]] utils.FullyShardedDataParallelPlugin
 
 [[autodoc]] utils.GradientAccumulationPlugin
 
 [[autodoc]] utils.MegatronLMPlugin
 
 [[autodoc]] utils.TorchDynamoPlugin",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#plugins,False,391,45,https://huggingface.co
663,Data Manipulation and Operations,"These include data operations that mimic the same `torch` ops but can be used on distributed processes.
 
 [[autodoc]] utils.broadcast
 
 [[autodoc]] utils.concatenate
 
 [[autodoc]] utils.gather
 
 [[autodoc]] utils.pad_across_processes
 
 [[autodoc]] utils.reduce
 
 [[autodoc]] utils.send_to_device",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#data-manipulation-and-operations,False,301,35,https://huggingface.co
664,Environment Checks,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed. 
 
 [[autodoc]] utils.is_bf16_available
 
 [[autodoc]] utils.is_ipex_available
 
 [[autodoc]] utils.is_mps_available
 
 [[autodoc]] utils.is_npu_available
 
 [[autodoc]] utils.is_torch_version
 
 [[autodoc]] utils.is_tpu_available
 
 [[autodoc]] utils.is_xpu_available",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#environment-checks,False,465,49,https://huggingface.co
665,Environment Manipulation,"[[autodoc]] utils.patch_environment
 
 [[autodoc]] utils.clear_environment
 
 [[autodoc]] utils.write_basic_config
 
 When setting up 🤗 Accelerate for the first time, rather than running `accelerate config` [~utils.write_basic_config] can be used as an alternative for quick configuration.",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#environment-manipulation,False,289,33,https://huggingface.co
667,Modeling,"These utilities relate to interacting with PyTorch models
 
 [[autodoc]] utils.extract_model_from_parallel
 
 [[autodoc]] utils.get_max_layer_size
 
 [[autodoc]] utils.offload_state_dict",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#modeling,False,186,17,https://huggingface.co
668,Parallel,"These include general utilities that should be used when working in parallel.
 
 [[autodoc]] utils.extract_model_from_parallel
 
 [[autodoc]] utils.save
 
 [[autodoc]] utils.wait_for_everyone",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#parallel,False,191,21,https://huggingface.co
669,Random,"These utilities relate to setting and synchronizing of all the random states.
 
 [[autodoc]] utils.set_seed
 
 [[autodoc]] utils.synchronize_rng_state
 
 [[autodoc]] utils.synchronize_rng_states",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#random,False,194,21,https://huggingface.co
670,PyTorch XLA,"These include utilities that are useful while using PyTorch with XLA.
 
 [[autodoc]] utils.install_xla",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#pytorch-xla,False,102,14,https://huggingface.co
671,Loading model weights,"These include utilities that are useful to load checkpoints.
 
 [[autodoc]] utils.load_checkpoint_in_model",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#loading-model-weights,False,106,12,https://huggingface.co
672,Quantization,"These include utilities that are useful to quantize model.
 
 [[autodoc]] utils.load_and_quantize_model
 
 [[autodoc]] utils.BnbQuantizationConfig",H2,https://huggingface.co/docs/accelerate/source/package_reference/utilities#quantization,False,146,15,https://huggingface.co
674,Utilities for DeepSpeed,"[[autodoc]] utils.DeepSpeedPlugin
 
 [[autodoc]] utils.DummyOptim
 
 [[autodoc]] utils.DummyScheduler
 
 [[autodoc]] utils.DeepSpeedEngineWrapper
 
 [[autodoc]] utils.DeepSpeedOptimizerWrapper
 
 [[autodoc]] utils.DeepSpeedSchedulerWrapper",H1,https://huggingface.co/docs/accelerate/source/package_reference/deepspeed#utilities-for-deepspeed,False,239,17,https://huggingface.co
676,Logging with Accelerate,"Accelerate has its own logging utility to handle logging while in a distributed system.
 To utilize this replace cases of `logging` with `accelerate.logging`:",H1,https://huggingface.co/docs/accelerate/source/package_reference/logging#logging-with-accelerate,False,158,23,https://huggingface.co
677,Setting the log level,"The log level can be set with the `ACCELERATE_LOG_LEVEL` environment variable or by passing 
 `log_level` to `get_logger`:
 ```python
 from accelerate.logging import get_logger
 
 logger = get_logger(__name__, log_level=""INFO"")
 ```
 
 [[autodoc]] logging.get_logger",H2,https://huggingface.co/docs/accelerate/source/package_reference/logging#setting-the-log-level,False,266,32,https://huggingface.co
681,"Wrapper classes for torch Dataloaders, Optimizers, and Schedulers","The internal classes Accelerate uses to prepare objects for distributed training
 when calling [`~Accelerator.prepare`].",H1,https://huggingface.co/docs/accelerate/source/package_reference/torch_wrappers#wrapper-classes-for-torch-dataloaders-optimizers-and-schedulers,False,120,14,https://huggingface.co
682,Datasets and DataLoaders,"[[autodoc]] data_loader.prepare_data_loader
 [[autodoc]] data_loader.skip_first_batches
 
 [[autodoc]] data_loader.BatchSamplerShard
 [[autodoc]] data_loader.IterableDatasetShard
 [[autodoc]] data_loader.DataLoaderShard
 [[autodoc]] data_loader.DataLoaderDispatcher",H2,https://huggingface.co/docs/accelerate/source/package_reference/torch_wrappers#datasets-and-dataloaders,False,265,13,https://huggingface.co
686,Launchers,"Functions for launching training on distributed processes.
 
 
 [[autodoc]] accelerate.notebook_launcher
 [[autodoc]] accelerate.debug_launcher",H1,https://huggingface.co/docs/accelerate/source/package_reference/launchers#launchers,False,143,13,https://huggingface.co
688,Debugging Distributed Operations,"When running scripts in a distributed fashion, often functions such as [`Accelerator.gather`] and [`Accelerator.reduce`] (and others) are neccessary to grab tensors across devices and perform certain operations on them. However, if the tensors which are being grabbed are not the proper shapes then this will result in your code hanging forever. The only sign that exists of this truly happening is hitting a timeout exception from `torch.distributed`, but this can get quite costly as usually the timeout is 10 minutes.
 
 Accelerate now has a `debug` mode which adds a neglible amount of time to each operation, but allows it to verify that the inputs you are bringing in can *actually* perform the operation you want **without** hitting this timeout problem!",H1,https://huggingface.co/docs/accelerate/source/usage_guides/debug#debugging-distributed-operations,False,761,121,https://huggingface.co
689,Visualizing the problem,"To have a tangible example of this issue, let's take the following setup (on 2 GPUs):
 
 ```python
 from accelerate import PartialState
 
 state = PartialState()
 if state.process_index == 0:
     tensor = torch.tensor([[0.0, 1, 2, 3, 4]]).to(state.device)
 else:
     tensor = torch.tensor([[[0.0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]]).to(state.device)
 
 broadcast_tensor = broadcast(tensor)
 print(broadcast_tensor)
 ```
 
 We've created a single tensor on each device, with two radically different shapes. With this setup if we want to perform an operation such as [`utils.broadcast`], we would forever hit a timeout because `torch.distributed` requires that these operations have the **exact same shape** across all processes for it to work.
 
 If you run this yourself, you will find that `broadcast_tensor` can be printed on the main process, but its results won't quite be right, and then it will just hang never printing it on any of the other processes:
 
 ```
 >>> tensor([[0, 1, 2, 3, 4]], device='cuda:0')
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/debug#visualizing-the-problem,False,1017,165,https://huggingface.co
690,The solution,"By enabling Accelerate's operational debug mode, Accelerate will properly find and catch errors such as this and provide a very clear traceback immediatly: 
 
 ```
 Traceback (most recent call last):
   File ""/home/zach_mueller_huggingface_co/test.py"", line 18, in <module>
     main()
   File ""/home/zach_mueller_huggingface_co/test.py"", line 15, in main
         main()broadcast_tensor = broadcast(tensor)
   File ""/home/zach_mueller_huggingface_co/accelerate/src/accelerate/utils/operations.py"", line 303, in wrapper
     broadcast_tensor = broadcast(tensor)
 accelerate.utils.operations.DistributedOperationException: Cannot apply desired operation due to shape mismatches. All shapes across devices must be valid.
 
 Operation: `accelerate.utils.operations.broadcast`
 Input shapes:
   - Process 0: [1, 5]
   - Process 1: [1, 2, 5]
 ```
 
 This explains that the shapes across our devices were *not* the same, and that we should ensure that they match properly to be compatible. Typically this means that there is either an extra dimension, or certain dimensions are incompatible with the operation.
 
 To enable this please do one of the following:
 
 Enable it through the questionarre during `accelerate config` (recommended)
 
 From the CLI: 
 
 ```
 accelerate launch --debug {my_script.py} --arg1 --arg2
 ```
 
 As an environmental variable (which avoids the need for `accelerate launch`):
 
 ```
 ACCELERATE_DEBUG_MODE=""1"" accelerate launch {my_script.py} --arg1 --arg2
 ```
 
 Manually changing the `config.yaml` file:
 
 ```diff
  compute_environment: LOCAL_MACHINE
 +debug: true
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/debug#the-solution,False,1598,227,https://huggingface.co
692,Amazon SageMaker,"Hugging Face and Amazon introduced new [Hugging Face Deep Learning Containers (DLCs)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers) to
 make it easier than ever to train Hugging Face Transformer models in [Amazon SageMaker](https://aws.amazon.com/sagemaker/).",H1,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#amazon-sagemaker,False,326,27,https://huggingface.co
694,Setup & Installation,"Before you can run your 🤗 Accelerate scripts on Amazon SageMaker you need to sign up for an AWS account. If you do not
 have an AWS account yet learn more [here](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html).
 
 After you have your AWS Account you need to install the `sagemaker` sdk for 🤗 Accelerate with:
 
 ```bash
 pip install ""accelerate[sagemaker]"" --upgrade
 ```
 
 🤗 Accelerate currently uses the 🤗 DLCs, with `transformers`, `datasets` and `tokenizers` pre-installed. 🤗
 Accelerate is not in the DLC yet (will soon be added!) so to use it within Amazon SageMaker you need to create a
 `requirements.txt` in the same directory where your training script is located and add it as dependency:
 
 ```
 accelerate
 ```
 
 You should also add any other dependencies you have to this `requirements.txt`.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#setup-installation,False,823,128,https://huggingface.co
695,Configure 🤗 Accelerate,"You can configure the launch configuration for Amazon SageMaker the same as you do for non SageMaker training jobs with
 the 🤗 Accelerate CLI:
 
 ```bash
 accelerate config",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#configure-accelerate,False,172,28,https://huggingface.co
696,Prepare a 🤗 Accelerate fine-tuning script,"The training script is very similar to a training script you might run outside of SageMaker, but to save your model
 after training you need to specify either `/opt/ml/model` or use `os.environ[""SM_MODEL_DIR""]` as your save
 directory. After training, artifacts in this directory are uploaded to S3:",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#prepare-a-accelerate-fine-tuning-script,False,299,46,https://huggingface.co
697,Launch Training,"You can launch your training with 🤗 Accelerate CLI with:
 
 ```
 accelerate launch path_to_script.py --args_to_the_script
 ```
 
 This will launch your training script using your configuration. The only thing you have to do is provide all the
 arguments needed by your training script as named arguments.
 
 **Examples**
 
 <Tip>
 
     If you run one of the example scripts, don't forget to add `accelerator.save('/opt/ml/model')` to it.
 
 </Tip>
 
 ```bash
 accelerate launch ./examples/sagemaker_example.py
 ```
 
 Outputs:
 
 ```
 Configuring Amazon SageMaker environment
 Converting Arguments to Hyperparameters
 Creating Estimator
 2021-04-08 11:56:50 Starting - Starting the training job...
 2021-04-08 11:57:13 Starting - Launching requested ML instancesProfilerReport-1617883008: InProgress
 .........
 2021-04-08 11:58:54 Starting - Preparing the instances for training.........
 2021-04-08 12:00:24 Downloading - Downloading input data
 2021-04-08 12:00:24 Training - Downloading the training image..................
 2021-04-08 12:03:39 Training - Training image download completed. Training in progress..
 ........
 epoch 0: {'accuracy': 0.7598039215686274, 'f1': 0.8178438661710037}
 epoch 1: {'accuracy': 0.8357843137254902, 'f1': 0.882249560632689}
 epoch 2: {'accuracy': 0.8406862745098039, 'f1': 0.8869565217391304}
 ........
 2021-04-08 12:05:40 Uploading - Uploading generated training model
 2021-04-08 12:05:40 Completed - Training job completed
 Training seconds: 331
 Billable seconds: 331
 You can find your model data at: s3://your-bucket/accelerate-sagemaker-1-2021-04-08-11-56-47-108/output/model.tar.gz
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#launch-training,False,1637,196,https://huggingface.co
699,Distributed Training: Data Parallelism,"Set up the accelerate config by running `accelerate config` and answer the SageMaker questions and set it up.
 To use SageMaker DDP, select it when asked 
 `What is the distributed mode? ([0] No distributed training, [1] data parallelism):`.
 Example config below:
 ```yaml
 base_job_name: accelerate-sagemaker-1
 compute_environment: AMAZON_SAGEMAKER
 distributed_type: DATA_PARALLEL
 ec2_instance_type: ml.p3.16xlarge
 iam_role_name: xxxxx
 image_uri: null
 mixed_precision: fp16
 num_machines: 1
 profile: xxxxx
 py_version: py38
 pytorch_version: 1.10.2
 region: us-east-1
 transformers_version: 4.17.0
 use_cpu: false
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#distributed-training-data-parallelism,False,627,72,https://huggingface.co
701,Python packages and dependencies,"🤗 Accelerate currently uses the 🤗 DLCs, with `transformers`, `datasets` and `tokenizers` pre-installed. If you
 want to use different/other Python packages you can do this by adding them to the `requirements.txt`. These packages
 will be installed before your training script is started.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#python-packages-and-dependencies,False,287,42,https://huggingface.co
702,Local Training: SageMaker Local mode,"The local mode in the SageMaker SDK allows you to run your training script locally inside the HuggingFace DLC (Deep Learning container) 
 or using your custom container image. This is useful for debugging and testing your training script inside the final container environment.
 Local mode uses Docker compose (*Note: Docker Compose V2 is not supported yet*). The SDK will handle the authentication against ECR
 to pull the DLC to your local environment. You can emulate CPU (single and multi-instance) and GPU (single instance) SageMaker training jobs.
 
 To use local mode, you need to set your `ec2_instance_type` to `local`.
 
 ```yaml
 ec2_instance_type: local
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#local-training-sagemaker-local-mode,False,670,105,https://huggingface.co
703,Advanced configuration,"The configuration allows you to override parameters for the [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html).
 These settings have to be applied in the config file and are not part of `accelerate config`. You can control many additional aspects of the training job, e.g. use Spot instances, enable network isolation and many more.
 
 ```yaml
 additional_args:
   # enable network isolation to restrict internet access for containers
   enable_network_isolation: True
 ```
 
 You can find all available configuration [here](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html).",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#advanced-configuration,False,632,75,https://huggingface.co
704,Use Spot Instances,"You can use Spot Instances e.g. using (see [Advanced configuration](#advanced-configuration)):
 ```yaml
 additional_args:
   use_spot_instances: True
   max_wait: 86400
 ```
 
 *Note: Spot Instances are subject to be terminated and training to be continued from a checkpoint. This is not handled in 🤗 Accelerate out of the box. Contact us if you would like this feature.*",H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#use-spot-instances,False,371,57,https://huggingface.co
705,Remote scripts: Use scripts located on Github,*undecided if feature is needed. Contact us if you would like this feature.*,H3,https://huggingface.co/docs/accelerate/source/usage_guides/sagemaker#remote-scripts-use-scripts-located-on-github,False,76,13,https://huggingface.co
707,Learning how to incorporate 🤗 Accelerate features quickly!,"Please use the interactive tool below to help you get started with learning about a particular 
 feature of 🤗 Accelerate and how to utilize it! It will provide you with a code diff, an explaination
 towards what is going on, as well as provide you with some useful links to explore more within
 the documentation!
 
 Most code examples start from the following python code before integrating 🤗 Accelerate in some way:
 
 ```python
 for batch in dataloader:
     optimizer.zero_grad()
     inputs, targets = batch
     inputs = inputs.to(device)
     targets = targets.to(device)
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     loss.backward()
     optimizer.step()
     scheduler.step()
 ```
 
 <div class=""block dark:hidden"">
 	<iframe 
         src=""https://muellerzr-accelerate-examples.hf.space?__theme=light""
         width=""850""
         height=""1600""
     ></iframe>
 </div>
 <div class=""hidden dark:block"">
     <iframe 
         src=""https://muellerzr-accelerate-examples.hf.space?__theme=dark""
         width=""850""
         height=""1600""
     ></iframe>
 </div>",H1,https://huggingface.co/docs/accelerate/source/usage_guides/explore#learning-how-to-incorporate-accelerate-features-quickly,False,1101,218,https://huggingface.co
709,Distributed Inference with 🤗 Accelerate,"Distributed inference is a common use case, especially with natural language processing (NLP) models. Users often want to
 send a number of different prompts, each to a different GPU, and then get the results back. This also has other cases
 outside of just NLP, however for this tutorial we will focus on just this idea of each GPU receiving a different prompt,
 and then returning the results.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/distributed_inference#distributed-inference-with-accelerate,False,395,67,https://huggingface.co
710,The Problem,"Normally when doing this, users send the model to a specific device to load it from the CPU, and then move each prompt to a different device. 
 
 A basic pipeline using the `diffusers` library might look something like so:
 
 ```python
 import torch
 import torch.distributed as dist
 from diffusers import DiffusionPipeline
 
 pipe = DiffusionPipeline.from_pretrained(""runwayml/stable-diffusion-v1-5"", torch_dtype=torch.float16)
 ```
 Followed then by performing inference based on the specific prompt:
 
 ```python
 def run_inference(rank, world_size):
     dist.init_process_group(""nccl"", rank=rank, world_size=world_size)
     pipe.to(rank)
 
     if torch.distributed.get_rank() == 0:
         prompt = ""a dog""
     elif torch.distributed.get_rank() == 1:
         prompt = ""a cat""
 
     result = pipe(prompt).images[0]
     result.save(f""result_{rank}.png"")
 ```
 One will notice how we have to check the rank to know what prompt to send, which can be a bit tedious.
 
 A user might then also think that with 🤗 Accelerate, using the `Accelerator` to prepare a dataloader for such a task might also be 
 a simple way to manage this. (To learn more, check out the relvent section in the [Quick Tour](../quicktour#distributed-evaluation))
 
 Can it manage it? Yes. Does it add unneeded extra code however: also yes.",H2,https://huggingface.co/docs/accelerate/source/usage_guides/distributed_inference#the-problem,False,1319,222,https://huggingface.co
711,The Solution,"With 🤗 Accelerate, we can simplify this process by using the [`Accelerator.split_between_processes`] context manager (which also exists in `PartialState` and `AcceleratorState`). 
 This function will automatically split whatever data you pass to it (be it a prompt, a set of tensors, a dictionary of the prior data, etc.) across all the processes (with a potential
 to be padded) for you to use right away.
 
 Let's rewrite the above example using this context manager:
 
 ```python
 from accelerate import PartialState  # Can also be Accelerator or AcceleratorState
 from diffusers import DiffusionPipeline
 
 pipe = DiffusionPipeline.from_pretrained(""runwayml/stable-diffusion-v1-5"", torch_dtype=torch.float16)
 distributed_state = PartialState()
 pipe.to(distributed_state.device)",H2,https://huggingface.co/docs/accelerate/source/usage_guides/distributed_inference#the-solution,False,783,101,https://huggingface.co
713,Megatron-LM,"[Megatron-LM](https://github.com/NVIDIA/Megatron-LM) enables training large transformer language models at scale.
 It provides efficient tensor, pipeline and sequence based model parallelism for pre-training transformer based
 Language Models such as [GPT](https://arxiv.org/abs/2005.14165) (Decoder Only), [BERT](https://arxiv.org/pdf/1810.04805.pdf) (Encoder Only) and [T5](https://arxiv.org/abs/1910.10683) (Encoder-Decoder).
 For detailed information and how things work behind the scene please refer the github [repo](https://github.com/NVIDIA/Megatron-LM).",H1,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#megatron-lm,False,562,51,https://huggingface.co
714,What is integrated?,"Accelerate integrates following feature of Megatron-LM to enable large scale pre-training/finetuning
 of BERT (Encoder), GPT (Decoder) or T5 models (Encoder and Decoder):
 
 a. **Tensor Parallelism (TP)**: Reduces memory footprint without much additional communication on intra-node ranks.
 Each tensor is split into multiple chunks with each shard residing on separate GPU. At each step, the same mini-batch of data is processed
 independently and in parallel by each shard followed by syncing across all GPUs (`all-reduce` operation). 
 In a simple transformer layer, this leads to 2 `all-reduces` in the forward path and 2 in the backward path.
 For more details, please refer research paper [Megatron-LM: Training Multi-Billion Parameter Language Models Using
 Model Parallelism](https://arxiv.org/pdf/1909.08053.pdf) and 
 this section of 🤗 blogpost [The Technology Behind BLOOM Training](https://huggingface.co/blog/bloom-megatron-deepspeed#tensor-parallelism).
 
 
 b. **Pipeline Parallelism (PP)**: Reduces memory footprint and enables large scale training via inter-node parallelization. 
 Reduces the bubble of naive PP via PipeDream-Flush schedule/1F1B schedule and Interleaved 1F1B schedule. 
 Layers are distributed uniformly across PP stages. For example, if a model has `24` layers and we have `4` GPUs for
 pipeline parallelism, each GPU will have `6` layers (24/4). For more details on schedules to reduce the idle time of PP,
 please refer to the research paper [Efficient Large-Scale Language Model Training on GPU Clusters
 Using Megatron-LM](https://arxiv.org/pdf/2104.04473.pdf) and 
 this section of 🤗 blogpost [The Technology Behind BLOOM Training](https://huggingface.co/blog/bloom-megatron-deepspeed#pipeline-parallelism).
 
 c. **Sequence Parallelism (SP)**: Reduces memory footprint without any additional communication. Only applicable when using TP.
 It reduces activation memory required as it prevents the same copies to be on the tensor parallel ranks 
 post `all-reduce` by replacing then with `reduce-scatter` and `no-op` operation would be replaced by `all-gather`. 
 As `all-reduce = reduce-scatter + all-gather`, this saves a ton of activation memory at no added communication cost. 
 To put it simply, it shards the outputs of each transformer layer along sequence dimension, e.g., 
 if the sequence length is `1024` and the TP size is `4`, each GPU will have `256` tokens (1024/4) for each sample. 
 This increases the batch size that can be supported for training. For more details, please refer to the research paper
 [Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/pdf/2205.05198.pdf). 
 
 d. **Data Parallelism (DP)** via Distributed Optimizer: Reduces the memory footprint by sharding optimizer states and gradients across DP ranks
 (versus the traditional method of replicating the optimizer state across data parallel ranks). 
 For example, when using Adam optimizer with mixed-precision training, each parameter accounts for 12 bytes of memory.
 This gets distributed equally across the GPUs, i.e., each parameter would account for 3 bytes (12/4) if we have 4 GPUs.
 For more details, please refer the research paper [ZeRO: Memory Optimizations Toward Training Trillion
 Parameter Models](https://arxiv.org/pdf/1910.02054.pdf) and following section of 🤗 blog 
 [The Technology Behind BLOOM Training](https://huggingface.co/blog/bloom-megatron-deepspeed#zero-data-parallelism).
 
 e. **Selective Activation Recomputation**: Reduces the memory footprint of activations significantly via smart activation checkpointing.
 It doesn't store activations occupying large memory while being fast to recompute thereby achieving great tradeoff between memory and recomputation.
 For example, for GPT-3, this leads to 70% reduction in required memory for activations at the expense of
 only 2.7% FLOPs overhead for recomputation of activations. For more details, please refer to the research paper 
 [Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/pdf/2205.05198.pdf).
 
 f. **Fused Kernels**: Fused Softmax, Mixed Precision Fused Layer Norm and  Fused gradient accumulation to weight gradient computation of linear layer.
 PyTorch JIT compiled Fused GeLU and Fused Bias+Dropout+Residual addition.
 
 g. **Support for Indexed datasets**: Efficient binary format of datasets for large scale training. Support for the `mmap`, `cached` index file and the `lazy` loader format.
 
 h. **Checkpoint reshaping and interoperability**: Utility for reshaping Megatron-LM checkpoints of variable 
 tensor and pipeline parallel sizes to the beloved 🤗 Transformers sharded checkpoints as it has great support with plethora of tools
 such as 🤗 Accelerate Big Model Inference, Megatron-DeepSpeed Inference etc. 
 Support is also available for converting 🤗 Transformers sharded checkpoints to Megatron-LM checkpoint of variable tensor and pipeline parallel sizes
 for large scale training.",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#what-is-integrated,False,4977,676,https://huggingface.co
715,Pre-Requisites,"You will need to install the latest pytorch, cuda, nccl, and NVIDIA [APEX](https://github.com/NVIDIA/apex#quick-start) releases and the nltk library.
 See [documentation](https://github.com/NVIDIA/Megatron-LM#setup) for more details. 
 Another way to setup the environment is to pull an NVIDIA PyTorch Container that comes with all the required installations from NGC.
 
 Below is a step-by-step method to set up the conda environment:
 
 1. Create a virtual environment
 ```
 conda create --name ml
 ```
 
 2. Assuming that the machine has CUDA 11.3 installed, installing the corresponding PyTorch GPU Version
 ```
 conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
 ```
 
 3. Install Nvidia APEX
 ```
 git clone https://github.com/NVIDIA/apex
 cd apex
 pip install -v --disable-pip-version-check --no-cache-dir --global-option=""--cpp_ext"" --global-option=""--cuda_ext"" ./
 cd ..
 ```
 
 4. Installing Megatron-LM
 
 ```
 pip install git+https://github.com/huggingface/Megatron-LM.git
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#pre-requisites,False,1012,128,https://huggingface.co
716,Accelerate Megatron-LM Plugin,"Important features are directly supported via the `accelerate config` command. 
 An example of thr corresponding questions for using Megatron-LM features is shown below:
 
 ```bash
 :~$ accelerate config --config_file ""megatron_gpt_config.yaml""
 In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0
 Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 2
 How many different machines will you use (use more than 1 for multi-node training)? [1]: 
 Do you want to use DeepSpeed? [yes/NO]: 
 Do you want to use FullyShardedDataParallel? [yes/NO]: 
 Do you want to use Megatron-LM ? [yes/NO]: yes
 What is the Tensor Parallelism degree/size? [1]:2
 Do you want to enable Sequence Parallelism? [YES/no]: 
 What is the Pipeline Parallelism degree/size? [1]:2
 What is the number of micro-batches? [1]:2
 Do you want to enable selective activation recomputation? [YES/no]: 
 Do you want to use distributed optimizer which shards optimizer state and gradients across data pralellel ranks? [YES/no]: 
 What is the gradient clipping value based on global L2 Norm (0 to disable)? [1.0]: 
 How many GPU(s) should be used for distributed training? [1]:4
 Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: bf16
 ```
 
 The resulting config is shown below:
 
 ```
 ~$ cat megatron_gpt_config.yaml 
 compute_environment: LOCAL_MACHINE
 deepspeed_config: {}
 distributed_type: MEGATRON_LM
 downcast_bf16: 'no'
 fsdp_config: {}
 machine_rank: 0
 main_process_ip: null
 main_process_port: null
 main_training_function: main
 megatron_lm_config:
   megatron_lm_gradient_clipping: 1.0
   megatron_lm_num_micro_batches: 2
   megatron_lm_pp_degree: 2
   megatron_lm_recompute_activations: true
   megatron_lm_sequence_parallelism: true
   megatron_lm_tp_degree: 2
   megatron_lm_use_distributed_optimizer: true
 mixed_precision: bf16
 num_machines: 1
 num_processes: 4
 rdzv_backend: static
 same_network: true
 use_cpu: false
 ```
 
 We will take the example of GPT pre-training. The minimal changes required to the official `run_clm_no_trainer.py` 
 to use Megatron-LM are as follows:
 
 1. As Megatron-LM uses its own implementation of Optimizer, the corresponding scheduler compatible with it needs to be used.
 As such, support for only the Megatron-LM's scheduler is present. User will need to create `accelerate.utils.MegatronLMDummyScheduler`.
 Example is given below:
 
 ```python
 from accelerate.utils import MegatronLMDummyScheduler
 
 if accelerator.distributed_type == DistributedType.MEGATRON_LM:
     lr_scheduler = MegatronLMDummyScheduler(
         optimizer=optimizer,
         total_num_steps=args.max_train_steps,
         warmup_num_steps=args.num_warmup_steps,
     )
 else:
     lr_scheduler = get_scheduler(
         name=args.lr_scheduler_type,
         optimizer=optimizer,
         num_warmup_steps=args.num_warmup_steps * args.gradient_accumulation_steps,
         num_training_steps=args.max_train_steps * args.gradient_accumulation_steps,
     )
 ```
 
 2. Getting the details of the total batch size now needs to be cognization of tensor and pipeline parallel sizes.
 Example of getting the effective total batch size is shown below:
 
 ```python
 if accelerator.distributed_type == DistributedType.MEGATRON_LM:
     total_batch_size = accelerator.state.megatron_lm_plugin.global_batch_size
 else:
     total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps
 ```
 
 3. When using Megatron-LM, the losses are already averaged across the data parallel group
 
 ```python
 if accelerator.distributed_type == DistributedType.MEGATRON_LM:
     losses.append(loss)
 else:
     losses.append(accelerator.gather_for_metrics(loss.repeat(args.per_device_eval_batch_size)))
 
 if accelerator.distributed_type == DistributedType.MEGATRON_LM:
     losses = torch.tensor(losses)
 else:
     losses = torch.cat(losses)
 ```
 
 4. For Megatron-LM, we need to save the model using `accelerator.save_state`
 
 ```python
 if accelerator.distributed_type == DistributedType.MEGATRON_LM:
     accelerator.save_state(args.output_dir)
 else:
     unwrapped_model = accelerator.unwrap_model(model)
     unwrapped_model.save_pretrained(
         args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save
     )
 ```
 
 That's it! We are good to go 🚀. Please find the example script in the examples folder at the path `accelerate/examples/by_feature/megatron_lm_gpt_pretraining.py`.
 Let's run it for `gpt-large` model architecture using 4 A100-80GB GPUs.
 
 ```bash
 accelerate launch --config_file megatron_gpt_config.yaml \",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#accelerate-megatron-lm-plugin,False,4718,648,https://huggingface.co
717,Advanced features to leverage writing custom train step and Megatron-LM Indexed Datasets,"For leveraging more features, please go through below details.
 
 1. Below is an example of changes required to customize the Train Step while using Megatron-LM. 
 You will implement the `accelerate.utils.AbstractTrainStep` or inherit from their corresponding children 
 `accelerate.utils.GPTTrainStep`, `accelerate.utils.BertTrainStep` or `accelerate.utils.T5TrainStep`.
 
 ```python
 from accelerate.utils import MegatronLMDummyScheduler, GPTTrainStep, avg_losses_across_data_parallel_group",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#advanced-features-to-leverage-writing-custom-train-step-and-megatron-lm-indexed-datasets,False,492,51,https://huggingface.co
718,Utility for Checkpoint reshaping and interoperability,"1. The scripts for these are present in 🤗 Transformers library under respective models. 
 Currently, it is available for GPT model [checkpoint_reshaping_and_interoperability.py](https://github.com/huggingface/transformers/blob/main/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py)
 
 2. Below is an example of conversion of checkpoint from Megatron-LM to universal 🤗 Transformers sharded checkpoint.
 ```bash",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#utility-for-checkpoint-reshaping-and-interoperability,False,443,42,https://huggingface.co
719,Megatron-LM GPT models support returning logits and `megatron_generate` function for text generation,"1. Returning logits require setting `require_logits=True` in MegatronLMPlugin as shown below. 
 These would be available on the in the last stage of pipeline.
 ```python
 megatron_lm_plugin = MegatronLMPlugin(return_logits=True)
 ```
 
 2. `megatron_generate` method for Megatron-LM GPT model: This will use Tensor and Pipeline Parallelism to complete 
 generations for a batch of inputs when using greedy with/without top_k/top_p sampling and for individual prompt inputs when using beam search decoding. 
 Only a subset of features of transformers generate is supported. This will help in using large models via tensor and pipeline parallelism 
 for generation (already does key-value caching and uses fused kernels by default).
 This requires data parallel size to be 1, sequence parallelism and activation checkpointing to be disabled.
 It also requires specifying path to tokenizer's vocab file and merges file. 
 Below example shows how to configure and use `megatron_generate` method for Megatron-LM GPT model.
 ```python",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#megatron-lm-gpt-models-support-returning-logits-and-megatron-generate-function-for-text-generation,False,1028,149,https://huggingface.co
720,Support for ROPE and ALiBi Positional embeddings and Multi-Query Attention,"1. For ROPE/ALiBi attention, pass `position_embedding_type` with `(""absolute"" | ""rotary"" | ""alibi"")` to `MegatronLMPlugin` as shown below.
 ```python
 other_megatron_args = {""position_embedding_type"": ""alibi""}
 megatron_lm_plugin = MegatronLMPlugin(other_megatron_args=other_megatron_args)
 ```
 
 2. For Multi-Query Attention, pass `attention_head_type` with `(""multihead"" | ""multiquery"")` to `MegatronLMPlugin` as shown below.
 ```python
 other_megatron_args = {""attention_head_type"": ""multiquery""}
 megatron_lm_plugin = MegatronLMPlugin(other_megatron_args=other_megatron_args)
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#support-for-rope-and-alibi-positional-embeddings-and-multi-query-attention,False,585,51,https://huggingface.co
721,Caveats,"1. Supports Transformers GPT2, Megatron-BERT and T5 models.
 This covers Decoder only, Encode only and Encoder-Decoder model classes.
 
 2. Only loss is returned from model forward pass as 
 there is quite complex interplay of pipeline, tensor and data parallelsim behind the scenes.
 The `model(**batch_data)` call return loss(es) averaged across the data parallel ranks.
 This is fine for most cases wherein pre-training jobs are run using Megatron-LM features and
 you can easily compute the `perplexity` using the loss. 
 For GPT model, returning logits in addition to loss(es) is supported. 
 These logits aren't gathered across data prallel ranks. Use `accelerator.utils.gather_across_data_parallel_groups`
 to gather logits across data parallel ranks. These logits along with labels can be used for computing various 
 performance metrics. 
 
 3. The main process is the last rank as the losses/logits are available in the last stage of pipeline.
 `accelerator.is_main_process` and `accelerator.is_local_main_process` return `True` for last rank when using 
 Megatron-LM integration.
 
 4. In `accelerator.prepare` call, a Megatron-LM model corresponding to a given Transformers model is created
 with random weights. Please use `accelerator.load_state` to load the Megatron-LM checkpoint with matching TP, PP and DP partitions.
 
 5. Currently, checkpoint reshaping and interoperability support is only available for GPT. 
 Soon it will be extended to BERT and T5.
 
 6. `gradient_accumulation_steps` needs to be 1. When using Megatron-LM, micro batches in pipeline parallelism 
 setting is synonymous with gradient accumulation. 
 
 7. When using Megatron-LM, use `accelerator.save_state` and `accelerator.load_state` for saving and loading checkpoints.
 
 8. Below are the mapping from Megatron-LM model architectures to the the equivalent 🤗 transformers model architectures.
 Only these 🤗 transformers model architectures are supported.
 
 a. Megatron-LM [BertModel](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/bert_model.py) : 
 🤗 transformers models with `megatron-bert` in config's model type, e.g., 
 [MegatronBERT](https://huggingface.co/docs/transformers/model_doc/megatron-bert)
     
 b. Megatron-LM [GPTModel](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py) : 
 🤗 transformers models with `gpt2` in config's model type, e.g., 
 [OpenAI GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)
    
 c. Megatron-LM [T5Model](https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/t5_model.py) : 
 🤗 transformers models with `t5` in  config's model type, e.g., 
 [T5](https://huggingface.co/docs/transformers/model_doc/t5) and 
 [MT5](https://huggingface.co/docs/transformers/model_doc/mt5)",H2,https://huggingface.co/docs/accelerate/source/usage_guides/megatron_lm#caveats,False,2770,343,https://huggingface.co
723,Tracking,"There are a large number of experiment tracking API's available, however getting them all to work with in a multi-processing environment can oftentimes be complex.
 🤗 Accelerate provides a general tracking API that can be used to log useful items during your script through [`Accelerator.log`]",H1,https://huggingface.co/docs/accelerate/source/usage_guides/tracking#tracking,False,293,45,https://huggingface.co
725,Implementing Custom Trackers,"To implement a new tracker to be used in `Accelerator`, a new one can be made through implementing the [`GeneralTracker`] class.
 Every tracker must implement three functions and have three properties:
   - `__init__`: 
     - Should store a `run_name` and initialize the tracker API of the integrated library. 
     - If a tracker stores their data locally (such as TensorBoard), a `logging_dir` parameter can be added.
   - `store_init_configuration`: 
     - Should take in a `values` dictionary and store them as a one-time experiment configuration
   - `log`: 
     - Should take in a `values` dictionary and a `step`, and should log them to the run
 
   - `name` (`str`):
     - A unique string name for the tracker, such as `""wandb""` for the wandb tracker. 
     - This will be used for interacting with this tracker specifically
   - `requires_logging_directory` (`bool`):
     - Whether a `logging_dir` is needed for this particular tracker and if it uses one.
   - `tracker`: 
     - This should be implemented as a `@property` function 
     - Should return the internal tracking mechanism the library uses, such as the `run` object for `wandb`.
 
 Each method should also utilize the [`state.PartialState`] class if the logger should only be executed on the main process for instance.
 
 A brief example can be seen below with an integration with Weights and Biases, containing only the relevant information and logging just on 
 the main process:
 ```python
 from accelerate.tracking import GeneralTracker, on_main_process
 from typing import Optional
 
 import wandb
 
 
 class MyCustomTracker(GeneralTracker):
     name = ""wandb""
     requires_logging_directory = False
 
     @on_main_process
     def __init__(self, run_name: str):
         self.run_name = run_name
         run = wandb.init(self.run_name)
 
     @property
     def tracker(self):
         return self.run.run
 
     @on_main_process
     def store_init_configuration(self, values: dict):
         wandb.config(values)
 
     @on_main_process
     def log(self, values: dict, step: Optional[int] = None):
         wandb.log(values, step=step)
 ```
 
 When you are ready to build your `Accelerator` object, pass in an **instance** of your tracker to [`Accelerator.log_with`] to have it automatically
 be used with the API:
 
 ```python
 tracker = MyCustomTracker(""some_run_name"")
 accelerator = Accelerator(log_with=tracker)
 ```
 
 These also can be mixed with existing trackers, including with `""all""`:
 
 ```python
 tracker = MyCustomTracker(""some_run_name"")
 accelerator = Accelerator(log_with=[tracker, ""all""])
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/tracking#implementing-custom-trackers,False,2603,481,https://huggingface.co
726,Accessing the internal tracker,"If some custom interactions with a tracker might be wanted directly, you can quickly access one using the 
 [`Accelerator.get_tracker`] method. Just pass in the string corresponding to a tracker's `.name` attribute 
 and it will return that tracker on the main process.
 
 This example shows doing so with wandb:
 
 ```python
 wandb_tracker = accelerator.get_tracker(""wandb"")
 ```
 
 From there you can interact with `wandb`'s `run` object like normal:
 
 ```python
 wandb_run.log_artifact(some_artifact_to_log)
 ```
 
 <Tip>
   Trackers built in Accelerate will automatically execute on the correct process, 
   so if a tracker is only meant to be ran on the main process it will do so 
   automatically.
 </Tip>
 
 If you want to truly remove Accelerate's wrapping entirely, you can 
 achieve the same outcome with:
 
 ```python
 wandb_tracker = accelerator.get_tracker(""wandb"", unwrap=True)
 with accelerator.on_main_process:
     wandb_tracker.log_artifact(some_artifact_to_log)
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/tracking#accessing-the-internal-tracker,False,987,146,https://huggingface.co
727,When a wrapper cannot work,"If a library has an API that does not follow a strict `.log` with an overall dictionary such as Neptune.AI, logging can be done manually under an `if accelerator.is_main_process` statement:
 ```diff
   from accelerate import Accelerator
 + import neptune.new as neptune
 
   accelerator = Accelerator()
 + run = neptune.init(...)
 
   my_model, my_optimizer, my_training_dataloader = accelerate.prepare(my_model, my_optimizer, my_training_dataloader)
   device = accelerator.device
   my_model.to(device)
 
   for iteration in config[""num_iterations""]:
       for batch in my_training_dataloader:
           my_optimizer.zero_grad()
           inputs, targets = batch
           inputs = inputs.to(device)
           targets = targets.to(device)
           outputs = my_model(inputs)
           loss = my_loss_function(outputs, targets)
           total_loss += loss
           accelerator.backward(loss)
           my_optimizer.step()
 +         if accelerator.is_main_process:
 +             run[""logs/training/batch/loss""].log(loss)
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/tracking#when-a-wrapper-cannot-work,False,1040,226,https://huggingface.co
729,Handling big models for inference,"One of the biggest advancements 🤗 Accelerate provides is the concept of [large model inference](../concept_guides/big_model_inference) wherein you can perform *inference* on models that cannot fully fit on your graphics card. 
 
 This tutorial will be broken down into two parts showcasing how to use both 🤗 Accelerate and 🤗 Transformers (a higher API-level) to make use of this idea.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/big_modeling#handling-big-models-for-inference,False,384,60,https://huggingface.co
730,Using 🤗 Accelerate,"For these tutorials, we'll assume a typical workflow for loading your model in such that:
 
 ```py
 import torch
 
 my_model = ModelClass(...)
 state_dict = torch.load(checkpoint_file)
 my_model.load_state_dict(state_dict)
 ```
 
 Note that here we assume that `ModelClass` is a model that takes up more video-card memory than what can fit on your device (be it `mps` or `cuda`).
 
 The first step is to init an empty skeleton of the model which won't take up any RAM using the [`init_empty_weights`] context manager:
 
 ```py
 from accelerate import init_empty_weights
 with init_empty_weights():
     my_model = ModelClass(...)
 ```
 
 With this `my_model` currently is ""parameterless"", hence leaving the smaller footprint than what one would normally get loading this onto the CPU directly. 
 
 Next we need to load in the weights to our model so we can perform inference.
 
 For this we will use [`load_checkpoint_and_dispatch`], which as the name implies will load a checkpoint inside your empty model and dispatch the weights for each layer across all the devices you have available (GPU/MPS and CPU RAM). 
 
 To determine how this `dispatch` can be performed, generally specifying `device_map=""auto""` will be good enough as 🤗 Accelerate
 will attempt to fill all the space in your GPU(s), then loading them to the CPU, and finally if there is not enough RAM it will be loaded to the disk (the absolute slowest option). 
 
 <Tip>
 
 For more details on desigining your own device map, see this section of the [concept guide](../concept_guide/big_model_inference#desigining-a-device-map)
 
 </Tip>
 
 See an example below:
 
 ```py
 from accelerate import load_checkpoint_and_dispatch
 
 model = load_checkpoint_and_dispatch(
     model, checkpoint=checkpoint_file, device_map=""auto""
 )
 ```
 
 <Tip>
 
     If there are certain ""chunks"" of layers that shouldn't be split, you can pass them in as `no_split_module_classes`. Read more about it [here](../concept_guides/big_model_inference#loading-weights)
 
 </Tip>
 
 <Tip>
 
     Also to save on memory (such as if the `state_dict` will not fit in RAM), a model's weights can be divided and split into multiple checkpoint files. Read more about it [here](../concept_guides/big_model_inference#sharded-checkpoints)
 
 </Tip>
 
 Now that the model is dispatched fully, you can perform inference as normal with the model:
 
 ```py
 input = torch.randn(2,3)
 input = input.to(""cuda"")
 output = model(input)
 ```
 
 What will happen now is each time the input gets passed through a layer, it will be sent from the CPU to the GPU (or disk to CPU to GPU), the output is calculated, and then the layer is pulled back off the GPU going back down the line. While this adds some overhead to the inference being performed, through this method it is possible to run **any size model** on your system, as long as the largest layer is capable of fitting on your GPU. 
 
 <Tip>
 
     Multiple GPUs can be utilized, however this is considered ""model parallism"" and as a result only one GPU will be active at a given moment, waiting for the prior one to send it the output. You should launch your script normally with `python`
     and not need `torchrun`, `accelerate launch`, etc.
 
 </Tip>
 
 For a visual representation of this, check out the animation below:
 
 <Youtube id=""MWCSGj9jEAo"" />",H2,https://huggingface.co/docs/accelerate/source/usage_guides/big_modeling#using-accelerate,False,3334,547,https://huggingface.co
731,Complete Example,"Below is the full example showcasing what we performed above:
 
 ```py
 import torch
 from accelerate import init_empty_weights, load_checkpoint_and_dispatch
 
 with init_empty_weights():
     model = MyModel(...)
 
 model = load_checkpoint_and_dispatch(
     model, checkpoint=checkpoint_file, device_map=""auto""
 )
 
 input = torch.randn(2,3)
 input = input.to(""cuda"")
 output = model(input)
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/big_modeling#complete-example,False,397,52,https://huggingface.co
732,"Using 🤗 Transformers, 🤗 Diffusers, and other 🤗 Open Source Libraries","Libraries that support 🤗 Accelerate big model inference include all of the earlier logic in their `from_pretrained` constructors. 
 
 These operate by specifying a string representing the model to download from the [🤗 Hub](https://hf.co/models) and then denoting `device_map=""auto""` along with a few extra parameters. 
 
 As a brief example, we will look at using `transformers` and loading in Big Science's T0pp model. 
 
 ```py
 from transformers import AutoModelForSeq2SeqLM
 
 model = AutoModelForSeq2SeqLM(""bigscience/T0pp"", device_map=""auto"")
 ```
 
 After loading the model in, the initial steps from before to prepare a model have all been done and the model is fully
 ready to make use of all the resources in your machine. Through these constructors, you can also save *more* memory by
 specifying the precision the model is loaded into as well, through the `torch_dtype` parameter, such as:
 
 ```py
 from transformers import AutoModelForSeq2SeqLM
 
 model = AutoModelForSeq2SeqLM(""bigscience/T0pp"", device_map=""auto"", torch_dtype=torch.float16)
 ```
 
 To learn more about this, check out the 🤗 Transformers documentation available [here](https://huggingface.co/docs/transformers/main/en/main_classes/model#large-model-loading).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/big_modeling#using-transformers-diffusers-and-other-open-source-libraries,False,1240,165,https://huggingface.co
733,Where to go from here,"For a much more detailed look at big model inference, be sure to check out the [Conceptual Guide on it](../concept_guides/big_model_inference)",H2,https://huggingface.co/docs/accelerate/source/usage_guides/big_modeling#where-to-go-from-here,False,142,20,https://huggingface.co
735,Example Zoo,Below contains a non-exhuastive list of tutorials and scripts showcasing 🤗 Accelerate,H1,https://huggingface.co/docs/accelerate/source/usage_guides/training_zoo#example-zoo,False,85,12,https://huggingface.co
737,Basic Examples,These examples showcase the base features of Accelerate and are a great starting point,H3,https://huggingface.co/docs/accelerate/source/usage_guides/training_zoo#basic-examples,False,86,14,https://huggingface.co
739,Full Examples,"These examples showcase every feature in Accelerate at once that was shown in ""Feature Specific Examples""",H3,https://huggingface.co/docs/accelerate/source/usage_guides/training_zoo#full-examples,False,105,16,https://huggingface.co
740,Integration Examples,"These are tutorials from libraries that integrate with 🤗 Accelerate: 
 
 > Don't find your integration here? Make a PR to include it!",H2,https://huggingface.co/docs/accelerate/source/usage_guides/training_zoo#integration-examples,False,133,24,https://huggingface.co
754,In Science,"Below contains a non-exhaustive list of papers utilizing 🤗 Accelerate. 
 
 > Don't find your paper here? Make a PR to include it!
 
 * Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, Omer Levy: “Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation”, 2023; [arXiv:2305.01569](http://arxiv.org/abs/2305.01569).
 * Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim: “Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models”, 2023; [arXiv:2305.04091](http://arxiv.org/abs/2305.04091).
 * Arthur Câmara, Claudia Hauff: “Moving Stuff Around: A study on efficiency of moving documents into memory for Neural IR models”, 2022; [arXiv:2205.08343](http://arxiv.org/abs/2205.08343).
 * Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y. Fu, Zhiqiang Xie, Beidi Chen, Clark Barrett, Joseph E. Gonzalez, Percy Liang, Christopher Ré, Ion Stoica, Ce Zhang: “High-throughput Generative Inference of Large Language Models with a Single GPU”, 2023; [arXiv:2303.06865](http://arxiv.org/abs/2303.06865).
 * Peter Melchior, Yan Liang, ChangHoon Hahn, Andy Goulding: “Autoencoding Galaxy Spectra I: Architecture”, 2022; [arXiv:2211.07890](http://arxiv.org/abs/2211.07890).
 * Jiaao Chen, Aston Zhang, Mu Li, Alex Smola, Diyi Yang: “A Cheaper and Better Diffusion Language Model with Soft-Masked Noise”, 2023; [arXiv:2304.04746](http://arxiv.org/abs/2304.04746).
 * Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa: “Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions”, 2023; [arXiv:2303.12789](http://arxiv.org/abs/2303.12789).
 * Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, Andrea Vedaldi: “RealFusion: 360° Reconstruction of Any Object from a Single Image”, 2023; [arXiv:2302.10663](http://arxiv.org/abs/2302.10663).
 * Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li: “Better Aligning Text-to-Image Models with Human Preference”, 2023; [arXiv:2303.14420](http://arxiv.org/abs/2303.14420).
 * Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang: “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace”, 2023; [arXiv:2303.17580](http://arxiv.org/abs/2303.17580).
 * Yue Yang, Wenlin Yao, Hongming Zhang, Xiaoyang Wang, Dong Yu, Jianshu Chen: “Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination”, 2022; [arXiv:2210.12261](http://arxiv.org/abs/2210.12261).
 * Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho: “How to Backdoor Diffusion Models?”, 2022; [arXiv:2212.05400](http://arxiv.org/abs/2212.05400).
 * Junyoung Seo, Wooseok Jang, Min-Seop Kwak, Jaehoon Ko, Hyeonsu Kim, Junho Kim, Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim: “Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation”, 2023; [arXiv:2303.07937](http://arxiv.org/abs/2303.07937).
 * Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or: “Localizing Object-level Shape Variations with Text-to-Image Diffusion Models”, 2023; [arXiv:2303.11306](http://arxiv.org/abs/2303.11306).
 * Dídac Surís, Sachit Menon, Carl Vondrick: “ViperGPT: Visual Inference via Python Execution for Reasoning”, 2023; [arXiv:2303.08128](http://arxiv.org/abs/2303.08128).
 * Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan, Qifeng Chen: “FateZero: Fusing Attentions for Zero-shot Text-based Video Editing”, 2023; [arXiv:2303.09535](http://arxiv.org/abs/2303.09535).
 * Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, Yejin Choi: “NaturalProver: Grounded Mathematical Proof Generation with Language Models”, 2022; [arXiv:2205.12910](http://arxiv.org/abs/2205.12910).
 * Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure: Text-Guided Texturing of 3D Shapes”, 2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).
 * Puijin Cheng, Li Lin, Yijin Huang, Huaqing He, Wenhan Luo, Xiaoying Tang: “Learning Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement”, 2023; [arXiv:2303.04603](http://arxiv.org/abs/2303.04603).
 * Shun Shao, Yftah Ziser, Shay Cohen: “Erasure of Unaligned Attributes from Neural Representations”, 2023; [arXiv:2302.02997](http://arxiv.org/abs/2302.02997).
 * Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim, Minjoon Seo: “In-Context Instruction Learning”, 2023; [arXiv:2302.14691](http://arxiv.org/abs/2302.14691).
 * Shikun Liu, Linxi Fan, Edward Johns, Zhiding Yu, Chaowei Xiao, Anima Anandkumar: “Prismer: A Vision-Language Model with An Ensemble of Experts”, 2023; [arXiv:2303.02506](http://arxiv.org/abs/2303.02506 ).
 * Haoyu Chen, Zhihua Wang, Yang Yang, Qilin Sun, Kede Ma: “Learning a Deep Color Difference Metric for Photographic Images”, 2023; [arXiv:2303.14964](http://arxiv.org/abs/2303.14964).
 * Van-Hoang Le, Hongyu Zhang: “Log Parsing with Prompt-based Few-shot Learning”, 2023; [arXiv:2302.07435](http://arxiv.org/abs/2302.07435).
 * Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Ana Brassard, Masashi Yoshikawa, Keisuke Sakaguchi, Kentaro Inui: “Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning?”, 2023; [arXiv:2302.07866](http://arxiv.org/abs/2302.07866).
 * Ruoyao Wang, Peter Jansen, Marc-Alexandre Côté, Prithviraj Ammanabrolu: “Behavior Cloned Transformers are Neurosymbolic Reasoners”, 2022; [arXiv:2210.07382](http://arxiv.org/abs/2210.07382).
 * Martin Wessel, Tomáš Horych, Terry Ruas, Akiko Aizawa, Bela Gipp, Timo Spinde: “Introducing MBIB -- the first Media Bias Identification Benchmark Task and Dataset Collection”, 2023; [arXiv:2304.13148](http://arxiv.org/abs/2304.13148 ). DOI: [https://dx.doi.org/10.1145/3539618.3591882 10.1145/3539618.3591882].
 * Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, Daniel Cohen-Or: “Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models”, 2023; [arXiv:2301.13826](http://arxiv.org/abs/2301.13826).
 * Marcio Fonseca, Yftah Ziser, Shay B. Cohen: “Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents”, 2022; [arXiv:2205.12486](http://arxiv.org/abs/2205.12486).
 * Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or: “TEXTure: Text-Guided Texturing of 3D Shapes”, 2023; [arXiv:2302.01721](http://arxiv.org/abs/2302.01721).
 * Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James Glass, Yulia Tsvetkov: “On the Blind Spots of Model-Based Evaluation Metrics for Text Generation”, 2022; [arXiv:2212.10020](http://arxiv.org/abs/2212.10020).
 * Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham: “In-Context Retrieval-Augmented Language Models”, 2023; [arXiv:2302.00083](http://arxiv.org/abs/2302.00083).
 * Dacheng Li, Rulin Shao, Hongyi Wang, Han Guo, Eric P. Xing, Hao Zhang: “MPCFormer: fast, performant and private Transformer inference with MPC”, 2022; [arXiv:2211.01452](http://arxiv.org/abs/2211.01452).
 * Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz Nouri, Zhou Yu, Bill Dolan, Jianfeng Gao: “GODEL: Large-Scale Pre-Training for Goal-Directed Dialog”, 2022; [arXiv:2206.11309](http://arxiv.org/abs/2206.11309).
 * Egil Rønningstad, Erik Velldal, Lilja Øvrelid: “Entity-Level Sentiment Analysis (ELSA): An exploratory task survey”, 2023, Proceedings of the 29th International Conference on Computational Linguistics, 2022, pages 6773-6783; [arXiv:2304.14241](http://arxiv.org/abs/2304.14241).
 * Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine: “Offline RL for Natural Language Generation with Implicit Language Q Learning”, 2022; [arXiv:2206.11871](http://arxiv.org/abs/2206.11871).
 * Zhiruo Wang, Shuyan Zhou, Daniel Fried, Graham Neubig: “Execution-Based Evaluation for Open-Domain Code Generation”, 2022; [arXiv:2212.10481](http://arxiv.org/abs/2212.10481).
 * Minh-Long Luu, Zeyi Huang, Eric P. Xing, Yong Jae Lee, Haohan Wang: “Expeditious Saliency-guided Mix-up through Random Gradient Thresholding”, 2022; [arXiv:2212.04875](http://arxiv.org/abs/2212.04875).
 * Jun Hao Liew, Hanshu Yan, Daquan Zhou, Jiashi Feng: “MagicMix: Semantic Mixing with Diffusion Models”, 2022; [arXiv:2210.16056](http://arxiv.org/abs/2210.16056).
 * Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, Jianfeng Gao: “LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot Learners”, 2021; [arXiv:2110.06274](http://arxiv.org/abs/2110.06274).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/training_zoo#in-science,False,8541,933,https://huggingface.co
756,Intel® Extension for PyTorch,"[IPEX](https://github.com/intel/intel-extension-for-pytorch) is optimized for CPUs with AVX-512 or above, and functionally works for CPUs with only AVX2. So, it is expected to bring performance benefit for Intel CPU generations with AVX-512 or above while CPUs with only AVX2 (e.g., AMD CPUs or older Intel CPUs) might result in a better performance under IPEX, but not guaranteed. IPEX provides performance optimizations for CPU training with both Float32 and BFloat16. The usage of BFloat16 is the main focus of the following sections.
 
 Low precision data type BFloat16 has been natively supported on the 3rd Generation Xeon® Scalable Processors (aka Cooper Lake) with AVX512 instruction set and will be supported on the next generation of Intel® Xeon® Scalable Processors with Intel® Advanced Matrix Extensions (Intel® AMX) instruction set with further boosted performance. The Auto Mixed Precision for CPU backend has been enabled since PyTorch-1.10. At the same time, the support of Auto Mixed Precision with BFloat16 for CPU and BFloat16 optimization of operators has been massively enabled in Intel® Extension for PyTorch, and partially upstreamed to PyTorch master branch. Users can get better performance and user experience with IPEX Auto Mixed Precision.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/ipex#intel-r-extension-for-pytorch,False,1267,190,https://huggingface.co
757,IPEX installation:,"IPEX release is following PyTorch, to install via pip:
 
 | PyTorch Version   | IPEX version   |
 | :---------------: | :----------:   |
 | 2.0               |  2.0.0         |
 | 1.13              |  1.13.0        |
 | 1.12              |  1.12.300      |
 | 1.11              |  1.11.200      |
 | 1.10              |  1.10.100      |
 
 ```
 pip install intel_extension_for_pytorch==<version_name> -f https://developer.intel.com/ipex-whl-stable-cpu
 ```
 
 Check more approaches for [IPEX installation](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/installation.html).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/ipex#ipex-installation,False,598,169,https://huggingface.co
758,How It Works For Training optimization in CPU,"🤗 Accelerate has integrated [IPEX](https://github.com/intel/intel-extension-for-pytorch), all you need to do is enabling it through the config.
 
 **Scenario 1**: Acceleration of No distributed CPU training
 
 Run <u>accelerate config</u> on your machine:
 
 ```bash",H2,https://huggingface.co/docs/accelerate/source/usage_guides/ipex#how-it-works-for-training-optimization-in-cpu,False,266,34,https://huggingface.co
761,Checkpointing,"When training a PyTorch model with 🤗 Accelerate, you may often want to save and continue a state of training. Doing so requires",H1,https://huggingface.co/docs/accelerate/source/usage_guides/checkpoint#checkpointing,False,127,23,https://huggingface.co
762,Restoring the state of the DataLoader,"After resuming from a checkpoint, it may also be desirable to resume from a particular point in the active `DataLoader` if 
 the state was saved during the middle of an epoch. You can use [`~Accelerator.skip_first_batches`] to do so. 
 
 ```python
 from accelerate import Accelerator
 
 accelerator = Accelerator(project_dir=""my/save/path"")
 
 train_dataloader = accelerator.prepare(train_dataloader)
 accelerator.load_state(""my_state"")",H2,https://huggingface.co/docs/accelerate/source/usage_guides/checkpoint#restoring-the-state-of-the-dataloader,False,436,55,https://huggingface.co
764,Performing gradient accumulation with 🤗 Accelerate,"Gradient accumulation is a technique where you can train on bigger batch sizes than 
 your machine would normally be able to fit into memory. This is done by accumulating gradients over
 several batches, and only stepping the optimizer after a certain number of batches have been performed.
 
 While technically standard gradient accumulation code would work fine in a distributed setup, it is not the most efficient
 method for doing so and you may experience considerable slowdowns!
 
 In this tutorial you will see how to quickly setup gradient accumulation and perform it with the utilities provided in 🤗 Accelerate,
 which can total to adding just one new line of code!
 
 This example will use a very simplistic PyTorch training loop that performs gradient accumulation every two batches:
 
 ```python
 device = ""cuda""
 model.to(device)
 
 gradient_accumulation_steps = 2
 
 for index, batch in enumerate(training_dataloader):
     inputs, targets = batch
     inputs = inputs.to(device)
     targets = targets.to(device)
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     loss = loss / gradient_accumulation_steps
     loss.backward()
     if (index + 1) % gradient_accumulation_steps == 0:
         optimizer.step()
         scheduler.step()
         optimizer.zero_grad()
 ```",H1,https://huggingface.co/docs/accelerate/source/usage_guides/gradient_accumulation#performing-gradient-accumulation-with-accelerate,False,1312,237,https://huggingface.co
765,Converting it to 🤗 Accelerate,"First the code shown earlier will be converted to utilize 🤗 Accelerate without the special gradient accumulation helper:
 
 ```diff
 + from accelerate import Accelerator
 + accelerator = Accelerator()
 
 + model, optimizer, training_dataloader, scheduler = accelerator.prepare(
 +     model, optimizer, training_dataloader, scheduler
 + )
 
   for index, batch in enumerate(training_dataloader):",H2,https://huggingface.co/docs/accelerate/source/usage_guides/gradient_accumulation#converting-it-to-accelerate,False,395,56,https://huggingface.co
766,Letting 🤗 Accelerate handle gradient accumulation,"All that is left now is to let 🤗 Accelerate handle the gradient accumulation for us. To do so you should pass in a `gradient_accumulation_steps` parameter to [`Accelerator`], dictating the number 
 of steps to perform before each call to `step()` and how to automatically adjust the loss during the call to [`~Accelerator.backward`]:
 
 ```diff",H2,https://huggingface.co/docs/accelerate/source/usage_guides/gradient_accumulation#letting-accelerate-handle-gradient-accumulation,False,344,55,https://huggingface.co
767,The finished code,"Below is the finished implementation for performing gradient accumulation with 🤗 Accelerate
 
 ```python
 from accelerate import Accelerator
 accelerator = Accelerator(gradient_accumulation_steps=2)
 model, optimizer, training_dataloader, scheduler = accelerator.prepare(
     model, optimizer, training_dataloader, scheduler
 )
 for batch in training_dataloader:
     with accelerator.accumulate(model):
         inputs, targets = batch
         outputs = model(inputs)
         loss = loss_function(outputs, targets)
         accelerator.backward(loss)
         optimizer.step()
         scheduler.step()
         optimizer.zero_grad()
 ```
 
 <Tip warning={true}>
 
 It's important that **only one forward/backward** should be done inside the context manager `with accelerator.accumulate(model)`.
 
 </Tip>
 
 
 To learn more about what magic this wraps around, read the [Gradient Synchronization concept guide](../concept_guides/gradient_synchronization)",H2,https://huggingface.co/docs/accelerate/source/usage_guides/gradient_accumulation#the-finished-code,False,958,156,https://huggingface.co
768,Self-contained example,"Here is a self-contained example that you can run to see gradient accumulation in action with 🤗 Accelerate:
 
 ```python
 import torch
 import copy
 from accelerate import Accelerator
 from accelerate.utils import set_seed
 from torch.utils.data import TensorDataset, DataLoader",H2,https://huggingface.co/docs/accelerate/source/usage_guides/gradient_accumulation#self-contained-example,False,278,37,https://huggingface.co
770,Memory Utilities,"One of the most frustrating errors when it comes to running training scripts is hitting ""CUDA Out-of-Memory"", 
 as the entire script needs to be restarted, progress is lost, and typically a developer would want to simply
 start their script and let it run.
 
 `Accelerate` provides a utility heavily based on [toma](https://github.com/BlackHC/toma) to give this capability.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/memory#memory-utilities,False,373,57,https://huggingface.co
771,find_executable_batch_size,"This algorithm operates with exponential decay, decreasing the batch size in half after each failed run on some 
 training script. To use it, restructure your training function to include an inner function that includes this wrapper, 
 and build your dataloaders inside it. At a minimum, this could look like 4 new lines of code. 
 > Note: The inner function *must* take in the batch size as the first parameter, but we do not pass one to it when called. The wrapper handles this for us
 
 It should also be noted that anything which will consume CUDA memory and passed to the `accelerator` **must** be declared inside the inner function,
 such as models and optimizers.
 
 ```diff
 def training_function(args):
     accelerator = Accelerator()
 
 +   @find_executable_batch_size(starting_batch_size=args.batch_size)
 +   def inner_training_loop(batch_size):
 +       nonlocal accelerator # Ensure they can be used in our context
 +       accelerator.free_memory() # Free all lingering references
         model = get_model()
         model.to(accelerator.device)
         optimizer = get_optimizer()
         train_dataloader, eval_dataloader = get_dataloaders(accelerator, batch_size)
         lr_scheduler = get_scheduler(
             optimizer, 
             num_training_steps=len(train_dataloader)*num_epochs
         )
         model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(
             model, optimizer, train_dataloader, eval_dataloader, lr_scheduler
         )
         train(model, optimizer, train_dataloader, lr_scheduler)
         validate(model, eval_dataloader)
 +   inner_training_loop()
 ```
 
 To find out more, check the documentation [here](../package_reference/utilities#accelerate.find_executable_batch_size).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/memory#find-executable-batch-size,False,1776,338,https://huggingface.co
773,DeepSpeed,"[DeepSpeed](https://github.com/microsoft/DeepSpeed) implements everything described in the [ZeRO paper](https://arxiv.org/abs/1910.02054). Currently, it provides full support for:
 
 1. Optimizer state partitioning (ZeRO stage 1)
 2. Gradient partitioning (ZeRO stage 2)
 3. Parameter partitioning (ZeRO stage 3)
 4. Custom mixed precision training handling
 5. A range of fast CUDA-extension-based optimizers
 6. ZeRO-Offload to CPU and Disk/NVMe
 
 ZeRO-Offload has its own dedicated paper: [ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840). And NVMe-support is described in the paper [ZeRO-Infinity: Breaking the GPU
 Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857).
 
 DeepSpeed ZeRO-2 is primarily used only for training, as its features are of no use to inference.
 
 DeepSpeed ZeRO-3 can be used for inference as well since it allows huge models to be loaded on multiple GPUs, which
 won't be possible on a single GPU.
 
 🤗 Accelerate integrates [DeepSpeed](https://github.com/microsoft/DeepSpeed) via 2 options:
 
 1. Integration of the DeepSpeed features via `deepspeed config file` specification in `accelerate config` . You just supply your custom config file or use our template. Most of
    this document is focused on this feature. This supports all the core features of DeepSpeed and gives user a lot of flexibility. 
    User may have to change a few lines of code depending on the config.
 2. Integration via `deepspeed_plugin`.This supports subset of the DeepSpeed features and uses default options for the rest of the configurations. 
    User need not change any code and is good for those who are fine with most of the default settings of DeepSpeed.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#deepspeed,False,1744,256,https://huggingface.co
774,What is integrated?,"Training:
 
 1. DeepSpeed ZeRO training supports the full ZeRO stages 1, 2 and 3 as well as CPU/Disk offload of optimizer states, gradients and parameters. 
 Below is a short description of Data Parallelism using ZeRO - Zero Redundancy Optimizer along with diagram from this [blog post](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)
 ![ZeRO Data Parallelism](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-zero.png)
 
 (Source: [link](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/))
 
  a. **Stage 1** : Shards optimizer states across data parallel workers/GPUs
 
  b. **Stage 2** : Shards optimizer states + gradients across data parallel workers/GPUs
 
  c. **Stage 3**: Shards optimizer states + gradients + model parameters across data parallel workers/GPUs
 
  d. **Optimizer Offload**: Offloads the gradients + optimizer states to CPU/Disk building on top of ZERO Stage 2
 
  e. **Param Offload**: Offloads the model parameters to CPU/Disk building on top of ZERO Stage 3
 
 <u>Note</u>: With respect to Disk Offload, the disk should be an NVME for decent speed but it technically works on any Disk
 
 Inference:
 
 1. DeepSpeed ZeRO Inference supports ZeRO stage 3 with ZeRO-Infinity. It uses the same ZeRO protocol as training, but
    it doesn't use an optimizer and a lr scheduler and only stage 3 is relevant. For more details see:
    [deepspeed-zero-inference](#deepspeed-zero-inference).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#what-is-integrated,False,1639,208,https://huggingface.co
775,How it works?,"**Pre-Requisites**: Install DeepSpeed version >=0.6.5. Please refer to the [DeepSpeed Installation details](https://github.com/microsoft/DeepSpeed#installation)
 for more information.
 
 We will first look at easy to use integration via `accelerate config`. 
 Followed by more flexible and feature rich `deepspeed config file` integration.",H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#how-it-works,False,339,40,https://huggingface.co
776,Accelerate DeepSpeed Plugin,"On your machine(s) just run:
 
 ```bash
 accelerate config
 ```
 
 and answer the questions asked. It will ask whether you want to use a config file for DeepSpeed to which you should answer no. Then answer the following questions to generate a basic DeepSpeed config.
 This will generate a config file that will be used automatically to properly set the
 default options when doing
 
 ```bash
 accelerate launch my_script.py --args_to_my_script
 ```
 
 For instance, here is how you would run the NLP example `examples/nlp_example.py` (from the root of the repo) with DeepSpeed Plugin:
 
 **ZeRO Stage-2 DeepSpeed Plugin Example**
 ```bash
 compute_environment: LOCAL_MACHINE
 deepspeed_config:
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  offload_optimizer_device: none
  offload_param_device: none
  zero3_init_flag: true
  zero_stage: 2
 distributed_type: DEEPSPEED
 fsdp_config: {}
 machine_rank: 0
 main_process_ip: null
 main_process_port: null
 main_training_function: main
 mixed_precision: fp16
 num_machines: 1
 num_processes: 2
 use_cpu: false
 ```
 
 ```bash
 accelerate launch examples/nlp_example.py --mixed_precision fp16
 ```
 
 **ZeRO Stage-3 with CPU Offload DeepSpeed Plugin Example**
 ```bash
 compute_environment: LOCAL_MACHINE
 deepspeed_config:
   gradient_accumulation_steps: 1
   gradient_clipping: 1.0
   offload_optimizer_device: cpu
   offload_param_device: cpu
   zero3_init_flag: true
   zero3_save_16bit_model: true
   zero_stage: 3
 distributed_type: DEEPSPEED
 fsdp_config: {}
 machine_rank: 0
 main_process_ip: null
 main_process_port: null
 main_training_function: main
 mixed_precision: fp16
 num_machines: 1
 num_processes: 2
 use_cpu: false
 ```
 
 ```bash
 accelerate launch examples/nlp_example.py --mixed_precision fp16
 ```
 
 Currently, `Accelerate` supports following config through the CLI:
 
 ```bash
 `zero_stage`: [0] Disabled, [1] optimizer state partitioning, [2] optimizer+gradient state partitioning and [3] optimizer+gradient+parameter partitioning
 `gradient_accumulation_steps`: Number of training steps to accumulate gradients before averaging and applying them.
 `gradient_clipping`: Enable gradient clipping with value.
 `offload_optimizer_device`: [none] Disable optimizer offloading, [cpu] offload optimizer to CPU, [nvme] offload optimizer to NVMe SSD. Only applicable with ZeRO >= Stage-2.
 `offload_param_device`: [none] Disable parameter offloading, [cpu] offload parameters to CPU, [nvme] offload parameters to NVMe SSD. Only applicable with ZeRO Stage-3.
 `zero3_init_flag`: Decides whether to enable `deepspeed.zero.Init` for constructing massive models. Only applicable with ZeRO Stage-3.
 `zero3_save_16bit_model`: Decides whether to save 16-bit model weights when using ZeRO Stage-3.
 `mixed_precision`: `no` for FP32 training, `fp16` for FP16 mixed-precision training and `bf16` for BF16 mixed-precision training. 
 ```
 To be able to tweak more options, you will need to use a DeepSpeed config file.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#accelerate-deepspeed-plugin,False,2986,370,https://huggingface.co
777,DeepSpeed Config File,"On your machine(s) just run:
 
 ```bash
 accelerate config
 ```
 
 and answer the questions asked. It will ask whether you want to use a config file for deepspeed to which you answer yes 
 and provide the path to the deepspeed config file. 
 This will generate a config file that will be used automatically to properly set the
 default options when doing
 
 ```bash
 accelerate launch my_script.py --args_to_my_script
 ```
 
 For instance, here is how you would run the NLP example `examples/by_feature/deepspeed_with_config_support.py` (from the root of the repo) with DeepSpeed Config File:
 
 **ZeRO Stage-2 DeepSpeed Config File Example**
 ```bash
 compute_environment: LOCAL_MACHINE
 deepspeed_config:
  deepspeed_config_file: /home/ubuntu/accelerate/examples/configs/deepspeed_config_templates/zero_stage2_config.json
  zero3_init_flag: true
 distributed_type: DEEPSPEED
 fsdp_config: {}
 machine_rank: 0
 main_process_ip: null
 main_process_port: null
 main_training_function: main
 mixed_precision: fp16
 num_machines: 1
 num_processes: 2
 use_cpu: false
 ```
 
 with the contents of `zero_stage2_config.json` being:
 ```json
 {
     ""fp16"": {
         ""enabled"": true,
         ""loss_scale"": 0,
         ""loss_scale_window"": 1000,
         ""initial_scale_power"": 16,
         ""hysteresis"": 2,
         ""min_loss_scale"": 1
     },
     ""optimizer"": {
         ""type"": ""AdamW"",
         ""params"": {
             ""lr"": ""auto"",
             ""weight_decay"": ""auto"",
             ""torch_adam"": true,
             ""adam_w_mode"": true
         }
     },
     ""scheduler"": {
         ""type"": ""WarmupDecayLR"",
         ""params"": {
             ""warmup_min_lr"": ""auto"",
             ""warmup_max_lr"": ""auto"",
             ""warmup_num_steps"": ""auto"",
             ""total_num_steps"": ""auto""
         }
     },
     ""zero_optimization"": {
         ""stage"": 2,
         ""allgather_partitions"": true,
         ""allgather_bucket_size"": 2e8,
         ""overlap_comm"": true,
         ""reduce_scatter"": true,
         ""reduce_bucket_size"": ""auto"",
         ""contiguous_gradients"": true
     },
     ""gradient_accumulation_steps"": 1,
     ""gradient_clipping"": ""auto"",
     ""steps_per_print"": 2000,
     ""train_batch_size"": ""auto"",
     ""train_micro_batch_size_per_gpu"": ""auto"",
     ""wall_clock_breakdown"": false
 }
 ```
 
 ```bash",H3,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#deepspeed-config-file,False,2317,525,https://huggingface.co
778,Saving and loading,"1. Saving and loading of models is unchanged for ZeRO Stage-1 and Stage-2.
 
 2. under ZeRO Stage-3, `state_dict` contains just the placeholders since the model weights are partitioned across multiple GPUs.
 ZeRO Stage-3 has 2 options:
 
    a. Saving the entire 16bit model weights to directly load later on using `model.load_state_dict(torch.load(pytorch_model.bin))`.
    For this, either set `zero_optimization.stage3_gather_16bit_weights_on_model_save` to True in DeepSpeed Config file or set
    `zero3_save_16bit_model` to True in DeepSpeed Plugin. 
    **Note that this option requires consolidation of the weights on one GPU it can be slow and memory demanding, so only use this feature when needed.**
    Below is the snippet from `examples/by_feature/deepspeed_with_config_support.py` showing this:
    ```python
    unwrapped_model = accelerator.unwrap_model(model)
 
    # New Code #
    # Saves the whole/unpartitioned fp16 model when in ZeRO Stage-3 to the output directory if
    # `stage3_gather_16bit_weights_on_model_save` is True in DeepSpeed Config file or
    # `zero3_save_16bit_model` is True in DeepSpeed Plugin.
    # For Zero Stages 1 and 2, models are saved as usual in the output directory.
    # The model name saved is `pytorch_model.bin`
    unwrapped_model.save_pretrained(
        args.output_dir,
        is_main_process=accelerator.is_main_process,
        save_function=accelerator.save,
        state_dict=accelerator.get_state_dict(model),
    )
    ```
 
    b. To get 32bit weights, first save the model using `model.save_checkpoint()`.
    Below is the snippet from `examples/by_feature/deepspeed_with_config_support.py` showing this:
    ```python
    success = model.save_checkpoint(PATH, ckpt_id, checkpoint_state_dict)
    status_msg = ""checkpointing: PATH={}, ckpt_id={}"".format(PATH, ckpt_id)
    if success:
        logging.info(f""Success {status_msg}"")
    else:
        logging.warning(f""Failure {status_msg}"")
    ``` 
    This will create ZeRO model and optimizer partitions along with `zero_to_fp32.py` script in checkpoint directory.
    You can use this script to do offline consolidation.  
    It requires no configuration files or GPUs. Here is an example of its usage:  
    ```bash
    $ cd /path/to/checkpoint_dir
    $ ./zero_to_fp32.py . pytorch_model.bin
    Processing zero checkpoint at global_step1
    Detected checkpoint of type zero stage 3, world_size: 2
    Saving fp32 state dict to pytorch_model.bin (total_numel=60506624)
    ```
    To get 32bit model for saving/inference, you can perform:
    ```python
    from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint
 
    unwrapped_model = accelerator.unwrap_model(model)
    fp32_model = load_state_dict_from_zero_checkpoint(unwrapped_model, checkpoint_dir)
    ```
    If you are only interested in the `state_dict`, you can do the following:
    ```python
    from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint
 
    state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)
    ```
    Note that all these functions require ~2x memory (general RAM) of the size of the final checkpoint.",H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#saving-and-loading,False,3180,532,https://huggingface.co
779,ZeRO Inference,"DeepSpeed ZeRO Inference supports ZeRO stage 3 with ZeRO-Infinity. 
 It uses the same ZeRO protocol as training, but it doesn't use an optimizer and a lr scheduler and only stage 3 is relevant.
 With accelerate integration, you just need to prepare the model and dataloader as shown below:
 
 ```python
 model, eval_dataloader = accelerator.prepare(model, eval_dataloader)
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#zero-inference,False,377,57,https://huggingface.co
780,Few caveats to be aware of,"1. Current integration doesn’t support Pipeline Parallelism of DeepSpeed.
 2. Current integration doesn’t support `mpu`, limiting the tensor parallelism which is supported in Megatron-LM. 
 3. Current integration doesn’t support multiple models.",H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#few-caveats-to-be-aware-of,False,245,32,https://huggingface.co
781,DeepSpeed Resources,The documentation for the internals related to deepspeed can be found [here](../package_reference/deepspeed).,H2,https://huggingface.co/docs/accelerate/source/usage_guides/deepspeed#deepspeed-resources,False,109,12,https://huggingface.co
783,Fully Sharded Data Parallel,"To accelerate training huge models on larger batch sizes, we can use a fully sharded data parallel model.
 This type of data parallel paradigm enables fitting more data and larger models by sharding the optimizer states, gradients and parameters.
 To read more about it and the benefits, check out the [Fully Sharded Data Parallel blog](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/).
 We have integrated the latest PyTorch's Fully Sharded Data Parallel (FSDP) training feature.
 All you need to do is enable it through the config.",H1,https://huggingface.co/docs/accelerate/source/usage_guides/fsdp#fully-sharded-data-parallel,False,563,79,https://huggingface.co
784,How it works out of the box,"On your machine(s) just run:
 
 ```bash
 accelerate config
 ```
 
 and answer the questions asked. This will generate a config file that will be used automatically to properly set the
 default options when doing
 
 ```bash
 accelerate launch my_script.py --args_to_my_script
 ```
 
 For instance, here is how you would run the NLP example (from the root of the repo) with FSDP enabled:
 
 ```bash
 compute_environment: LOCAL_MACHINE
 deepspeed_config: {}
 distributed_type: FSDP
 downcast_bf16: 'no'
 fsdp_config:
   fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
   fsdp_backward_prefetch_policy: BACKWARD_PRE
   fsdp_offload_params: false
   fsdp_sharding_strategy: 1
   fsdp_state_dict_type: FULL_STATE_DICT
   fsdp_transformer_layer_cls_to_wrap: GPT2Block
 machine_rank: 0
 main_process_ip: null
 main_process_port: null
 main_training_function: main
 mixed_precision: 'no'
 num_machines: 1
 num_processes: 2
 use_cpu: false
 ```
 
 ```bash
 accelerate launch examples/nlp_example.py
 ```
 
 Currently, `Accelerate` supports the following config through the CLI:
 
 ```bash
 `Sharding Strategy`: [1] FULL_SHARD (shards optimizer states, gradients and parameters), [2] SHARD_GRAD_OP (shards optimizer states and gradients), [3] NO_SHARD
 `Offload Params`: Decides Whether to offload parameters and gradients to CPU
 `Auto Wrap Policy`: [1] TRANSFORMER_BASED_WRAP, [2] SIZE_BASED_WRAP, [3] NO_WRAP [4] ""HYBRID_SHARD"" [5] ""HYBRID_SHARD_ZERO2""
 `Transformer Layer Class to Wrap`: When using `TRANSFORMER_BASED_WRAP`, user specifies comma-separated string of transformer layer class names (case-sensitive) to wrap ,e.g, 
 `BertLayer`, `GPTJBlock`, `T5Block`, `BertLayer,BertEmbeddings,BertSelfOutput`...
 `Min Num Params`: minimum number of parameters when using `SIZE_BASED_WRAP`
 `Backward Prefetch`: [1] BACKWARD_PRE, [2] BACKWARD_POST, [3] NO_PREFETCH
 `State Dict Type`: [1] FULL_STATE_DICT, [2] LOCAL_STATE_DICT, [3] SHARDED_STATE_DICT  
 `Use Orig Params`: If True, allows non-uniform `requires_grad` during init, which means support for interspersed frozen and trainable paramteres. 
 Useful in cases such as parameter-efficient fine-tuning. 
 Please refer this [blog](https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019)
 `Sync Module States`: If True, each individually wrapped FSDP unit will broadcast module parameters from rank 0
 `Forward Prefetch`: If True, then FSDP explicitly prefetches the next upcoming all-gather while executing in the forward pass
 ```
 
 For additional and more nuanced control, you can specify other FSDP parameters via `FullyShardedDataParallelPlugin`. 
 When creating `FullyShardedDataParallelPlugin` object, pass it the parameters that weren't part of the accelerate config or if you want to override them.
 The FSDP parameters will be picked based on the accelerate config file or launch command arguments and other parameters that you will pass directly through the `FullyShardedDataParallelPlugin` object will set/override that.
 
 Below is an example:
 
 ```py
 from accelerate import FullyShardedDataParallelPlugin
 from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig
 
 fsdp_plugin = FullyShardedDataParallelPlugin(
     state_dict_config=FullStateDictConfig(offload_to_cpu=False, rank0_only=False),
     optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=False, rank0_only=False),
 )
 
 accelerator = Accelerator(fsdp_plugin=fsdp_plugin)
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/fsdp#how-it-works-out-of-the-box,False,3522,406,https://huggingface.co
785,Saving and loading,"The new recommended way of checkpointing when using FSDP models is to use `SHARDED_STATE_DICT` as `StateDictType` when setting up the accelerate config.
 Below is the code snippet to save using `save_state` utility of accelerate.
 
 ```py
 accelerator.save_state(""ckpt"")
 ```
 
 Inspect the ckeckpoint folder to see model and optimizer as shards per process:
 ```
 ls ckpt",H2,https://huggingface.co/docs/accelerate/source/usage_guides/fsdp#saving-and-loading,False,372,55,https://huggingface.co
786,State Dict,"`accelerator.get_state_dict` will call the underlying `model.state_dict` implementation.  With a model wrapped by FSDP, the default behavior of `state_dict` is to gather all of the state in the rank 0 device.  This can cause CUDA out of memory errors if the parameters don't fit on a single GPU.
 
 To avoid this, PyTorch provides a context manager that adjusts the behavior of `state_dict`.  To offload some of the state dict onto CPU, you can use the following code:
 
 ```
 from torch.distributed.fsdp import FullyShardedDataParallel as FSDP, StateDictType, FullStateDictConfig
 
 full_state_dict_config = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)
 with FSDP.state_dict_type(unwrapped_model, StateDictType.FULL_STATE_DICT, full_state_dict_config):
     state = accelerator.get_state_dict(unwrapped_model)
 ```
 
 You can then pass `state` into the `save_pretrained` method.  There are several modes for `StateDictType` and `FullStateDictConfig` that you can use to control the behavior of `state_dict`.  For more information, see the [PyTorch documentation](https://pytorch.org/docs/stable/fsdp.html).",H3,https://huggingface.co/docs/accelerate/source/usage_guides/fsdp#state-dict,False,1120,144,https://huggingface.co
790,`bitsandbytes` Integration,"🤗 Accelerate brings `bitsandbytes` quantization to your model. You can now load any pytorch model in 8-bit or 4-bit with a few lines of code.
 
 If you want to use 🤗 Transformers models with `bitsandbytes`, you should follow this [documentation](https://huggingface.co/docs/transformers/main_classes/quantization). 
 
 To learn more about how the `bitsandbytes` quantization works, check out the blog posts on [8-bit quantization](https://huggingface.co/blog/hf-bitsandbytes-integration) and [4-bit quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#bitsandbytes-integration,False,573,63,https://huggingface.co
792,How it works,"First, we need to initialize our model. To save memory, we can initialize an empty model using the context manager [`init_empty_weights`]. 
 
 Let's take the GPT2 model from minGPT library.
 ```py
 from accelerate import init_empty_weights
 from mingpt.model import GPT
 
 model_config = GPT.get_default_config()
 model_config.model_type = 'gpt2-xl'
 model_config.vocab_size = 50257
 model_config.block_size = 1024
 
 with init_empty_weights():
     empty_model = GPT(model_config)
 ```
 
 Then, we need to get the path to the weights of your model. The path can be the state_dict file (e.g. ""pytorch_model.bin"") or a folder containing the sharded checkpoints. 
 
 ```py
 from huggingface_hub import snapshot_download
 weights_location = snapshot_download(repo_id=""marcsun13/gpt2-xl-linear-sharded"")
 ```
 
 Finally, you need to set your quantization configuration with [`~utils.BnbQuantizationConfig`].
 
 Here's an example for 8-bit quantization:
 ```py
 from accelerate.utils import BnbQuantizationConfig
 bnb_quantization_config = BnbQuantizationConfig(load_in_8bit=True, llm_int8_threshold = 6)
 ```
 
 Here's an example for 4-bit quantization:
 ```py
 from accelerate.utils import BnbQuantizationConfig
 bnb_quantization_config = BnbQuantizationConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=""nf4"")
 ```
 
 To quantize your empty model with the selected configuration, you need to use [`~utils.load_and_quantize_model`]. 
 
 ```py
 from accelerate.utils import load_and_quantize_model
 quantized_model = load_and_quantize_model(empty_model, weights_location=weights_location, bnb_quantization_config=bnb_quantization_config, device_map = ""auto"")
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#how-it-works,False,1726,185,https://huggingface.co
793,Saving and loading 8-bit model,"You can save your 8-bit model with accelerate using [`~Accelerator.save_model`]. 
 
 ```py
 from accelerate import Accelerator
 accelerate = Accelerator()
 new_weights_location = ""path/to/save_directory""
 accelerate.save_model(quantized_model, new_weights_location)
 
 quantized_model_from_saved = load_and_quantize_model(empty_model, weights_location=new_weights_location, bnb_quantization_config=bnb_quantization_config, device_map = ""auto"")
 ```
 
 Note that 4-bit model serialization is currently not supported.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#saving-and-loading-8-bit-model,False,515,45,https://huggingface.co
794,Offload modules to cpu and disk,"You can offload some modules to cpu/disk if you don't have enough space on the GPU to store the entire model on your GPUs.
 This uses big model inference under the hood. Check this [documentation](https://huggingface.co/docs/accelerate/usage_guides/big_modeling) for more details. 
 
 For 8-bit quantization, the selected modules will be converted to 8-bit precision. 
 
 For 4-bit quantization, the selected modules will be kept in `torch_dtype` that the user passed in `BnbQuantizationConfig`.  We will add support to convert these offloaded modules in 4-bit when 4-bit serialization will be possible. 
 
  You just need to pass a custom `device_map` in order to offload modules on cpu/disk. The offload modules will be dispatched on the GPU when needed. Here's an example :
 
 ```py
 device_map = {
     ""transformer.wte"": 0,
     ""transformer.wpe"": 0,
     ""transformer.drop"": 0,
     ""transformer.h"": ""cpu"",
     ""transformer.ln_f"": ""disk"",
     ""lm_head"": ""disk"",
 }
 ```",H3,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#offload-modules-to-cpu-and-disk,False,977,165,https://huggingface.co
795,Fine-tune a quantized model,"It is not possible to perform pure 8bit or 4bit training on these models. However, you can train these models by leveraging parameter efficient fine tuning methods (PEFT) and train for example adapters on top of them. Please have a look at [peft](https://github.com/huggingface/peft) library for more details.
 
 Currently, you can't add adapters on top of any quantized model. However, with the official support of adapters with 🤗 Transformers models, you can fine-tune quantized models. If you want to finetune a 🤗 Transformers model , follow this [documentation](https://huggingface.co/docs/transformers/main_classes/quantization) instead. Check out this [demo](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing) on how to fine-tune a 4-bit 🤗 Transformers model. 
 
 Note that you don’t need to pass `device_map` when loading the model for training. It will automatically load your model on your GPU. Please note that `device_map=auto` should be used for inference only.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#fine-tune-a-quantized-model,False,1009,137,https://huggingface.co
796,Example demo - running GPT2 1.5b on a Google Colab,"Check out the Google Colab [demo](https://colab.research.google.com/drive/1T1pOgewAWVpR9gKpaEWw4orOrzPFb3yM?usp=sharing) for running quantized models on a GTP2 model. The GPT2-1.5B model checkpoint is in FP32 which uses 6GB of memory. After quantization, it uses 1.6GB with 8-bit modules and 1.2GB with 4-bit modules.",H3,https://huggingface.co/docs/accelerate/source/usage_guides/quantization#example-demo-running-gpt2-15b-on-a-google-colab,False,317,39,https://huggingface.co
798,Accelerated PyTorch Training on Mac,"With PyTorch v1.12 release, developers and researchers can take advantage of Apple silicon GPUs for significantly faster model training. 
 This unlocks the ability to perform machine learning workflows like prototyping and fine-tuning locally, right on Mac.
 Apple's Metal Performance Shaders (MPS) as a backend for PyTorch enables this and can be used via the new `""mps""` device. 
 This will map computational graphs and primitives on the MPS Graph framework and tuned kernels provided by MPS.
 For more information please refer official documents [Introducing Accelerated PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)
 and [MPS BACKEND](https://pytorch.org/docs/stable/notes/mps.html).",H1,https://huggingface.co/docs/accelerate/source/usage_guides/mps#accelerated-pytorch-training-on-mac,False,741,93,https://huggingface.co
799,Benefits of Training and Inference using Apple Silicon Chips,"1. Enables users to train larger networks or batch sizes locally
 2. Reduces data retrieval latency and provides the GPU with direct access to the full memory store due to unified memory architecture. 
 Therefore, improving end-to-end performance.
 3. Reduces costs associated with cloud-based development or the need for additional local GPUs.
 
 **Pre-requisites**: To install torch with mps support, 
 please follow this nice medium article [GPU-Acceleration Comes to PyTorch on M1 Macs](https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1).",H3,https://huggingface.co/docs/accelerate/source/usage_guides/mps#benefits-of-training-and-inference-using-apple-silicon-chips,False,590,74,https://huggingface.co
800,How it works out of the box,"It is enabled by default on MacOs machines with MPS enabled Apple Silicon GPUs.
 To disable it, pass `--cpu` flag to `accelerate launch` command or answer the corresponding question when answering the `accelerate config` questionnaire.
 
 You can directly run the following script to test it out on MPS enabled Apple Silicon machines:
 ```bash
 accelerate launch /examples/cv_example.py --data_dir images
 ```",H2,https://huggingface.co/docs/accelerate/source/usage_guides/mps#how-it-works-out-of-the-box,False,409,60,https://huggingface.co
801,A few caveats to be aware of,"1. We strongly recommend to install PyTorch >= 1.13 (nightly version at the time of writing) on your MacOS machine. 
 It has major fixes related to model correctness and performance improvements for transformer based models.
 Please refer to https://github.com/pytorch/pytorch/issues/82707 for more details.
 2. Distributed setups `gloo` and `nccl` are not working with `mps` device. 
 This means that currently only single GPU of `mps` device type can be used.
 
 Finally, please, remember that, 🤗 `Accelerate` only integrates MPS backend, therefore if you
 have any problems or questions with regards to MPS backend usage, please, file an issue with [PyTorch GitHub](https://github.com/pytorch/pytorch/issues).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/mps#a-few-caveats-to-be-aware-of,False,712,102,https://huggingface.co
803,Using Local SGD with 🤗 Accelerate,"Local SGD is a technique for distributed training where gradients are not synchronized every step. Thus, each process updates its own version of the model weights and after a given number of steps these weights are synchronized by averaging across all processes. This improves communication efficiency and can lead to substantial training speed up especially when a computer lacks a faster interconnect such as NVLink.
 Unlike gradient accumulation (where improving communication efficiency requires increasing the effective batch size), Local SGD does not require changing a batch size or a learning rate / schedule. However, if necessary, Local SGD can be combined with gradient accumulation as well.
 
 In this tutorial you will see how to quickly setup  Local SGD 🤗 Accelerate. Compared to a standard Accelerate setup, this requires only two extra lines of code.
 
 This example will use a very simplistic PyTorch training loop that performs gradient accumulation every two batches:
 
 ```python
 device = ""cuda""
 model.to(device)
 
 gradient_accumulation_steps = 2
 
 for index, batch in enumerate(training_dataloader):
     inputs, targets = batch
     inputs = inputs.to(device)
     targets = targets.to(device)
     outputs = model(inputs)
     loss = loss_function(outputs, targets)
     loss = loss / gradient_accumulation_steps
     loss.backward()
     if (index + 1) % gradient_accumulation_steps == 0:
         optimizer.step()
         scheduler.step()
         optimizer.zero_grad()
 ```",H1,https://huggingface.co/docs/accelerate/source/usage_guides/local_sgd#using-local-sgd-with-accelerate,False,1504,261,https://huggingface.co
804,Converting it to 🤗 Accelerate,"First the code shown earlier will be converted to use 🤗 Accelerate  with neither a LocalSGD or a gradient accumulation helper:
 
 ```diff
 + from accelerate import Accelerator
 + accelerator = Accelerator()
 
 + model, optimizer, training_dataloader, scheduler = accelerator.prepare(
 +     model, optimizer, training_dataloader, scheduler
 + )
 
   for index, batch in enumerate(training_dataloader):",H2,https://huggingface.co/docs/accelerate/source/usage_guides/local_sgd#converting-it-to-accelerate,False,401,60,https://huggingface.co
805,Letting 🤗 Accelerate handle model synchronization,"All that is left now is to let 🤗 Accelerate handle model parameter synchronization **and** the gradient accumulation for us. For simplicity let us assume we need to synchronize every 8 steps. This is
 achieved by adding one `with LocalSGD` statement and one call `local_sgd.step()` after every optimizer step:
 
 ```diff
 +local_sgd_steps=8
 
 +with LocalSGD(accelerator=accelerator, model=model, local_sgd_steps=8, enabled=True) as local_sgd:
     for batch in training_dataloader:
         with accelerator.accumulate(model):
             inputs, targets = batch
             outputs = model(inputs)
             loss = loss_function(outputs, targets)
             accelerator.backward(loss)
             optimizer.step()
             scheduler.step()
             optimizer.zero_grad()
 +           local_sgd.step()
 ```
 
 Under the hood, the Local SGD code **disables** automatic gradient synchornization (but accumulation still works as expected!). Instead it averages model parameters every `local_sgd_steps` steps (as well as in the end of the training loop).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/local_sgd#letting-accelerate-handle-model-synchronization,False,1067,226,https://huggingface.co
806,Limitations,"The current implementation works only with basic multi-GPU (or multi-CPU) training without, e.g., [DeepSpeed.](https://github.com/microsoft/DeepSpeed).",H2,https://huggingface.co/docs/accelerate/source/usage_guides/local_sgd#limitations,False,151,14,https://huggingface.co
807,References,"Although we are not aware of the true origins of this simple approach, the idea of local SGD is quite old and goes
     back to at least:
 
     Zhang, J., De Sa, C., Mitliagkas, I., & Ré, C. (2016). [Parallel SGD: When does averaging help?. arXiv preprint
     arXiv:1606.07365.](https://arxiv.org/abs/1606.07365)
 
     We credit the term Local SGD to the following paper (but there might be earlier references we are not aware of).
 
     Stich, Sebastian Urban. [""Local SGD Converges Fast and Communicates Little."" ICLR 2019-International Conference on
     Learning Representations. No. CONF. 2019.](https://arxiv.org/abs/1805.09767)",H2,https://huggingface.co/docs/accelerate/source/usage_guides/local_sgd#references,False,638,114,https://huggingface.co
809,Gradient Synchronization,"PyTorch's distributed module operates by communicating back and forth between all of the GPUs in your system.
 This communication takes time, and ensuring all processes know the states of each other happens at particular triggerpoints
 when using the `ddp` module. 
 
 These triggerpoints are added to the PyTorch model, specifically their `forward()` and `backward()` methods. 
 This happens when the model is wrapped with `DistributedDataParallel`:
 ```python
 import torch.nn as nn
 from torch.nn.parallel import DistributedDataParallel
 
 model = nn.Linear(10, 10)
 ddp_model = DistributedDataParallel(model)
 ```
 In 🤗 Accelerate this conversion happens automatically when calling [`~Accelerator.prepare`] and passing in your model.
 
 ```diff
 + from accelerate import Accelerator
 + accelerator = Accelerator()",H1,https://huggingface.co/docs/accelerate/source/concept_guides/gradient_synchronization#gradient-synchronization,False,817,110,https://huggingface.co
810,The slowdown in gradient accumulation,"You now understand that PyTorch adds hooks to the `forward` and `backward` method of your PyTorch model when 
 training in a distributed setup. But how does this risk slowing down your code?
 
 In DDP (distributed data parallel), the specific order in which processes are performed and ran are expected
 at specific points and these must also occur at roughly the same time before moving on.
 
 The most direct example is when you update model parameters through
 `optimizer.step()`.
 Without gradient accumulation, all instances of the model need to have updated
 their gradients computed, collated, and updated before moving on to the next
 batch of data.
 When performing gradient accumulation, you accumulate `n` loss gradients and
 skip `optimizer.step()` until `n` batches have been reached. As all training
 processes only need to sychronize by the time `optimizer.step()` is called,
 without any modification to your training step, this neededless inter-process
 communication can cause a significant slowdown.
 
  How can you avoid this overhead?",H2,https://huggingface.co/docs/accelerate/source/concept_guides/gradient_synchronization#the-slowdown-in-gradient-accumulation,False,1055,163,https://huggingface.co
811,Solving the slowdown problem,"Since you are skipping model parameter updates when training on these batches, their gradients do not need to be synchronized until the point where `optimizer.step()` is actually called. 
 PyTorch cannot automagically tell when you need to do this, but they do provide a tool to help through the [`no_sync`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync) context manager
 that is added to your model after converting it to DDP.
 
 Under this context manager, PyTorch will skip synchronizing the gradients when
 `.backward()` is called, and the first call to `.backward()` outside this 
 context manager will trigger the synchronization. See an example below:
 ```python
 ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)
 
 for index, batch in enumerate(dataloader):
     inputs, targets = batch
     # Trigger gradient synchronization on the last batch
     if index != (len(dataloader) - 1):
         with ddp_model.no_sync():
             # Gradients only accumulate
             outputs = ddp_model(inputs)
             loss = loss_func(outputs)
             accelerator.backward(loss)
     else:
         # Gradients finally sync
         outputs = ddp_model(inputs)
         loss = loss_func(outputs)
         accelerator.backward(loss)
         optimizer.step()
 ```
 
 In 🤗 Accelerate to make this an API that can be called no matter the training device (though it may not do anything if you are not in a distributed system!),
 `ddp_model.no_sync` gets replaced with [`~Accelerator.no_sync`] and operates the same way:
 
 ```diff
   ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)
 
   for index, batch in enumerate(dataloader):
       inputs, targets = batch
       # Trigger gradient synchronization on the last batch",H2,https://huggingface.co/docs/accelerate/source/concept_guides/gradient_synchronization#solving-the-slowdown-problem,False,1892,353,https://huggingface.co
812,"Just how much of a slowdown is there, and easy mistakes you can make","To set up a realistic example, consider the following setup:
 
 * Two single-GPU T4 nodes and one node with two GPUs
 * Each GPU is a T4, and are hosted on GCP
 * The script used is a modification of the [NLP Example](https://github.com/muellerzr/timing_experiments/blob/main/baseline.py) script
 * Batch size per GPU is 16, and gradients are accumulated every 4 steps
 
 All scripts are available in [this repository](https://github.com/muellerzr/timing_experiments).
 
 If not careful about gradient synchronization and GPU communication, a *large* amount of time can be wasted 
 from when these GPUs communicate to each other during unnecessary periods.
 
 By how much?",H2,https://huggingface.co/docs/accelerate/source/concept_guides/gradient_synchronization#just-how-much-of-a-slowdown-is-there-and-easy-mistakes-you-can-make,False,672,101,https://huggingface.co
814,Deferring Executions,"When you run your usual script, instructions are executed in order. Using 🤗 Accelerate to deploy your script on several
 GPUs at the same time introduces a complication: while each process executes all instructions in order, some may be
 faster than others.
 
 You might need to wait for all processes to have reached a certain point before executing a given instruction. For
 instance, you shouldn't save a model before being sure every process is done with training, and you wouldn't want to 
 continue training before all the model weights have been loaded in. To do this, just write the following line in your code:
 
 ```
 accelerator.wait_for_everyone()
 ```
 
 This instruction will block all the processes that arrive first until all the other processes have reached that
 point (if you run your script on just one GPU or CPU, this won't do anything).
 
 A few example cases of when to use this utility are listed below:
 
 <Tip>
 
     Some of these are utilized with the [`~Accelerator.main_process_first`] context manager, which utilizes [`~Accelerator.wait_for_everyone`] to 
     run a particular set of code on the main process beforehand before triggering and launching the other processes
 
 </Tip>",H1,https://huggingface.co/docs/accelerate/source/concept_guides/deferring_execution#deferring-executions,False,1214,205,https://huggingface.co
815,Downloading a Dataset,"When downloading a dataset, you should download it first on the main process and then load the cached dataset afterward
 
 <Tip>
 
     `load_dataset` will perform a lock under the hood to stop multiple downloads from happening at once, but if you are downloading something 
     not using this library you should use this method.
     
 </Tip>
 
 ```python
 with accelerator.main_process_first():
     datasets = load_dataset(""glue"", ""mrpc"")
 ```
 
 Under the hood this is the same as calling: 
 
 ```python",H2,https://huggingface.co/docs/accelerate/source/concept_guides/deferring_execution#downloading-a-dataset,False,508,95,https://huggingface.co
816,Saving the `state_dict`,"When saving the `state_dict` of the model, since you would normally save one file on just the main process
 you should specify that:
 
 ```python
 if accelerator.is_main_process:
     model = accelerator.unwrap_model(model)
     torch.save(model.state_dict(), ""weights.pth"")
 ```",H2,https://huggingface.co/docs/accelerate/source/concept_guides/deferring_execution#saving-the-state-dict,False,279,41,https://huggingface.co
817,Loading in the `state_dict`,"When loading in the `state_dict` to a model, optimizer, or scheduler, you should wait 
 for all workers to have the weights loaded in before moving on to training
 
 ```python
 with accelerator.main_process_first():
     state = torch.load(""weights.pth"")
     model.load_state_dict(state)
 ```",H2,https://huggingface.co/docs/accelerate/source/concept_guides/deferring_execution#loading-in-the-state-dict,False,293,46,https://huggingface.co
818,Applying a multi-worker CPU operation,"Applying a `map()` operation on multiple workers, such as tokenizing should be done on the 
 main process first, and then propagated to each one. 
 
 ```python
 datasets = load_dataset(""glue"", ""mrpc"")
 
 with accelerator.main_process_first():
     tokenized_datasets = datasets.map(
         tokenize_function,
         batched=True,
         remove_columns=[""idx"", ""sentence1"", ""sentence2""],
     )
 ```",H2,https://huggingface.co/docs/accelerate/source/concept_guides/deferring_execution#applying-a-multi-worker-cpu-operation,False,404,77,https://huggingface.co
820,Comparing performance between different device setups,"Evaluating and comparing the performance from different setups can be quite tricky if you don't know what to look for.
 For example, you cannot run the same script with the same batch size across TPU, multi-GPU, and single-GPU with Accelerate 
 and expect your results to line up. 
 
 But why?
 
 There are three reasons for this that this tutorial will cover: 
 
 1. **Setting the right seeds**
 2. **Observed Batch Sizes**
 3. **Learning Rates**",H1,https://huggingface.co/docs/accelerate/source/concept_guides/performance#comparing-performance-between-different-device-setups,False,447,78,https://huggingface.co
821,Setting the Seed,"While this issue has not come up as much, make sure to use [`utils.set_seed`] to fully set the seed in all distributed cases so training will be reproducible:
 
 ```python
 from accelerate.utils import set_seed
 
 set_seed(42)
 ```
 
 Why is this important? Under the hood this will set **5** different seed settings:
 
 ```python
     random.seed(seed)
     np.random.seed(seed)
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
     # ^^ safe to call this function even if cuda is not available
     if is_tpu_available():
         xm.set_rng_state(seed)
 ```
 
 The random state, numpy's state, torch, torch's cuda state, and if TPUs are available torch_xla's cuda state.",H2,https://huggingface.co/docs/accelerate/source/concept_guides/performance#setting-the-seed,False,691,125,https://huggingface.co
822,Observed Batch Sizes,"When training with Accelerate, the batch size passed to the dataloader is the **batch size per GPU**. What this entails is 
 a batch size of 64 on two GPUs is truly a batch size of 128. As a result, when testing on a single GPU this needs to be accounted for,
 as well as similarly for TPUs. 
 
 The below table can be used as a quick reference to try out different batch sizes:
 
 <Tip>
 
 In this example, there are two GPUs for ""Multi-GPU"" and a TPU pod with 8 workers
 
 </Tip>
 
 | Single GPU Batch Size | Multi-GPU Equivalent Batch Size | TPU Equivalent Batch Size |
 |-----------------------|---------------------------------|---------------------------|
 | 256                   | 128                             | 32                        |
 | 128                   | 64                              | 16                        |
 | 64                    | 32                              | 8                         |
 | 32                    | 16                              | 4                         |",H2,https://huggingface.co/docs/accelerate/source/concept_guides/performance#observed-batch-sizes,False,1017,426,https://huggingface.co
823,Learning Rates,"As noted in multiple sources[[1](https://aws.amazon.com/blogs/machine-learning/scalable-multi-node-deep-learning-training-using-gpus-in-the-aws-cloud/)][[2](https://docs.nvidia.com/clara/tlt-mi_archive/clara-train-sdk-v2.0/nvmidl/appendix/training_with_multiple_gpus.html)], the learning rate should be scaled *linearly* based on the number of devices present. The below 
 snippet shows doing so with Accelerate:
 
 <Tip>
 
 Since users can have their own learning rate schedulers defined, we leave this up to the user to decide if they wish to scale their 
 learning rate or not.
  
 </Tip>
 
 ```python
 learning_rate = 1e-3
 accelerator = Accelerator()
 learning_rate *= accelerator.num_processes
 
 optimizer = AdamW(params=model.parameters(), lr=learning_rate)
 ```
 
 You will also find that `accelerate` will step the learning rate based on the number of processes being trained on. This is because 
 of the observed batch size noted earlier. So in the case of 2 GPUs, the learning rate will be stepped twice as often as a single GPU
 to account for the batch size being twice as large (if no changes to the batch size on the single GPU instance are made).",H2,https://huggingface.co/docs/accelerate/source/concept_guides/performance#learning-rates,False,1163,157,https://huggingface.co
824,Gradient Accumulation and Mixed Precision,"When using gradient accumulation and mixed precision, due to how gradient averaging works (accumulation) and the precision loss (mixed precision), 
 some degradation in performance is expected. This will be explicitly seen when comparing the batch-wise loss between different compute 
 setups. However, the overall loss, metric, and general performance at the end of training should be _roughly_ the same.",H2,https://huggingface.co/docs/accelerate/source/concept_guides/performance#gradient-accumulation-and-mixed-precision,False,405,60,https://huggingface.co
826,Training on TPUs with 🤗 Accelerate,"Training on TPUs can be slightly different from training on multi-gpu, even with 🤗 Accelerate. This guide aims to show you 
 where you should be careful and why, as well as the best practices in general.",H1,https://huggingface.co/docs/accelerate/source/concept_guides/training_tpu#training-on-tpus-with-accelerate,False,203,37,https://huggingface.co
827,Training in a Notebook,"The main carepoint when training on TPUs comes from the [`notebook_launcher`]. As mentioned in the [notebook tutorial](../usage_guides/notebook), you need to 
 restructure your training code into a function that can get passed to the [`notebook_launcher`] function and be careful about not declaring any tensors on the GPU.
 
 While on a TPU that last part is not as important, a critical part to understand is that when you launch code from a notebook you do so through a process called **forking**. 
 When launching from the command-line, you perform **spawning**, where a python process is not currently running and you *spawn* a new process in. Since your Jupyter notebook is already 
 utilizing a python process, you need to *fork* a new process from it to launch your code. 
 
 Where this becomes important is in regard to declaring your model. On forked TPU processes, it is recommended that you instantiate your model *once* and pass this into your 
 training function. This is different than training on GPUs where you create `n` models that have their gradients synced and back-propagated at certain moments. Instead, one 
 model instance is shared between all the nodes and it is passed back and forth. This is important especially when training on low-resource TPUs such as those provided in Kaggle kernels or
 on Google Colaboratory. 
 
 Below is an example of a training function passed to the [`notebook_launcher`] if training on CPUs or GPUs:
 
 <Tip>
 
     This code snippet is based off the one from the `simple_nlp_example` notebook found [here](https://github.com/huggingface/notebooks/blob/main/examples/accelerate/simple_nlp_example.ipynb) with slight 
     modifications for the sake of simplicity
 
 </Tip>
 
 ```python
 def training_function():
     # Initialize accelerator
     accelerator = Accelerator()
     model = AutoModelForSequenceClassification.from_pretrained(""bert-base-cased"", num_labels=2)
     train_dataloader, eval_dataloader = create_dataloaders(
         train_batch_size=hyperparameters[""train_batch_size""], eval_batch_size=hyperparameters[""eval_batch_size""]
     )
 
     # Instantiate optimizer
     optimizer = AdamW(params=model.parameters(), lr=hyperparameters[""learning_rate""])
 
     # Prepare everything
     # There is no specific order to remember, we just need to unpack the objects in the same order we gave them to the
     # prepare method.
     model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
         model, optimizer, train_dataloader, eval_dataloader
     )
 
     num_epochs = hyperparameters[""num_epochs""]
     # Now we train the model
     for epoch in range(num_epochs):
         model.train()
         for step, batch in enumerate(train_dataloader):
             outputs = model(**batch)
             loss = outputs.loss
             accelerator.backward(loss)
 
             optimizer.step()
             optimizer.zero_grad()
 ```
 
 ```python
 from accelerate import notebook_launcher
 
 notebook_launcher(training_function)
 ```
 
 <Tip>
 
     The `notebook_launcher` will default to 8 processes if 🤗 Accelerate has been configured for a TPU
 
 </Tip>
 
 If you use this example and declare the model *inside* the training loop, then on a low-resource system you will potentially see an error 
 like:
 
 ```
 ProcessExitedException: process 0 terminated with signal SIGSEGV
 ```
 
 This error is *extremely* cryptic but the basic explanation is you ran out of system RAM. You can avoid this entirely by reconfiguring the training function to 
 accept a single `model` argument, and declare it in an outside cell:
 
 ```python",H2,https://huggingface.co/docs/accelerate/source/concept_guides/training_tpu#training-in-a-notebook,False,3627,647,https://huggingface.co
828,Mixed Precision and Global Variables,"As mentioned in the [mixed precision tutorial](../usage_guides/mixed_precision), 🤗 Accelerate supports fp16 and bf16, both of which can be used on TPUs.
 That being said, ideally `bf16` should be utilized as it is extremely efficient to use.
 
 There are two ""layers"" when using `bf16` and 🤗 Accelerate on TPUs, at the base level and at the operation level. 
 
 At the base level, this is enabled when passing `mixed_precision=""bf16""` to `Accelerator`, such as:
 ```python
 accelerator = Accelerator(mixed_precision=""bf16"")
 ```
 By default, this will cast `torch.float` and `torch.double` to `bfloat16` on TPUs. 
 The specific configuration being set is an environmental variable of `XLA_USE_BF16` is set to `1`.
 
 There is a further configuration you can perform which is setting the `XLA_DOWNCAST_BF16` environmental variable. If set to `1`, then 
 `torch.float` is `bfloat16` and `torch.double` is `float32`.
 
 This is performed in the `Accelerator` object when passing `downcast_bf16=True`:
 ```python
 accelerator = Accelerator(mixed_precision=""bf16"", downcast_bf16=True)
 ```
 
 Using downcasting instead of bf16 everywhere is good for when you are trying to calculate metrics, log values, and more where raw bf16 tensors would be unusable.",H2,https://huggingface.co/docs/accelerate/source/concept_guides/training_tpu#mixed-precision-and-global-variables,False,1249,181,https://huggingface.co
829,Training Times on TPUs,"As you launch your script, you may notice that training seems exceptionally slow at first. This is because TPUs
 first run through a few batches of data to see how much memory to allocate before finally utilizing this configured 
 memory allocation extremely efficiently. 
 
 If you notice that your evaluation code to calculate the metrics of your model takes longer due to a larger batch size being used, 
 it is recommended to keep the batch size the same as the training data if it is too slow. Otherwise the memory will reallocate to this 
 new batch size after the first few iterations. 
 
 <Tip>
 
     Just because the memory is allocated does not mean it will be used or that the batch size will increase when going back to your training dataloader.
 
 </Tip>",H2,https://huggingface.co/docs/accelerate/source/concept_guides/training_tpu#training-times-on-tpus,False,768,143,https://huggingface.co
831,Handling big models for inference,"When loading a pre-trained model in PyTorch, the usual workflow looks like this:
 
 ```py
 import torch
 
 my_model = ModelClass(...)
 state_dict = torch.load(checkpoint_file)
 my_model.load_state_dict(state_dict)
 ```
 
 In plain English, those steps are:
 1. Create the model with randomly initialized weights
 2. Load the model weights (in a dictionary usually called a state dict) from the disk
 3. Load those weights inside the model
 
 While this works very well for regularly sized models, this workflow has some clear limitations when we deal with a huge model: in step 1, we load a full version of the model in RAM, and spend some time randomly initializing the weights (which will be discarded in step 3). In step 2, we load another full version of the model in RAM, with the pre-trained weights. If you're loading a model with 6 billion parameters, this means you will need 24GB of RAM for each copy of the model, so 48GB in total (half of it to load the model in FP16).
 
 <Tip warning={true}>
 
 This API is quite new and still in its experimental stage. While we strive to provide a stable API, it's possible some small parts of the public API will change in the future.
 
 </Tip>",H1,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#handling-big-models-for-inference,False,1194,207,https://huggingface.co
834,Instantiating an empty model,"The first tool 🤗 Accelerate introduces to help with big models is a context manager [`init_empty_weights`] that helps you initialize a model without using any RAM so that step 1 can be done on models of any size. Here is how it works:
 
 ```py
 from accelerate import init_empty_weights
 
 with init_empty_weights():
     my_model = ModelClass(...)
 ```
 
 For instance:
 
 ```py
 with init_empty_weights():
     model = nn.Sequential(*[nn.Linear(10000, 10000) for _ in range(1000)])
 ```
 
 initializes an empty model with a bit more than 100B parameters. Behind the scenes, this relies on the meta device introduced in PyTorch 1.9. During the initialization under the context manager, each time a parameter is created, it is instantly moved to that device.
 
 <Tip warning={true}>
 
     You can't move a model initialized like this on CPU or another device directly, since it doesn't have any data. It's also very likely that a forward pass with that empty model will fail, as not all operations are supported on the meta device.
 
 </Tip>",H3,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#instantiating-an-empty-model,False,1042,179,https://huggingface.co
835,Sharded checkpoints,"It's possible your model is so big that even a single copy won't fit in RAM. That doesn't mean it can't be loaded: if you have one or several GPUs, this is more memory available to store your model. In this case, it's better if your checkpoint is split into several smaller files that we call checkpoint shards.
 
 🤗 Accelerate will handle sharded checkpoints as long as you follow the following format: your checkpoint should be in a folder, with several files containing the partial state dicts, and there should be an index in the JSON format that contains a dictionary mapping parameter names to the file containing their weights. You can easily shard your model with [`~Accelerator.save_model`]. For instance, we could have a folder containing:
 
 ```bash
 first_state_dict.bin
 index.json
 second_state_dict.bin
 ```
 
 with index.json being the following file:
 
 ```
 {
   ""linear1.weight"": ""first_state_dict.bin"",
   ""linear1.bias"": ""first_state_dict.bin"",
   ""linear2.weight"": ""second_state_dict.bin"",
   ""linear2.bias"": ""second_state_dict.bin""
 }
 ```
 
 and `first_state_dict.bin` containing the weights for `""linear1.weight""` and `""linear1.bias""`, `second_state_dict.bin` the ones for `""linear2.weight""` and `""linear2.bias""`",H3,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#sharded-checkpoints,False,1237,178,https://huggingface.co
836,Loading weights,"The second tool 🤗 Accelerate introduces is a function [`load_checkpoint_and_dispatch`], that will allow you to load a checkpoint inside your empty model. This supports full checkpoints (a single file containing the whole state dict) as well as sharded checkpoints. It will also automatically dispatch those weights across the devices you have available (GPUs, CPU RAM), so if you are loading a sharded checkpoint, the maximum RAM usage will be the size of the biggest shard.
 
 If you want to use big model inference with 🤗 Transformers models, check out this [documentation](https://huggingface.co/docs/transformers/main/en/main_classes/model#large-model-loading).
 
 Here is how we can use this to load the [GPT2-1.5B](https://huggingface.co/marcsun13/gpt2-xl-linear-sharded) model.
 
 Let's download the sharded version of this model.
 
 ```bash
 pip install huggingface_hub
 ```
 
 ```py
 from huggingface_hub import snapshot_download
 checkpoint = ""marcsun13/gpt2-xl-linear-sharded""
 weights_location = snapshot_download(repo_id=checkpoint)
 ```
 
 In order to initialize the model, we will use the library minGPT. 
 
 ```bash
 git clone https://github.com/karpathy/minGPT.git
 pip install minGPT/
 ```
 
 ```py
 from accelerate import init_empty_weights
 from mingpt.model import GPT
 
 model_config = GPT.get_default_config()
 model_config.model_type = 'gpt2-xl'
 model_config.vocab_size = 50257
 model_config.block_size = 1024
 
 with init_empty_weights():
     model = GPT(model_config)
 ```
 
 Then, load the checkpoint we just downloaded with:
 
 ```py
 from accelerate import load_checkpoint_and_dispatch
 
 model = load_checkpoint_and_dispatch(
     model, checkpoint=weights_location, device_map=""auto"", no_split_module_classes=['Block']
 )
 ```",H3,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#loading-weights,False,1759,219,https://huggingface.co
837,`no_split_module_classes`,"This parameter will indicate that some of the modules with the name `""Block""` should not be split across different devices. You should set here all blocks that 
 include a residutal connection of some kind.",H4,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#no-split-module-classes,False,206,35,https://huggingface.co
838,The `device_map`,"You can see the `device_map` that 🤗 Accelerate picked by accessing the `hf_device_map` attribute of your model:
 
 ```py
 model.hf_device_map
 ```
 
 ```python out
 {'transformer.wte': 0,
  'transformer.wpe': 0,
  'transformer.drop': 0,
  'transformer.h.0': 0,
  ...
  'transformer.h.21': 0, 
  'transformer.h.22': 1, 
  'transformer.h.23': 1, 
  'transformer.h.24': 1,
  ...
  'transformer.h.47': 1, 
  'transformer.ln_f': 1, 
  'lm_head': 1}
  ```
 
 It's fully possible to create your own device map for the layers to use as well, specifying the GPU device to use (a number), `""cpu""`, or `""disk""` and pass this in:
 
 ```python
 device_map = {
     ""transformer.wte"": ""cpu"",
     ""transformer.wpe"": 0,
     ""transformer.drop"": ""cpu"",
     ""transformer.h.0"": ""disk""
 }
 
 model = load_checkpoint_and_dispatch(
     model, checkpoint=weights_location, device_map=device_map
 )
 
 ```",H4,https://huggingface.co/docs/accelerate/source/concept_guides/big_model_inference#the-device-map,False,884,143,https://huggingface.co
